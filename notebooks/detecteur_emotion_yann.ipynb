{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "31132dbf",
   "metadata": {},
   "source": [
    "# Dectecteur Emotion\n",
    "\n",
    "L'objectif est qu'à partir de données textuelles, je classifie l'émotion du texte"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a4b619bd",
   "metadata": {},
   "source": [
    "pour ce faire, nous utiliseras go/emotions : https://www.kaggle.com/datasets/shivamb/go-emotions-google-emotions-dataset?resource=download"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "cd6f1fd3",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Shape: (211225, 31)\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>id</th>\n",
       "      <th>text</th>\n",
       "      <th>example_very_unclear</th>\n",
       "      <th>admiration</th>\n",
       "      <th>amusement</th>\n",
       "      <th>anger</th>\n",
       "      <th>annoyance</th>\n",
       "      <th>approval</th>\n",
       "      <th>caring</th>\n",
       "      <th>confusion</th>\n",
       "      <th>...</th>\n",
       "      <th>love</th>\n",
       "      <th>nervousness</th>\n",
       "      <th>optimism</th>\n",
       "      <th>pride</th>\n",
       "      <th>realization</th>\n",
       "      <th>relief</th>\n",
       "      <th>remorse</th>\n",
       "      <th>sadness</th>\n",
       "      <th>surprise</th>\n",
       "      <th>neutral</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>eew5j0j</td>\n",
       "      <td>That game hurt.</td>\n",
       "      <td>False</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>eemcysk</td>\n",
       "      <td>&gt;sexuality shouldn’t be a grouping category I...</td>\n",
       "      <td>True</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>ed2mah1</td>\n",
       "      <td>You do right, if you don't care then fuck 'em!</td>\n",
       "      <td>False</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>eeibobj</td>\n",
       "      <td>Man I love reddit.</td>\n",
       "      <td>False</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>eda6yn6</td>\n",
       "      <td>[NAME] was nowhere near them, he was by the Fa...</td>\n",
       "      <td>False</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows × 31 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "        id                                               text  \\\n",
       "0  eew5j0j                                    That game hurt.   \n",
       "1  eemcysk   >sexuality shouldn’t be a grouping category I...   \n",
       "2  ed2mah1     You do right, if you don't care then fuck 'em!   \n",
       "3  eeibobj                                 Man I love reddit.   \n",
       "4  eda6yn6  [NAME] was nowhere near them, he was by the Fa...   \n",
       "\n",
       "   example_very_unclear  admiration  amusement  anger  annoyance  approval  \\\n",
       "0                 False           0          0      0          0         0   \n",
       "1                  True           0          0      0          0         0   \n",
       "2                 False           0          0      0          0         0   \n",
       "3                 False           0          0      0          0         0   \n",
       "4                 False           0          0      0          0         0   \n",
       "\n",
       "   caring  confusion  ...  love  nervousness  optimism  pride  realization  \\\n",
       "0       0          0  ...     0            0         0      0            0   \n",
       "1       0          0  ...     0            0         0      0            0   \n",
       "2       0          0  ...     0            0         0      0            0   \n",
       "3       0          0  ...     1            0         0      0            0   \n",
       "4       0          0  ...     0            0         0      0            0   \n",
       "\n",
       "   relief  remorse  sadness  surprise  neutral  \n",
       "0       0        0        1         0        0  \n",
       "1       0        0        0         0        0  \n",
       "2       0        0        0         0        1  \n",
       "3       0        0        0         0        0  \n",
       "4       0        0        0         0        1  \n",
       "\n",
       "[5 rows x 31 columns]"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import pandas as pd\n",
    "\n",
    "# Charger le dataset\n",
    "df = pd.read_csv('../data/emotion_datasets/go_emotions_dataset.csv')\n",
    "\n",
    "# Aperçu\n",
    "print(\"Shape:\", df.shape)\n",
    "df.head()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "6675c1c3",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Colonnes disponibles :\n",
      "Index(['id', 'text', 'example_very_unclear', 'admiration', 'amusement',\n",
      "       'anger', 'annoyance', 'approval', 'caring', 'confusion', 'curiosity',\n",
      "       'desire', 'disappointment', 'disapproval', 'disgust', 'embarrassment',\n",
      "       'excitement', 'fear', 'gratitude', 'grief', 'joy', 'love',\n",
      "       'nervousness', 'optimism', 'pride', 'realization', 'relief', 'remorse',\n",
      "       'sadness', 'surprise', 'neutral'],\n",
      "      dtype='object')\n",
      "\n",
      "Types de données :\n",
      "id                      object\n",
      "text                    object\n",
      "example_very_unclear      bool\n",
      "admiration               int64\n",
      "amusement                int64\n",
      "anger                    int64\n",
      "annoyance                int64\n",
      "approval                 int64\n",
      "caring                   int64\n",
      "confusion                int64\n",
      "curiosity                int64\n",
      "desire                   int64\n",
      "disappointment           int64\n",
      "disapproval              int64\n",
      "disgust                  int64\n",
      "embarrassment            int64\n",
      "excitement               int64\n",
      "fear                     int64\n",
      "gratitude                int64\n",
      "grief                    int64\n",
      "joy                      int64\n",
      "love                     int64\n",
      "nervousness              int64\n",
      "optimism                 int64\n",
      "pride                    int64\n",
      "realization              int64\n",
      "relief                   int64\n",
      "remorse                  int64\n",
      "sadness                  int64\n",
      "surprise                 int64\n",
      "neutral                  int64\n",
      "dtype: object\n"
     ]
    }
   ],
   "source": [
    "print(\"Colonnes disponibles :\")\n",
    "print(df.columns)\n",
    "\n",
    "print(\"\\nTypes de données :\")\n",
    "print(df.dtypes)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "fe5c71e6",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Longueur moyenne des textes : 12.99718783287963\n",
      "\n",
      "Valeurs uniques par colonne :\n",
      "id                      58011\n",
      "text                    57732\n",
      "example_very_unclear        2\n",
      "admiration                  2\n",
      "amusement                   2\n",
      "anger                       2\n",
      "annoyance                   2\n",
      "approval                    2\n",
      "caring                      2\n",
      "confusion                   2\n",
      "curiosity                   2\n",
      "desire                      2\n",
      "disappointment              2\n",
      "disapproval                 2\n",
      "disgust                     2\n",
      "embarrassment               2\n",
      "excitement                  2\n",
      "fear                        2\n",
      "gratitude                   2\n",
      "grief                       2\n",
      "joy                         2\n",
      "love                        2\n",
      "nervousness                 2\n",
      "optimism                    2\n",
      "pride                       2\n",
      "realization                 2\n",
      "relief                      2\n",
      "remorse                     2\n",
      "sadness                     2\n",
      "surprise                    2\n",
      "neutral                     2\n",
      "text_length                33\n",
      "dtype: int64\n"
     ]
    }
   ],
   "source": [
    "# Longueur moyenne des textes\n",
    "df['text_length'] = df['text'].apply(lambda x: len(str(x).split()))\n",
    "print(\"Longueur moyenne des textes :\", df['text_length'].mean())\n",
    "\n",
    "# Nombre de valeurs uniques par colonne (si pertinent)\n",
    "print(\"\\nValeurs uniques par colonne :\")\n",
    "print(df.nunique())\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "94fd79eb",
   "metadata": {},
   "source": [
    "### Analyse des étiquettes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "0d0e95d7",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Nombre de labels : 30\n",
      "\n",
      "Distribution des émotions :\n",
      "text_length             2745331\n",
      "neutral                   55298\n",
      "approval                  17620\n",
      "admiration                17131\n",
      "annoyance                 13618\n",
      "gratitude                 11625\n",
      "disapproval               11424\n",
      "curiosity                  9692\n",
      "amusement                  9245\n",
      "realization                8785\n",
      "optimism                   8715\n",
      "disappointment             8469\n",
      "love                       8191\n",
      "anger                      8084\n",
      "joy                        7983\n",
      "confusion                  7359\n",
      "sadness                    6758\n",
      "caring                     5999\n",
      "excitement                 5629\n",
      "surprise                   5514\n",
      "disgust                    5301\n",
      "desire                     3817\n",
      "example_very_unclear       3411\n",
      "fear                       3197\n",
      "remorse                    2525\n",
      "embarrassment              2476\n",
      "nervousness                1810\n",
      "pride                      1302\n",
      "relief                     1289\n",
      "grief                       673\n",
      "dtype: int64\n"
     ]
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 1200x500 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "label_cols = [col for col in df.columns if col not in ['text', 'id']]  # ajuste selon les vraies colonnes\n",
    "print(\"Nombre de labels :\", len(label_cols))\n",
    "\n",
    "# Fréquence des émotions\n",
    "emotion_counts = df[label_cols].sum().sort_values(ascending=False)\n",
    "print(\"\\nDistribution des émotions :\")\n",
    "print(emotion_counts)\n",
    "\n",
    "# Affichage graphique\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "emotion_counts.plot(kind='bar', figsize=(12,5), title=\"Fréquence des émotions\")\n",
    "plt.tight_layout()\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "328e0321",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 1200x500 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "\n",
    "label_cols = [col for col in df.columns if col not in ['id', 'text', 'example_very_unclear', 'text_length']]\n",
    "emotion_counts = df[label_cols].sum().sort_values(ascending=False)\n",
    "\n",
    "emotion_counts.plot(kind='bar', figsize=(12,5), title=\"Fréquence des émotions\")\n",
    "plt.ylabel(\"Nombre d'exemples\")\n",
    "plt.xticks(rotation=45, ha='right')\n",
    "plt.tight_layout()\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "83a10231",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Nombre moyen d'émotions par texte : 1.1813421706710854\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "num_labels\n",
       "0       3411\n",
       "1     171820\n",
       "2      31187\n",
       "3       4218\n",
       "4        399\n",
       "5        106\n",
       "6         53\n",
       "7         20\n",
       "8          6\n",
       "9          3\n",
       "10         1\n",
       "12         1\n",
       "Name: count, dtype: int64"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df['num_labels'] = df[label_cols].sum(axis=1)\n",
    "\n",
    "print(\"Nombre moyen d'émotions par texte :\", df['num_labels'].mean())\n",
    "df['num_labels'].value_counts().sort_index()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "375ddc0a",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>text</th>\n",
       "      <th>num_labels</th>\n",
       "      <th>admiration</th>\n",
       "      <th>amusement</th>\n",
       "      <th>anger</th>\n",
       "      <th>annoyance</th>\n",
       "      <th>approval</th>\n",
       "      <th>caring</th>\n",
       "      <th>confusion</th>\n",
       "      <th>curiosity</th>\n",
       "      <th>...</th>\n",
       "      <th>love</th>\n",
       "      <th>nervousness</th>\n",
       "      <th>optimism</th>\n",
       "      <th>pride</th>\n",
       "      <th>realization</th>\n",
       "      <th>relief</th>\n",
       "      <th>remorse</th>\n",
       "      <th>sadness</th>\n",
       "      <th>surprise</th>\n",
       "      <th>neutral</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>That is odd.</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15</th>\n",
       "      <td>I appreciate it, that's good to know. I hope I...</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>23</th>\n",
       "      <td>Now I'm wondering on what I've been missing ou...</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>29</th>\n",
       "      <td>So happy for [NAME]. So sad he's not here. Ima...</td>\n",
       "      <td>3</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>32</th>\n",
       "      <td>Dark and funny, but not really nice guy. He ha...</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows × 30 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                 text  num_labels  admiration  \\\n",
       "13                                       That is odd.           2           0   \n",
       "15  I appreciate it, that's good to know. I hope I...           2           1   \n",
       "23  Now I'm wondering on what I've been missing ou...           2           0   \n",
       "29  So happy for [NAME]. So sad he's not here. Ima...           3           0   \n",
       "32  Dark and funny, but not really nice guy. He ha...           2           0   \n",
       "\n",
       "    amusement  anger  annoyance  approval  caring  confusion  curiosity  ...  \\\n",
       "13          0      0          0         0       0          0          0  ...   \n",
       "15          0      0          0         0       0          0          0  ...   \n",
       "23          0      0          0         0       0          0          1  ...   \n",
       "29          0      0          0         0       0          0          0  ...   \n",
       "32          0      0          0         0       0          0          0  ...   \n",
       "\n",
       "    love  nervousness  optimism  pride  realization  relief  remorse  sadness  \\\n",
       "13     0            0         0      0            0       0        0        0   \n",
       "15     0            0         0      0            0       0        0        0   \n",
       "23     0            0         0      0            0       0        0        0   \n",
       "29     0            0         0      0            0       0        0        1   \n",
       "32     0            0         0      0            0       0        0        0   \n",
       "\n",
       "    surprise  neutral  \n",
       "13         0        0  \n",
       "15         0        0  \n",
       "23         0        0  \n",
       "29         0        0  \n",
       "32         0        0  \n",
       "\n",
       "[5 rows x 30 columns]"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "multi_label_df = df[df['num_labels'] > 1]\n",
    "multi_label_df[['text', 'num_labels'] + label_cols].head()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3ce325ad",
   "metadata": {},
   "source": [
    "### Corrélations entre émotions "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "e933f758",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting seaborn\n",
      "  Using cached seaborn-0.13.2-py3-none-any.whl.metadata (5.4 kB)\n",
      "Requirement already satisfied: numpy!=1.24.0,>=1.20 in c:\\users\\yann\\anaconda3\\envs\\hf_gpu_env\\lib\\site-packages (from seaborn) (2.1.2)\n",
      "Requirement already satisfied: pandas>=1.2 in c:\\users\\yann\\anaconda3\\envs\\hf_gpu_env\\lib\\site-packages (from seaborn) (2.3.0)\n",
      "Requirement already satisfied: matplotlib!=3.6.1,>=3.4 in c:\\users\\yann\\anaconda3\\envs\\hf_gpu_env\\lib\\site-packages (from seaborn) (3.10.3)\n",
      "Requirement already satisfied: contourpy>=1.0.1 in c:\\users\\yann\\anaconda3\\envs\\hf_gpu_env\\lib\\site-packages (from matplotlib!=3.6.1,>=3.4->seaborn) (1.3.2)\n",
      "Requirement already satisfied: cycler>=0.10 in c:\\users\\yann\\anaconda3\\envs\\hf_gpu_env\\lib\\site-packages (from matplotlib!=3.6.1,>=3.4->seaborn) (0.12.1)\n",
      "Requirement already satisfied: fonttools>=4.22.0 in c:\\users\\yann\\anaconda3\\envs\\hf_gpu_env\\lib\\site-packages (from matplotlib!=3.6.1,>=3.4->seaborn) (4.58.4)\n",
      "Requirement already satisfied: kiwisolver>=1.3.1 in c:\\users\\yann\\anaconda3\\envs\\hf_gpu_env\\lib\\site-packages (from matplotlib!=3.6.1,>=3.4->seaborn) (1.4.8)\n",
      "Requirement already satisfied: packaging>=20.0 in c:\\users\\yann\\anaconda3\\envs\\hf_gpu_env\\lib\\site-packages (from matplotlib!=3.6.1,>=3.4->seaborn) (25.0)\n",
      "Requirement already satisfied: pillow>=8 in c:\\users\\yann\\anaconda3\\envs\\hf_gpu_env\\lib\\site-packages (from matplotlib!=3.6.1,>=3.4->seaborn) (11.0.0)\n",
      "Requirement already satisfied: pyparsing>=2.3.1 in c:\\users\\yann\\anaconda3\\envs\\hf_gpu_env\\lib\\site-packages (from matplotlib!=3.6.1,>=3.4->seaborn) (3.2.3)\n",
      "Requirement already satisfied: python-dateutil>=2.7 in c:\\users\\yann\\anaconda3\\envs\\hf_gpu_env\\lib\\site-packages (from matplotlib!=3.6.1,>=3.4->seaborn) (2.9.0.post0)\n",
      "Requirement already satisfied: pytz>=2020.1 in c:\\users\\yann\\anaconda3\\envs\\hf_gpu_env\\lib\\site-packages (from pandas>=1.2->seaborn) (2025.2)\n",
      "Requirement already satisfied: tzdata>=2022.7 in c:\\users\\yann\\anaconda3\\envs\\hf_gpu_env\\lib\\site-packages (from pandas>=1.2->seaborn) (2025.2)\n",
      "Requirement already satisfied: six>=1.5 in c:\\users\\yann\\anaconda3\\envs\\hf_gpu_env\\lib\\site-packages (from python-dateutil>=2.7->matplotlib!=3.6.1,>=3.4->seaborn) (1.17.0)\n",
      "Using cached seaborn-0.13.2-py3-none-any.whl (294 kB)\n",
      "Installing collected packages: seaborn\n",
      "Successfully installed seaborn-0.13.2\n"
     ]
    }
   ],
   "source": [
    "!pip install seaborn"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "faa3ab22",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 1400x1200 with 2 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "import seaborn as sns\n",
    "\n",
    "# Matrice de corrélation entre émotions\n",
    "correlation_matrix = df[label_cols].corr()\n",
    "plt.figure(figsize=(14, 12))\n",
    "sns.heatmap(correlation_matrix, annot=False, cmap=\"coolwarm\", square=True)\n",
    "plt.title(\"Corrélation entre émotions\")\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d162a2fd",
   "metadata": {},
   "source": [
    "### Analyse rare et fréquent"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "56494f7c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Exemples de textes avec 'neutral' :\n",
      "['Man people say baseball is dragged out but football is realllyyyy dragged out'\n",
      " 'Well this beats the whole \"[NAME] tried to convince the front office to take [NAME] at 1\" narrative'\n",
      " 'No, but I might choose to not support certain teams because their owners are trash.'\n",
      " '[NAME] is clearly our 5th best player'\n",
      " 'No since parries read the heavy press, not the release.']\n",
      "\n",
      "Exemples avec 'grief' :\n",
      "[\"I dread the day something happens in Ireland, we've been sheltered from the most of it.\"\n",
      " 'The day I get the phone call: \"your Nmom/Ndad/Nbrother have passed away.\" \"Fuuuuuuuuuuucking ***FINALLY***\"'\n",
      " 'Dude, she had just lost her baby, too. '\n",
      " 'I tell them my wife died in a car accident 10 years ago and I couldn’t fall in love again. I’ve never been married.'\n",
      " \"Honestly at this point I don't think there's anything that will make me feel better. Maybe down the road, but right now nothing is helping. \"]\n"
     ]
    }
   ],
   "source": [
    "print(\"Exemples de textes avec 'neutral' :\")\n",
    "print(df[df['neutral'] == 1]['text'].sample(5).values)\n",
    "\n",
    "print(\"\\nExemples avec 'grief' :\")\n",
    "print(df[df['grief'] == 1]['text'].sample(5).values)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e63a7dec",
   "metadata": {},
   "source": [
    "### longueur texte par émotion "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "24c220ef",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 1200x500 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "import numpy as np\n",
    "\n",
    "emotion_lengths = {\n",
    "    emotion: df[df[emotion] == 1]['text_length'].mean() \n",
    "    for emotion in label_cols\n",
    "}\n",
    "\n",
    "pd.Series(emotion_lengths).sort_values(ascending=False).plot(kind='bar', figsize=(12,5), title=\"Longueur moyenne des textes par émotion\")\n",
    "plt.tight_layout()\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e245805a",
   "metadata": {},
   "source": [
    "###  Analyse Exploratoire du Dataset GoEmotions\n",
    "\n",
    "---\n",
    "\n",
    "####  1. Structure générale du dataset\n",
    "\n",
    "- **58 000+ exemples**\n",
    "- Colonnes principales :\n",
    "  - `id` (identifiant)\n",
    "  - `text` (texte du commentaire)\n",
    "  - `example_very_unclear` (booléen)\n",
    "  - **30 colonnes binaires** représentant les émotions (`int64`, 0 ou 1)\n",
    "    - 27 émotions\n",
    "    - + `neutral`\n",
    "    - + autres (`example_very_unclear`)\n",
    "\n",
    ">  **Format multi-label**, chaque exemple peut avoir plusieurs émotions.\n",
    "\n",
    "---\n",
    "\n",
    "####  2. Distribution des émotions (fort déséquilibre)\n",
    "\n",
    "- `neutral` domine largement (**55 298 exemples**)\n",
    "- Classes fréquentes : `approval`, `admiration`, `gratitude`\n",
    "- Classes très rares :\n",
    "  - `grief` (~673)\n",
    "  - `relief`, `pride`, `nervousness`... (< 2000 exemples)\n",
    "\n",
    "#####  Implications :\n",
    "- **Risque de surapprentissage** sur les classes fréquentes\n",
    "- Besoin probable de :\n",
    "  - techniques d’**oversampling/undersampling**\n",
    "  - **pénalisation des classes majoritaires** (`class_weight`, `focal loss`)\n",
    "  - ou **fusion de certaines classes** si pertinent\n",
    "\n",
    "---\n",
    "\n",
    "####  3. Nombre d’étiquettes par texte\n",
    "\n",
    "- **Moyenne** : ~1.18 émotions/texte\n",
    "- **170 000 exemples** avec **1 seule étiquette**\n",
    "- Quelques cas extrêmes : jusqu’à **12 émotions** par texte\n",
    "\n",
    "#####  Implications :\n",
    "- Dataset **majoritairement mono-label**\n",
    "- Tu peux entraîner :\n",
    "  - Un **modèle mono-label simplifié**\n",
    "  - Et un **modèle multi-label plus réaliste**\n",
    "\n",
    "---\n",
    "\n",
    "####  4. Corrélation entre émotions\n",
    "\n",
    "- Heatmap = **peu de corrélations fortes globales**\n",
    "- Quelques cooccurrences naturelles :\n",
    "  - `admiration` ↔ `gratitude`\n",
    "  - `disapproval` ↔ `anger`\n",
    "  - `realization` ↔ `optimism`\n",
    "\n",
    "#####  Implications :\n",
    "- Ces associations peuvent être exploitées via :\n",
    "  - **loss pondérée** (pondérer les erreurs entre émotions proches)\n",
    "  - **modèle hiérarchique ou graphe de labels**\n",
    "\n",
    "---\n",
    "\n",
    "####  5. Longueur moyenne des textes par émotion\n",
    "\n",
    "- **Longueur moyenne** : ~13 tokens\n",
    "- Les textes les **plus longs** expriment :\n",
    "  - `optimism`, `realization`, `desire`\n",
    "- Les **plus courts** :\n",
    "  - `gratitude`, `excitement`, `anger`, `neutral`\n",
    "\n",
    "#####  Implications :\n",
    "- Les émotions **cognitives ou complexes** nécessitent plus de contexte\n",
    "- À envisager :\n",
    "  - **Normalisation de longueur** (padding/troncature)\n",
    "  - Étude de l'impact de la longueur sur la performance\n",
    "\n",
    "---\n",
    "\n",
    "####  Synthèse des forces et problèmes potentiels\n",
    "\n",
    "| Élément                   | Observation                       | Conséquence                                      |\n",
    "|---------------------------|-----------------------------------|--------------------------------------------------|\n",
    "| Format multi-label        | ✅ OK                              | Doit être traité avec **sigmoid** (pas softmax) |\n",
    "| Déséquilibre des classes  | ❗ Fort                            | Adapter la loss (focal, class weights...)        |\n",
    "| Étiquettes par texte      | Souvent 1                         | Benchmark mono-label vs. multi-label             |\n",
    "| Corrélations faibles      | Majoritairement indépendantes     | Potentiel pour graphe ou multi-task              |\n",
    "| Longueurs des textes      | Variées selon l’émotion           | Adapter tokenizer et **max_length**              |\n",
    "\n",
    "---\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c9403f06",
   "metadata": {},
   "source": [
    "# Traitement des données"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "9c11dc1c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Taille du dataset après nettoyage : (207814, 33)\n"
     ]
    }
   ],
   "source": [
    "# Supprimer les exemples très flous\n",
    "df_clean = df[(df['example_very_unclear'] == False) & (df['num_labels'] > 0)].copy()\n",
    "\n",
    "print(\"Taille du dataset après nettoyage :\", df_clean.shape)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4c79a31b",
   "metadata": {},
   "source": [
    "###   Séparation des données"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "a28172f9",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: scikit-learn in c:\\users\\yann\\anaconda3\\envs\\hf_gpu_env\\lib\\site-packages (1.7.0)\n",
      "Requirement already satisfied: numpy>=1.22.0 in c:\\users\\yann\\anaconda3\\envs\\hf_gpu_env\\lib\\site-packages (from scikit-learn) (2.1.2)\n",
      "Requirement already satisfied: scipy>=1.8.0 in c:\\users\\yann\\anaconda3\\envs\\hf_gpu_env\\lib\\site-packages (from scikit-learn) (1.15.3)\n",
      "Requirement already satisfied: joblib>=1.2.0 in c:\\users\\yann\\anaconda3\\envs\\hf_gpu_env\\lib\\site-packages (from scikit-learn) (1.5.1)\n",
      "Requirement already satisfied: threadpoolctl>=3.1.0 in c:\\users\\yann\\anaconda3\\envs\\hf_gpu_env\\lib\\site-packages (from scikit-learn) (3.6.0)\n"
     ]
    }
   ],
   "source": [
    "!pip install scikit-learn"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "bccab2cb",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "num_labels\n",
      "1    171820\n",
      "2     31187\n",
      "3      4218\n",
      "4       399\n",
      "5       106\n",
      "6        53\n",
      "7        20\n",
      "Name: count, dtype: int64\n",
      "Train : (166242, 33)\n",
      "Val : (20780, 33)\n",
      "Test : (20781, 33)\n"
     ]
    }
   ],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "df_stratifiable = df_clean[df_clean['num_labels'] <= 7].copy()\n",
    "\n",
    "# Vérification\n",
    "print(df_stratifiable['num_labels'].value_counts())\n",
    "\n",
    "# Split maintenant OK avec stratify\n",
    "df_train, df_temp = train_test_split(df_stratifiable, test_size=0.2, random_state=42, stratify=df_stratifiable['num_labels'])\n",
    "df_val, df_test = train_test_split(df_temp, test_size=0.5, random_state=42, stratify=df_temp['num_labels'])\n",
    "\n",
    "print(\"Train :\", df_train.shape)\n",
    "print(\"Val :\", df_val.shape)\n",
    "print(\"Test :\", df_test.shape)\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3fa7997b",
   "metadata": {},
   "source": [
    "### Préparer les features et labels"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "c894d58a",
   "metadata": {},
   "outputs": [],
   "source": [
    "label_cols = [col for col in df.columns if col not in ['id', 'text', 'example_very_unclear', 'num_labels', 'text_length']]\n",
    "\n",
    "# X = textes, y = labels binaires\n",
    "X_train = df_train['text'].tolist()\n",
    "y_train = df_train[label_cols].values\n",
    "\n",
    "X_val = df_val['text'].tolist()\n",
    "y_val = df_val[label_cols].values\n",
    "\n",
    "X_test = df_test['text'].tolist()\n",
    "y_test = df_test[label_cols].values\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0a4db6c3",
   "metadata": {},
   "source": [
    "####  Analyse des poids de classes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "0fe40278",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "admiration: 0.105\n",
      "amusement: 0.112\n",
      "anger: 0.114\n",
      "annoyance: 0.108\n",
      "approval: 0.105\n",
      "caring: 0.118\n",
      "confusion: 0.115\n",
      "curiosity: 0.112\n",
      "desire: 0.125\n",
      "disappointment: 0.113\n",
      "disapproval: 0.110\n",
      "disgust: 0.120\n",
      "embarrassment: 0.132\n",
      "excitement: 0.119\n",
      "fear: 0.127\n",
      "gratitude: 0.110\n",
      "grief: 0.159\n",
      "joy: 0.114\n",
      "love: 0.114\n",
      "nervousness: 0.138\n",
      "optimism: 0.113\n",
      "pride: 0.144\n",
      "realization: 0.113\n",
      "relief: 0.144\n",
      "remorse: 0.132\n",
      "sadness: 0.116\n",
      "surprise: 0.119\n",
      "neutral: 0.093\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "\n",
    "# Fréquence inverse pour class weighting\n",
    "class_weights = np.sum(y_train, axis=0)\n",
    "class_weights = 1 / np.log1p(class_weights)  # ou 1/class_freq\n",
    "\n",
    "# Affichage\n",
    "for label, weight in zip(label_cols, class_weights):\n",
    "    print(f\"{label}: {weight:.3f}\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1bc4a90f",
   "metadata": {},
   "source": [
    "# Modélisation"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c1c6d5de",
   "metadata": {},
   "source": [
    "## TF IDF + regression logistique"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "83aecc0a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Dimensions TF-IDF : (166242, 10000)\n"
     ]
    }
   ],
   "source": [
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "\n",
    "# Limite à 10k tokens max pour éviter surdimension\n",
    "vectorizer = TfidfVectorizer(max_features=10000, ngram_range=(1, 2), stop_words='english')\n",
    "\n",
    "X_train_tfidf = vectorizer.fit_transform(X_train)\n",
    "X_val_tfidf = vectorizer.transform(X_val)\n",
    "X_test_tfidf = vectorizer.transform(X_test)\n",
    "\n",
    "print(\"Dimensions TF-IDF :\", X_train_tfidf.shape)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "4fe428eb",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<style>#sk-container-id-1 {\n",
       "  /* Definition of color scheme common for light and dark mode */\n",
       "  --sklearn-color-text: #000;\n",
       "  --sklearn-color-text-muted: #666;\n",
       "  --sklearn-color-line: gray;\n",
       "  /* Definition of color scheme for unfitted estimators */\n",
       "  --sklearn-color-unfitted-level-0: #fff5e6;\n",
       "  --sklearn-color-unfitted-level-1: #f6e4d2;\n",
       "  --sklearn-color-unfitted-level-2: #ffe0b3;\n",
       "  --sklearn-color-unfitted-level-3: chocolate;\n",
       "  /* Definition of color scheme for fitted estimators */\n",
       "  --sklearn-color-fitted-level-0: #f0f8ff;\n",
       "  --sklearn-color-fitted-level-1: #d4ebff;\n",
       "  --sklearn-color-fitted-level-2: #b3dbfd;\n",
       "  --sklearn-color-fitted-level-3: cornflowerblue;\n",
       "\n",
       "  /* Specific color for light theme */\n",
       "  --sklearn-color-text-on-default-background: var(--sg-text-color, var(--theme-code-foreground, var(--jp-content-font-color1, black)));\n",
       "  --sklearn-color-background: var(--sg-background-color, var(--theme-background, var(--jp-layout-color0, white)));\n",
       "  --sklearn-color-border-box: var(--sg-text-color, var(--theme-code-foreground, var(--jp-content-font-color1, black)));\n",
       "  --sklearn-color-icon: #696969;\n",
       "\n",
       "  @media (prefers-color-scheme: dark) {\n",
       "    /* Redefinition of color scheme for dark theme */\n",
       "    --sklearn-color-text-on-default-background: var(--sg-text-color, var(--theme-code-foreground, var(--jp-content-font-color1, white)));\n",
       "    --sklearn-color-background: var(--sg-background-color, var(--theme-background, var(--jp-layout-color0, #111)));\n",
       "    --sklearn-color-border-box: var(--sg-text-color, var(--theme-code-foreground, var(--jp-content-font-color1, white)));\n",
       "    --sklearn-color-icon: #878787;\n",
       "  }\n",
       "}\n",
       "\n",
       "#sk-container-id-1 {\n",
       "  color: var(--sklearn-color-text);\n",
       "}\n",
       "\n",
       "#sk-container-id-1 pre {\n",
       "  padding: 0;\n",
       "}\n",
       "\n",
       "#sk-container-id-1 input.sk-hidden--visually {\n",
       "  border: 0;\n",
       "  clip: rect(1px 1px 1px 1px);\n",
       "  clip: rect(1px, 1px, 1px, 1px);\n",
       "  height: 1px;\n",
       "  margin: -1px;\n",
       "  overflow: hidden;\n",
       "  padding: 0;\n",
       "  position: absolute;\n",
       "  width: 1px;\n",
       "}\n",
       "\n",
       "#sk-container-id-1 div.sk-dashed-wrapped {\n",
       "  border: 1px dashed var(--sklearn-color-line);\n",
       "  margin: 0 0.4em 0.5em 0.4em;\n",
       "  box-sizing: border-box;\n",
       "  padding-bottom: 0.4em;\n",
       "  background-color: var(--sklearn-color-background);\n",
       "}\n",
       "\n",
       "#sk-container-id-1 div.sk-container {\n",
       "  /* jupyter's `normalize.less` sets `[hidden] { display: none; }`\n",
       "     but bootstrap.min.css set `[hidden] { display: none !important; }`\n",
       "     so we also need the `!important` here to be able to override the\n",
       "     default hidden behavior on the sphinx rendered scikit-learn.org.\n",
       "     See: https://github.com/scikit-learn/scikit-learn/issues/21755 */\n",
       "  display: inline-block !important;\n",
       "  position: relative;\n",
       "}\n",
       "\n",
       "#sk-container-id-1 div.sk-text-repr-fallback {\n",
       "  display: none;\n",
       "}\n",
       "\n",
       "div.sk-parallel-item,\n",
       "div.sk-serial,\n",
       "div.sk-item {\n",
       "  /* draw centered vertical line to link estimators */\n",
       "  background-image: linear-gradient(var(--sklearn-color-text-on-default-background), var(--sklearn-color-text-on-default-background));\n",
       "  background-size: 2px 100%;\n",
       "  background-repeat: no-repeat;\n",
       "  background-position: center center;\n",
       "}\n",
       "\n",
       "/* Parallel-specific style estimator block */\n",
       "\n",
       "#sk-container-id-1 div.sk-parallel-item::after {\n",
       "  content: \"\";\n",
       "  width: 100%;\n",
       "  border-bottom: 2px solid var(--sklearn-color-text-on-default-background);\n",
       "  flex-grow: 1;\n",
       "}\n",
       "\n",
       "#sk-container-id-1 div.sk-parallel {\n",
       "  display: flex;\n",
       "  align-items: stretch;\n",
       "  justify-content: center;\n",
       "  background-color: var(--sklearn-color-background);\n",
       "  position: relative;\n",
       "}\n",
       "\n",
       "#sk-container-id-1 div.sk-parallel-item {\n",
       "  display: flex;\n",
       "  flex-direction: column;\n",
       "}\n",
       "\n",
       "#sk-container-id-1 div.sk-parallel-item:first-child::after {\n",
       "  align-self: flex-end;\n",
       "  width: 50%;\n",
       "}\n",
       "\n",
       "#sk-container-id-1 div.sk-parallel-item:last-child::after {\n",
       "  align-self: flex-start;\n",
       "  width: 50%;\n",
       "}\n",
       "\n",
       "#sk-container-id-1 div.sk-parallel-item:only-child::after {\n",
       "  width: 0;\n",
       "}\n",
       "\n",
       "/* Serial-specific style estimator block */\n",
       "\n",
       "#sk-container-id-1 div.sk-serial {\n",
       "  display: flex;\n",
       "  flex-direction: column;\n",
       "  align-items: center;\n",
       "  background-color: var(--sklearn-color-background);\n",
       "  padding-right: 1em;\n",
       "  padding-left: 1em;\n",
       "}\n",
       "\n",
       "\n",
       "/* Toggleable style: style used for estimator/Pipeline/ColumnTransformer box that is\n",
       "clickable and can be expanded/collapsed.\n",
       "- Pipeline and ColumnTransformer use this feature and define the default style\n",
       "- Estimators will overwrite some part of the style using the `sk-estimator` class\n",
       "*/\n",
       "\n",
       "/* Pipeline and ColumnTransformer style (default) */\n",
       "\n",
       "#sk-container-id-1 div.sk-toggleable {\n",
       "  /* Default theme specific background. It is overwritten whether we have a\n",
       "  specific estimator or a Pipeline/ColumnTransformer */\n",
       "  background-color: var(--sklearn-color-background);\n",
       "}\n",
       "\n",
       "/* Toggleable label */\n",
       "#sk-container-id-1 label.sk-toggleable__label {\n",
       "  cursor: pointer;\n",
       "  display: flex;\n",
       "  width: 100%;\n",
       "  margin-bottom: 0;\n",
       "  padding: 0.5em;\n",
       "  box-sizing: border-box;\n",
       "  text-align: center;\n",
       "  align-items: start;\n",
       "  justify-content: space-between;\n",
       "  gap: 0.5em;\n",
       "}\n",
       "\n",
       "#sk-container-id-1 label.sk-toggleable__label .caption {\n",
       "  font-size: 0.6rem;\n",
       "  font-weight: lighter;\n",
       "  color: var(--sklearn-color-text-muted);\n",
       "}\n",
       "\n",
       "#sk-container-id-1 label.sk-toggleable__label-arrow:before {\n",
       "  /* Arrow on the left of the label */\n",
       "  content: \"▸\";\n",
       "  float: left;\n",
       "  margin-right: 0.25em;\n",
       "  color: var(--sklearn-color-icon);\n",
       "}\n",
       "\n",
       "#sk-container-id-1 label.sk-toggleable__label-arrow:hover:before {\n",
       "  color: var(--sklearn-color-text);\n",
       "}\n",
       "\n",
       "/* Toggleable content - dropdown */\n",
       "\n",
       "#sk-container-id-1 div.sk-toggleable__content {\n",
       "  display: none;\n",
       "  text-align: left;\n",
       "  /* unfitted */\n",
       "  background-color: var(--sklearn-color-unfitted-level-0);\n",
       "}\n",
       "\n",
       "#sk-container-id-1 div.sk-toggleable__content.fitted {\n",
       "  /* fitted */\n",
       "  background-color: var(--sklearn-color-fitted-level-0);\n",
       "}\n",
       "\n",
       "#sk-container-id-1 div.sk-toggleable__content pre {\n",
       "  margin: 0.2em;\n",
       "  border-radius: 0.25em;\n",
       "  color: var(--sklearn-color-text);\n",
       "  /* unfitted */\n",
       "  background-color: var(--sklearn-color-unfitted-level-0);\n",
       "}\n",
       "\n",
       "#sk-container-id-1 div.sk-toggleable__content.fitted pre {\n",
       "  /* unfitted */\n",
       "  background-color: var(--sklearn-color-fitted-level-0);\n",
       "}\n",
       "\n",
       "#sk-container-id-1 input.sk-toggleable__control:checked~div.sk-toggleable__content {\n",
       "  /* Expand drop-down */\n",
       "  display: block;\n",
       "  width: 100%;\n",
       "  overflow: visible;\n",
       "}\n",
       "\n",
       "#sk-container-id-1 input.sk-toggleable__control:checked~label.sk-toggleable__label-arrow:before {\n",
       "  content: \"▾\";\n",
       "}\n",
       "\n",
       "/* Pipeline/ColumnTransformer-specific style */\n",
       "\n",
       "#sk-container-id-1 div.sk-label input.sk-toggleable__control:checked~label.sk-toggleable__label {\n",
       "  color: var(--sklearn-color-text);\n",
       "  background-color: var(--sklearn-color-unfitted-level-2);\n",
       "}\n",
       "\n",
       "#sk-container-id-1 div.sk-label.fitted input.sk-toggleable__control:checked~label.sk-toggleable__label {\n",
       "  background-color: var(--sklearn-color-fitted-level-2);\n",
       "}\n",
       "\n",
       "/* Estimator-specific style */\n",
       "\n",
       "/* Colorize estimator box */\n",
       "#sk-container-id-1 div.sk-estimator input.sk-toggleable__control:checked~label.sk-toggleable__label {\n",
       "  /* unfitted */\n",
       "  background-color: var(--sklearn-color-unfitted-level-2);\n",
       "}\n",
       "\n",
       "#sk-container-id-1 div.sk-estimator.fitted input.sk-toggleable__control:checked~label.sk-toggleable__label {\n",
       "  /* fitted */\n",
       "  background-color: var(--sklearn-color-fitted-level-2);\n",
       "}\n",
       "\n",
       "#sk-container-id-1 div.sk-label label.sk-toggleable__label,\n",
       "#sk-container-id-1 div.sk-label label {\n",
       "  /* The background is the default theme color */\n",
       "  color: var(--sklearn-color-text-on-default-background);\n",
       "}\n",
       "\n",
       "/* On hover, darken the color of the background */\n",
       "#sk-container-id-1 div.sk-label:hover label.sk-toggleable__label {\n",
       "  color: var(--sklearn-color-text);\n",
       "  background-color: var(--sklearn-color-unfitted-level-2);\n",
       "}\n",
       "\n",
       "/* Label box, darken color on hover, fitted */\n",
       "#sk-container-id-1 div.sk-label.fitted:hover label.sk-toggleable__label.fitted {\n",
       "  color: var(--sklearn-color-text);\n",
       "  background-color: var(--sklearn-color-fitted-level-2);\n",
       "}\n",
       "\n",
       "/* Estimator label */\n",
       "\n",
       "#sk-container-id-1 div.sk-label label {\n",
       "  font-family: monospace;\n",
       "  font-weight: bold;\n",
       "  display: inline-block;\n",
       "  line-height: 1.2em;\n",
       "}\n",
       "\n",
       "#sk-container-id-1 div.sk-label-container {\n",
       "  text-align: center;\n",
       "}\n",
       "\n",
       "/* Estimator-specific */\n",
       "#sk-container-id-1 div.sk-estimator {\n",
       "  font-family: monospace;\n",
       "  border: 1px dotted var(--sklearn-color-border-box);\n",
       "  border-radius: 0.25em;\n",
       "  box-sizing: border-box;\n",
       "  margin-bottom: 0.5em;\n",
       "  /* unfitted */\n",
       "  background-color: var(--sklearn-color-unfitted-level-0);\n",
       "}\n",
       "\n",
       "#sk-container-id-1 div.sk-estimator.fitted {\n",
       "  /* fitted */\n",
       "  background-color: var(--sklearn-color-fitted-level-0);\n",
       "}\n",
       "\n",
       "/* on hover */\n",
       "#sk-container-id-1 div.sk-estimator:hover {\n",
       "  /* unfitted */\n",
       "  background-color: var(--sklearn-color-unfitted-level-2);\n",
       "}\n",
       "\n",
       "#sk-container-id-1 div.sk-estimator.fitted:hover {\n",
       "  /* fitted */\n",
       "  background-color: var(--sklearn-color-fitted-level-2);\n",
       "}\n",
       "\n",
       "/* Specification for estimator info (e.g. \"i\" and \"?\") */\n",
       "\n",
       "/* Common style for \"i\" and \"?\" */\n",
       "\n",
       ".sk-estimator-doc-link,\n",
       "a:link.sk-estimator-doc-link,\n",
       "a:visited.sk-estimator-doc-link {\n",
       "  float: right;\n",
       "  font-size: smaller;\n",
       "  line-height: 1em;\n",
       "  font-family: monospace;\n",
       "  background-color: var(--sklearn-color-background);\n",
       "  border-radius: 1em;\n",
       "  height: 1em;\n",
       "  width: 1em;\n",
       "  text-decoration: none !important;\n",
       "  margin-left: 0.5em;\n",
       "  text-align: center;\n",
       "  /* unfitted */\n",
       "  border: var(--sklearn-color-unfitted-level-1) 1pt solid;\n",
       "  color: var(--sklearn-color-unfitted-level-1);\n",
       "}\n",
       "\n",
       ".sk-estimator-doc-link.fitted,\n",
       "a:link.sk-estimator-doc-link.fitted,\n",
       "a:visited.sk-estimator-doc-link.fitted {\n",
       "  /* fitted */\n",
       "  border: var(--sklearn-color-fitted-level-1) 1pt solid;\n",
       "  color: var(--sklearn-color-fitted-level-1);\n",
       "}\n",
       "\n",
       "/* On hover */\n",
       "div.sk-estimator:hover .sk-estimator-doc-link:hover,\n",
       ".sk-estimator-doc-link:hover,\n",
       "div.sk-label-container:hover .sk-estimator-doc-link:hover,\n",
       ".sk-estimator-doc-link:hover {\n",
       "  /* unfitted */\n",
       "  background-color: var(--sklearn-color-unfitted-level-3);\n",
       "  color: var(--sklearn-color-background);\n",
       "  text-decoration: none;\n",
       "}\n",
       "\n",
       "div.sk-estimator.fitted:hover .sk-estimator-doc-link.fitted:hover,\n",
       ".sk-estimator-doc-link.fitted:hover,\n",
       "div.sk-label-container:hover .sk-estimator-doc-link.fitted:hover,\n",
       ".sk-estimator-doc-link.fitted:hover {\n",
       "  /* fitted */\n",
       "  background-color: var(--sklearn-color-fitted-level-3);\n",
       "  color: var(--sklearn-color-background);\n",
       "  text-decoration: none;\n",
       "}\n",
       "\n",
       "/* Span, style for the box shown on hovering the info icon */\n",
       ".sk-estimator-doc-link span {\n",
       "  display: none;\n",
       "  z-index: 9999;\n",
       "  position: relative;\n",
       "  font-weight: normal;\n",
       "  right: .2ex;\n",
       "  padding: .5ex;\n",
       "  margin: .5ex;\n",
       "  width: min-content;\n",
       "  min-width: 20ex;\n",
       "  max-width: 50ex;\n",
       "  color: var(--sklearn-color-text);\n",
       "  box-shadow: 2pt 2pt 4pt #999;\n",
       "  /* unfitted */\n",
       "  background: var(--sklearn-color-unfitted-level-0);\n",
       "  border: .5pt solid var(--sklearn-color-unfitted-level-3);\n",
       "}\n",
       "\n",
       ".sk-estimator-doc-link.fitted span {\n",
       "  /* fitted */\n",
       "  background: var(--sklearn-color-fitted-level-0);\n",
       "  border: var(--sklearn-color-fitted-level-3);\n",
       "}\n",
       "\n",
       ".sk-estimator-doc-link:hover span {\n",
       "  display: block;\n",
       "}\n",
       "\n",
       "/* \"?\"-specific style due to the `<a>` HTML tag */\n",
       "\n",
       "#sk-container-id-1 a.estimator_doc_link {\n",
       "  float: right;\n",
       "  font-size: 1rem;\n",
       "  line-height: 1em;\n",
       "  font-family: monospace;\n",
       "  background-color: var(--sklearn-color-background);\n",
       "  border-radius: 1rem;\n",
       "  height: 1rem;\n",
       "  width: 1rem;\n",
       "  text-decoration: none;\n",
       "  /* unfitted */\n",
       "  color: var(--sklearn-color-unfitted-level-1);\n",
       "  border: var(--sklearn-color-unfitted-level-1) 1pt solid;\n",
       "}\n",
       "\n",
       "#sk-container-id-1 a.estimator_doc_link.fitted {\n",
       "  /* fitted */\n",
       "  border: var(--sklearn-color-fitted-level-1) 1pt solid;\n",
       "  color: var(--sklearn-color-fitted-level-1);\n",
       "}\n",
       "\n",
       "/* On hover */\n",
       "#sk-container-id-1 a.estimator_doc_link:hover {\n",
       "  /* unfitted */\n",
       "  background-color: var(--sklearn-color-unfitted-level-3);\n",
       "  color: var(--sklearn-color-background);\n",
       "  text-decoration: none;\n",
       "}\n",
       "\n",
       "#sk-container-id-1 a.estimator_doc_link.fitted:hover {\n",
       "  /* fitted */\n",
       "  background-color: var(--sklearn-color-fitted-level-3);\n",
       "}\n",
       "\n",
       ".estimator-table summary {\n",
       "    padding: .5rem;\n",
       "    font-family: monospace;\n",
       "    cursor: pointer;\n",
       "}\n",
       "\n",
       ".estimator-table details[open] {\n",
       "    padding-left: 0.1rem;\n",
       "    padding-right: 0.1rem;\n",
       "    padding-bottom: 0.3rem;\n",
       "}\n",
       "\n",
       ".estimator-table .parameters-table {\n",
       "    margin-left: auto !important;\n",
       "    margin-right: auto !important;\n",
       "}\n",
       "\n",
       ".estimator-table .parameters-table tr:nth-child(odd) {\n",
       "    background-color: #fff;\n",
       "}\n",
       "\n",
       ".estimator-table .parameters-table tr:nth-child(even) {\n",
       "    background-color: #f6f6f6;\n",
       "}\n",
       "\n",
       ".estimator-table .parameters-table tr:hover {\n",
       "    background-color: #e0e0e0;\n",
       "}\n",
       "\n",
       ".estimator-table table td {\n",
       "    border: 1px solid rgba(106, 105, 104, 0.232);\n",
       "}\n",
       "\n",
       ".user-set td {\n",
       "    color:rgb(255, 94, 0);\n",
       "    text-align: left;\n",
       "}\n",
       "\n",
       ".user-set td.value pre {\n",
       "    color:rgb(255, 94, 0) !important;\n",
       "    background-color: transparent !important;\n",
       "}\n",
       "\n",
       ".default td {\n",
       "    color: black;\n",
       "    text-align: left;\n",
       "}\n",
       "\n",
       ".user-set td i,\n",
       ".default td i {\n",
       "    color: black;\n",
       "}\n",
       "\n",
       ".copy-paste-icon {\n",
       "    background-image: url(data:image/svg+xml;base64,PHN2ZyB4bWxucz0iaHR0cDovL3d3dy53My5vcmcvMjAwMC9zdmciIHZpZXdCb3g9IjAgMCA0NDggNTEyIj48IS0tIUZvbnQgQXdlc29tZSBGcmVlIDYuNy4yIGJ5IEBmb250YXdlc29tZSAtIGh0dHBzOi8vZm9udGF3ZXNvbWUuY29tIExpY2Vuc2UgLSBodHRwczovL2ZvbnRhd2Vzb21lLmNvbS9saWNlbnNlL2ZyZWUgQ29weXJpZ2h0IDIwMjUgRm9udGljb25zLCBJbmMuLS0+PHBhdGggZD0iTTIwOCAwTDMzMi4xIDBjMTIuNyAwIDI0LjkgNS4xIDMzLjkgMTQuMWw2Ny45IDY3LjljOSA5IDE0LjEgMjEuMiAxNC4xIDMzLjlMNDQ4IDMzNmMwIDI2LjUtMjEuNSA0OC00OCA0OGwtMTkyIDBjLTI2LjUgMC00OC0yMS41LTQ4LTQ4bDAtMjg4YzAtMjYuNSAyMS41LTQ4IDQ4LTQ4ek00OCAxMjhsODAgMCAwIDY0LTY0IDAgMCAyNTYgMTkyIDAgMC0zMiA2NCAwIDAgNDhjMCAyNi41LTIxLjUgNDgtNDggNDhMNDggNTEyYy0yNi41IDAtNDgtMjEuNS00OC00OEwwIDE3NmMwLTI2LjUgMjEuNS00OCA0OC00OHoiLz48L3N2Zz4=);\n",
       "    background-repeat: no-repeat;\n",
       "    background-size: 14px 14px;\n",
       "    background-position: 0;\n",
       "    display: inline-block;\n",
       "    width: 14px;\n",
       "    height: 14px;\n",
       "    cursor: pointer;\n",
       "}\n",
       "</style><body><div id=\"sk-container-id-1\" class=\"sk-top-container\"><div class=\"sk-text-repr-fallback\"><pre>OneVsRestClassifier(estimator=LogisticRegression(solver=&#x27;liblinear&#x27;))</pre><b>In a Jupyter environment, please rerun this cell to show the HTML representation or trust the notebook. <br />On GitHub, the HTML representation is unable to render, please try loading this page with nbviewer.org.</b></div><div class=\"sk-container\" hidden><div class=\"sk-item sk-dashed-wrapped\"><div class=\"sk-label-container\"><div class=\"sk-label fitted sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-1\" type=\"checkbox\" ><label for=\"sk-estimator-id-1\" class=\"sk-toggleable__label fitted sk-toggleable__label-arrow\"><div><div>OneVsRestClassifier</div></div><div><a class=\"sk-estimator-doc-link fitted\" rel=\"noreferrer\" target=\"_blank\" href=\"https://scikit-learn.org/1.7/modules/generated/sklearn.multiclass.OneVsRestClassifier.html\">?<span>Documentation for OneVsRestClassifier</span></a><span class=\"sk-estimator-doc-link fitted\">i<span>Fitted</span></span></div></label><div class=\"sk-toggleable__content fitted\" data-param-prefix=\"\">\n",
       "        <div class=\"estimator-table\">\n",
       "            <details>\n",
       "                <summary>Parameters</summary>\n",
       "                <table class=\"parameters-table\">\n",
       "                  <tbody>\n",
       "                    \n",
       "        <tr class=\"user-set\">\n",
       "            <td><i class=\"copy-paste-icon\"\n",
       "                 onclick=\"copyToClipboard('estimator',\n",
       "                          this.parentElement.nextElementSibling)\"\n",
       "            ></i></td>\n",
       "            <td class=\"param\">estimator&nbsp;</td>\n",
       "            <td class=\"value\">LogisticRegre...r=&#x27;liblinear&#x27;)</td>\n",
       "        </tr>\n",
       "    \n",
       "\n",
       "        <tr class=\"default\">\n",
       "            <td><i class=\"copy-paste-icon\"\n",
       "                 onclick=\"copyToClipboard('n_jobs',\n",
       "                          this.parentElement.nextElementSibling)\"\n",
       "            ></i></td>\n",
       "            <td class=\"param\">n_jobs&nbsp;</td>\n",
       "            <td class=\"value\">None</td>\n",
       "        </tr>\n",
       "    \n",
       "\n",
       "        <tr class=\"default\">\n",
       "            <td><i class=\"copy-paste-icon\"\n",
       "                 onclick=\"copyToClipboard('verbose',\n",
       "                          this.parentElement.nextElementSibling)\"\n",
       "            ></i></td>\n",
       "            <td class=\"param\">verbose&nbsp;</td>\n",
       "            <td class=\"value\">0</td>\n",
       "        </tr>\n",
       "    \n",
       "                  </tbody>\n",
       "                </table>\n",
       "            </details>\n",
       "        </div>\n",
       "    </div></div></div><div class=\"sk-parallel\"><div class=\"sk-parallel-item\"><div class=\"sk-item\"><div class=\"sk-label-container\"><div class=\"sk-label fitted sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-2\" type=\"checkbox\" ><label for=\"sk-estimator-id-2\" class=\"sk-toggleable__label fitted sk-toggleable__label-arrow\"><div><div>estimator: LogisticRegression</div></div></label><div class=\"sk-toggleable__content fitted\" data-param-prefix=\"estimator__\"><pre>LogisticRegression(solver=&#x27;liblinear&#x27;)</pre></div></div></div><div class=\"sk-serial\"><div class=\"sk-item\"><div class=\"sk-estimator fitted sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-3\" type=\"checkbox\" ><label for=\"sk-estimator-id-3\" class=\"sk-toggleable__label fitted sk-toggleable__label-arrow\"><div><div>LogisticRegression</div></div><div><a class=\"sk-estimator-doc-link fitted\" rel=\"noreferrer\" target=\"_blank\" href=\"https://scikit-learn.org/1.7/modules/generated/sklearn.linear_model.LogisticRegression.html\">?<span>Documentation for LogisticRegression</span></a></div></label><div class=\"sk-toggleable__content fitted\" data-param-prefix=\"estimator__\">\n",
       "        <div class=\"estimator-table\">\n",
       "            <details>\n",
       "                <summary>Parameters</summary>\n",
       "                <table class=\"parameters-table\">\n",
       "                  <tbody>\n",
       "                    \n",
       "        <tr class=\"default\">\n",
       "            <td><i class=\"copy-paste-icon\"\n",
       "                 onclick=\"copyToClipboard('penalty',\n",
       "                          this.parentElement.nextElementSibling)\"\n",
       "            ></i></td>\n",
       "            <td class=\"param\">penalty&nbsp;</td>\n",
       "            <td class=\"value\">&#x27;l2&#x27;</td>\n",
       "        </tr>\n",
       "    \n",
       "\n",
       "        <tr class=\"default\">\n",
       "            <td><i class=\"copy-paste-icon\"\n",
       "                 onclick=\"copyToClipboard('dual',\n",
       "                          this.parentElement.nextElementSibling)\"\n",
       "            ></i></td>\n",
       "            <td class=\"param\">dual&nbsp;</td>\n",
       "            <td class=\"value\">False</td>\n",
       "        </tr>\n",
       "    \n",
       "\n",
       "        <tr class=\"default\">\n",
       "            <td><i class=\"copy-paste-icon\"\n",
       "                 onclick=\"copyToClipboard('tol',\n",
       "                          this.parentElement.nextElementSibling)\"\n",
       "            ></i></td>\n",
       "            <td class=\"param\">tol&nbsp;</td>\n",
       "            <td class=\"value\">0.0001</td>\n",
       "        </tr>\n",
       "    \n",
       "\n",
       "        <tr class=\"default\">\n",
       "            <td><i class=\"copy-paste-icon\"\n",
       "                 onclick=\"copyToClipboard('C',\n",
       "                          this.parentElement.nextElementSibling)\"\n",
       "            ></i></td>\n",
       "            <td class=\"param\">C&nbsp;</td>\n",
       "            <td class=\"value\">1.0</td>\n",
       "        </tr>\n",
       "    \n",
       "\n",
       "        <tr class=\"default\">\n",
       "            <td><i class=\"copy-paste-icon\"\n",
       "                 onclick=\"copyToClipboard('fit_intercept',\n",
       "                          this.parentElement.nextElementSibling)\"\n",
       "            ></i></td>\n",
       "            <td class=\"param\">fit_intercept&nbsp;</td>\n",
       "            <td class=\"value\">True</td>\n",
       "        </tr>\n",
       "    \n",
       "\n",
       "        <tr class=\"default\">\n",
       "            <td><i class=\"copy-paste-icon\"\n",
       "                 onclick=\"copyToClipboard('intercept_scaling',\n",
       "                          this.parentElement.nextElementSibling)\"\n",
       "            ></i></td>\n",
       "            <td class=\"param\">intercept_scaling&nbsp;</td>\n",
       "            <td class=\"value\">1</td>\n",
       "        </tr>\n",
       "    \n",
       "\n",
       "        <tr class=\"default\">\n",
       "            <td><i class=\"copy-paste-icon\"\n",
       "                 onclick=\"copyToClipboard('class_weight',\n",
       "                          this.parentElement.nextElementSibling)\"\n",
       "            ></i></td>\n",
       "            <td class=\"param\">class_weight&nbsp;</td>\n",
       "            <td class=\"value\">None</td>\n",
       "        </tr>\n",
       "    \n",
       "\n",
       "        <tr class=\"default\">\n",
       "            <td><i class=\"copy-paste-icon\"\n",
       "                 onclick=\"copyToClipboard('random_state',\n",
       "                          this.parentElement.nextElementSibling)\"\n",
       "            ></i></td>\n",
       "            <td class=\"param\">random_state&nbsp;</td>\n",
       "            <td class=\"value\">None</td>\n",
       "        </tr>\n",
       "    \n",
       "\n",
       "        <tr class=\"user-set\">\n",
       "            <td><i class=\"copy-paste-icon\"\n",
       "                 onclick=\"copyToClipboard('solver',\n",
       "                          this.parentElement.nextElementSibling)\"\n",
       "            ></i></td>\n",
       "            <td class=\"param\">solver&nbsp;</td>\n",
       "            <td class=\"value\">&#x27;liblinear&#x27;</td>\n",
       "        </tr>\n",
       "    \n",
       "\n",
       "        <tr class=\"default\">\n",
       "            <td><i class=\"copy-paste-icon\"\n",
       "                 onclick=\"copyToClipboard('max_iter',\n",
       "                          this.parentElement.nextElementSibling)\"\n",
       "            ></i></td>\n",
       "            <td class=\"param\">max_iter&nbsp;</td>\n",
       "            <td class=\"value\">100</td>\n",
       "        </tr>\n",
       "    \n",
       "\n",
       "        <tr class=\"default\">\n",
       "            <td><i class=\"copy-paste-icon\"\n",
       "                 onclick=\"copyToClipboard('multi_class',\n",
       "                          this.parentElement.nextElementSibling)\"\n",
       "            ></i></td>\n",
       "            <td class=\"param\">multi_class&nbsp;</td>\n",
       "            <td class=\"value\">&#x27;deprecated&#x27;</td>\n",
       "        </tr>\n",
       "    \n",
       "\n",
       "        <tr class=\"default\">\n",
       "            <td><i class=\"copy-paste-icon\"\n",
       "                 onclick=\"copyToClipboard('verbose',\n",
       "                          this.parentElement.nextElementSibling)\"\n",
       "            ></i></td>\n",
       "            <td class=\"param\">verbose&nbsp;</td>\n",
       "            <td class=\"value\">0</td>\n",
       "        </tr>\n",
       "    \n",
       "\n",
       "        <tr class=\"default\">\n",
       "            <td><i class=\"copy-paste-icon\"\n",
       "                 onclick=\"copyToClipboard('warm_start',\n",
       "                          this.parentElement.nextElementSibling)\"\n",
       "            ></i></td>\n",
       "            <td class=\"param\">warm_start&nbsp;</td>\n",
       "            <td class=\"value\">False</td>\n",
       "        </tr>\n",
       "    \n",
       "\n",
       "        <tr class=\"default\">\n",
       "            <td><i class=\"copy-paste-icon\"\n",
       "                 onclick=\"copyToClipboard('n_jobs',\n",
       "                          this.parentElement.nextElementSibling)\"\n",
       "            ></i></td>\n",
       "            <td class=\"param\">n_jobs&nbsp;</td>\n",
       "            <td class=\"value\">None</td>\n",
       "        </tr>\n",
       "    \n",
       "\n",
       "        <tr class=\"default\">\n",
       "            <td><i class=\"copy-paste-icon\"\n",
       "                 onclick=\"copyToClipboard('l1_ratio',\n",
       "                          this.parentElement.nextElementSibling)\"\n",
       "            ></i></td>\n",
       "            <td class=\"param\">l1_ratio&nbsp;</td>\n",
       "            <td class=\"value\">None</td>\n",
       "        </tr>\n",
       "    \n",
       "                  </tbody>\n",
       "                </table>\n",
       "            </details>\n",
       "        </div>\n",
       "    </div></div></div></div></div></div></div></div></div></div><script>function copyToClipboard(text, element) {\n",
       "    // Get the parameter prefix from the closest toggleable content\n",
       "    const toggleableContent = element.closest('.sk-toggleable__content');\n",
       "    const paramPrefix = toggleableContent ? toggleableContent.dataset.paramPrefix : '';\n",
       "    const fullParamName = paramPrefix ? `${paramPrefix}${text}` : text;\n",
       "\n",
       "    const originalStyle = element.style;\n",
       "    const computedStyle = window.getComputedStyle(element);\n",
       "    const originalWidth = computedStyle.width;\n",
       "    const originalHTML = element.innerHTML.replace('Copied!', '');\n",
       "\n",
       "    navigator.clipboard.writeText(fullParamName)\n",
       "        .then(() => {\n",
       "            element.style.width = originalWidth;\n",
       "            element.style.color = 'green';\n",
       "            element.innerHTML = \"Copied!\";\n",
       "\n",
       "            setTimeout(() => {\n",
       "                element.innerHTML = originalHTML;\n",
       "                element.style = originalStyle;\n",
       "            }, 2000);\n",
       "        })\n",
       "        .catch(err => {\n",
       "            console.error('Failed to copy:', err);\n",
       "            element.style.color = 'red';\n",
       "            element.innerHTML = \"Failed!\";\n",
       "            setTimeout(() => {\n",
       "                element.innerHTML = originalHTML;\n",
       "                element.style = originalStyle;\n",
       "            }, 2000);\n",
       "        });\n",
       "    return false;\n",
       "}\n",
       "\n",
       "document.querySelectorAll('.fa-regular.fa-copy').forEach(function(element) {\n",
       "    const toggleableContent = element.closest('.sk-toggleable__content');\n",
       "    const paramPrefix = toggleableContent ? toggleableContent.dataset.paramPrefix : '';\n",
       "    const paramName = element.parentElement.nextElementSibling.textContent.trim();\n",
       "    const fullParamName = paramPrefix ? `${paramPrefix}${paramName}` : paramName;\n",
       "\n",
       "    element.setAttribute('title', fullParamName);\n",
       "});\n",
       "</script></body>"
      ],
      "text/plain": [
       "OneVsRestClassifier(estimator=LogisticRegression(solver='liblinear'))"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.multiclass import OneVsRestClassifier\n",
    "\n",
    "\n",
    "lr = LogisticRegression(solver='liblinear')\n",
    "clf = OneVsRestClassifier(lr)\n",
    "\n",
    "clf.fit(X_train_tfidf, y_train)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "01cf107a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "F1 micro : 0.23770491803278687\n",
      "F1 macro : 0.1698538763928398\n",
      "Hamming loss : 0.03995943902103671\n",
      "                precision    recall  f1-score   support\n",
      "\n",
      "    admiration       0.67      0.27      0.38      1691\n",
      "     amusement       0.61      0.27      0.37       926\n",
      "         anger       0.59      0.11      0.18       861\n",
      "     annoyance       0.37      0.02      0.04      1353\n",
      "      approval       0.54      0.03      0.06      1794\n",
      "        caring       0.50      0.03      0.06       577\n",
      "     confusion       0.66      0.05      0.10       721\n",
      "     curiosity       0.90      0.04      0.07       947\n",
      "        desire       0.50      0.07      0.13       361\n",
      "disappointment       0.61      0.02      0.05       849\n",
      "   disapproval       0.40      0.01      0.02      1184\n",
      "       disgust       0.63      0.08      0.14       550\n",
      " embarrassment       0.58      0.03      0.05       264\n",
      "    excitement       0.70      0.06      0.12       553\n",
      "          fear       0.65      0.16      0.26       318\n",
      "     gratitude       0.89      0.72      0.80      1162\n",
      "         grief       0.00      0.00      0.00        66\n",
      "           joy       0.55      0.11      0.18       779\n",
      "          love       0.64      0.40      0.50       812\n",
      "   nervousness       0.67      0.02      0.04       186\n",
      "      optimism       0.67      0.18      0.28       875\n",
      "         pride       0.62      0.04      0.08       124\n",
      "   realization       0.71      0.01      0.03       870\n",
      "        relief       0.00      0.00      0.00       146\n",
      "       remorse       0.57      0.14      0.23       266\n",
      "       sadness       0.63      0.14      0.24       677\n",
      "      surprise       0.60      0.08      0.14       548\n",
      "       neutral       0.56      0.16      0.25      5484\n",
      "\n",
      "     micro avg       0.65      0.15      0.24     24944\n",
      "     macro avg       0.57      0.12      0.17     24944\n",
      "  weighted avg       0.60      0.15      0.21     24944\n",
      "   samples avg       0.17      0.15      0.16     24944\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\Yann\\Desktop\\DEV\\School\\ml_m1\\NLP\\CustomGPT\\scraper_env\\Lib\\site-packages\\sklearn\\metrics\\_classification.py:1706: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", result.shape[0])\n",
      "c:\\Users\\Yann\\Desktop\\DEV\\School\\ml_m1\\NLP\\CustomGPT\\scraper_env\\Lib\\site-packages\\sklearn\\metrics\\_classification.py:1706: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in samples with no predicted labels. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", result.shape[0])\n"
     ]
    }
   ],
   "source": [
    "from sklearn.metrics import classification_report, f1_score, hamming_loss\n",
    "\n",
    "y_val_pred = clf.predict(X_val_tfidf)\n",
    "\n",
    "print(\"F1 micro :\", f1_score(y_val, y_val_pred, average='micro'))\n",
    "print(\"F1 macro :\", f1_score(y_val, y_val_pred, average='macro'))\n",
    "print(\"Hamming loss :\", hamming_loss(y_val, y_val_pred))\n",
    "\n",
    "# Rapport détaillé\n",
    "print(classification_report(y_val, y_val_pred, target_names=label_cols))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9cd23fc1",
   "metadata": {},
   "source": [
    "###  Analyse des Résultats - TF-IDF + Logistic Regression\n",
    "\n",
    "---\n",
    "\n",
    "#### Résultats globaux\n",
    "\n",
    "| Indicateur       | Valeur    | Interprétation |\n",
    "|------------------|-----------|----------------|\n",
    "| **F1 micro**     | `0.2377`  | Mesure globale sur toutes les émotions, pondérée par fréquence. Correct mais peu discriminant. |\n",
    "| **F1 macro**     | `0.1698`  | Moyenne simple des F1-score pour chaque émotion. Indique que les classes rares sont très mal prédites. |\n",
    "| **Hamming Loss** | `0.0399`  | En moyenne, 3.99% des labels sont mal prédits par exemple. Plus c’est bas, mieux c’est. |\n",
    "\n",
    "---\n",
    "\n",
    "####  Performances par émotion\n",
    "\n",
    "#####  Bonnes performances (précision + rappel équilibrés)\n",
    "\n",
    "| Émotion      | F1-score | Remarques |\n",
    "|--------------|----------|-----------|\n",
    "| `gratitude`  | 0.80     | Très bon — émotion claire et bien représentée |\n",
    "| `love`       | 0.50     | Moyenne correcte — souvent détectée correctement |\n",
    "| `joy`        | 0.18     | Faible mais attendue pour une émotion plus diffuse |\n",
    "\n",
    "---\n",
    "\n",
    "#####  Faibles performances (émotions ignorées ou difficiles)\n",
    "\n",
    "| Émotion         | F1-score | Remarques |\n",
    "|-----------------|----------|-----------|\n",
    "| `grief`         | 0.00     | Trop peu d’exemples pour apprendre correctement |\n",
    "| `disapproval`   | 0.02     | Mauvais rappel malgré une fréquence modérée |\n",
    "| `desire`        | 0.13     | Mal capturée, probablement trop abstraite pour TF-IDF |\n",
    "\n",
    "---\n",
    "\n",
    "####  Analyse qualitative\n",
    "\n",
    "- Le modèle **sous-prédit beaucoup** → rappel très bas\n",
    "- Les émotions les plus simples ou avec des **mots clés explicites** sont mieux détectées (`gratitude`, `excitement`, etc.)\n",
    "- Les émotions **complexes ou peu fréquentes** sont souvent ignorées\n",
    "\n",
    "> Le F1-macro très bas montre que le modèle ne généralise pas bien à toutes les classes.\n",
    "\n",
    "---\n",
    "\n",
    "####  Limites du modèle\n",
    "\n",
    "- **TF-IDF** ne capture pas le sens ni le contexte grammatical\n",
    "- **LogisticRegression (OneVsRest)** ne partage pas d'information entre classes\n",
    "- Modèle **très sensible au déséquilibre** entre les classes\n",
    "\n",
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f0cae952",
   "metadata": {},
   "source": [
    "## Autres modèles classifiers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "4cdb78c5",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.multiclass import OneVsRestClassifier\n",
    "\n",
    "# Initialiser un modèle de forêt aléatoire\n",
    "rf = RandomForestClassifier(n_estimators=100, random_state=42, n_jobs=-1)\n",
    "\n",
    "# Wrapping en OneVsRest pour le multi-label\n",
    "clf_rf = OneVsRestClassifier(rf)\n",
    "\n",
    "# Entraînement\n",
    "clf_rf.fit(X_train_tfidf, y_train)\n",
    "\n",
    "# Prédictions\n",
    "y_val_pred_rf = clf_rf.predict(X_val_tfidf)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "16c488cf",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "F1 micro : 0.3515952143569292\n",
      "F1 macro : 0.27622241218604354\n",
      "Hamming loss : 0.04470988587927953\n",
      "\n",
      "Rapport par classe :\n",
      "                precision    recall  f1-score   support\n",
      "\n",
      "    admiration       0.56      0.42      0.48      1691\n",
      "     amusement       0.54      0.46      0.49       926\n",
      "         anger       0.44      0.23      0.30       861\n",
      "     annoyance       0.24      0.11      0.16      1353\n",
      "      approval       0.32      0.13      0.19      1794\n",
      "        caring       0.28      0.13      0.18       577\n",
      "     confusion       0.34      0.17      0.23       721\n",
      "     curiosity       0.38      0.22      0.28       947\n",
      "        desire       0.31      0.15      0.20       361\n",
      "disappointment       0.25      0.12      0.16       849\n",
      "   disapproval       0.30      0.14      0.19      1184\n",
      "       disgust       0.38      0.17      0.24       550\n",
      " embarrassment       0.26      0.11      0.15       264\n",
      "    excitement       0.35      0.14      0.20       553\n",
      "          fear       0.50      0.29      0.37       318\n",
      "     gratitude       0.84      0.74      0.79      1162\n",
      "         grief       0.30      0.09      0.14        66\n",
      "           joy       0.40      0.21      0.28       779\n",
      "          love       0.61      0.54      0.57       812\n",
      "   nervousness       0.17      0.06      0.09       186\n",
      "      optimism       0.46      0.26      0.33       875\n",
      "         pride       0.33      0.08      0.13       124\n",
      "   realization       0.25      0.09      0.13       870\n",
      "        relief       0.17      0.05      0.08       146\n",
      "       remorse       0.48      0.26      0.34       266\n",
      "       sadness       0.42      0.25      0.31       677\n",
      "      surprise       0.43      0.23      0.30       548\n",
      "       neutral       0.51      0.39      0.44      5484\n",
      "\n",
      "     micro avg       0.46      0.28      0.35     24944\n",
      "     macro avg       0.39      0.22      0.28     24944\n",
      "  weighted avg       0.43      0.28      0.34     24944\n",
      "   samples avg       0.31      0.29      0.29     24944\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\Yann\\Desktop\\DEV\\School\\ml_m1\\NLP\\CustomGPT\\scraper_env\\Lib\\site-packages\\sklearn\\metrics\\_classification.py:1706: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in samples with no predicted labels. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", result.shape[0])\n"
     ]
    }
   ],
   "source": [
    "from sklearn.metrics import f1_score, classification_report, hamming_loss\n",
    "\n",
    "print(\"F1 micro :\", f1_score(y_val, y_val_pred_rf, average='micro'))\n",
    "print(\"F1 macro :\", f1_score(y_val, y_val_pred_rf, average='macro'))\n",
    "print(\"Hamming loss :\", hamming_loss(y_val, y_val_pred_rf))\n",
    "\n",
    "print(\"\\nRapport par classe :\")\n",
    "print(classification_report(y_val, y_val_pred_rf, target_names=label_cols))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b688bce4",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "d1e36240",
   "metadata": {},
   "source": [
    "###   Alternatives à TF-IDF pour la Vectorisation de Texte\n",
    "\n",
    "---\n",
    "\n",
    "####  🔹 1. Bag-of-Words (BoW)\n",
    "\n",
    "📌 **Description**  \n",
    "Simple comptage d’occurrences des mots  \n",
    "Pas de pondération (contrairement au TF-IDF)\n",
    "\n",
    "\n",
    "from sklearn.feature_extraction.text import CountVectorizer\n",
    "vectorizer = CountVectorizer(max_features=10000, ngram_range=(1,2), stop_words='english')\n",
    "X = vectorizer.fit_transform(X_train)\n",
    "\n",
    " Simple\n",
    " Ne tient pas compte de l’importance relative des mots\n",
    "\n",
    "####   🔹 2. Word Embeddings Moyennés\n",
    "📌 Description\n",
    "Moyenne des vecteurs de mots pré-entraînés (ex: GloVe, FastText, Word2Vec)\n",
    "\n",
    "import numpy as np\n",
    "import gensim.downloader as api\n",
    "\n",
    "#####   Charger un modèle GloVe ou FastText\n",
    "glove = api.load(\"glove-wiki-gigaword-100\")  # 100 dimensions\n",
    "\n",
    "def vectorize_avg(text):\n",
    "    words = text.lower().split()\n",
    "    vectors = [glove[word] for word in words if word in glove]\n",
    "    return np.mean(vectors, axis=0) if vectors else np.zeros(100)\n",
    "\n",
    "X_train_embed = np.array([vectorize_avg(t) for t in X_train])\n",
    "✅ Vecteurs denses, conserve un peu de sens\n",
    "❌ Perte de l’ordre, dépend du modèle choisi\n",
    "\n",
    "####  3. Doc2Vec (gensim)\n",
    "📌 Description\n",
    "Crée un vecteur de document entier, entraîné sur le corpus\n",
    "Basé sur Word2Vec + contexte global\n",
    "\n",
    "from gensim.models.doc2vec import Doc2Vec, TaggedDocument\n",
    "\n",
    "tagged_docs = [TaggedDocument(words=text.lower().split(), tags=[i]) for i, text in enumerate(X_train)]\n",
    "model = Doc2Vec(tagged_docs, vector_size=100, epochs=20)\n",
    "\n",
    "X_train_vec = np.array([model.infer_vector(t.words) for t in tagged_docs])\n",
    "✅ Encode mieux le contexte document\n",
    "❌ Long à entraîner, dépend du volume\n",
    "\n",
    "####  🔹 4. Sentence Embeddings (BERT-like)\n",
    "📌 Description\n",
    "Utilise des modèles de type Sentence-BERT ou USE pour obtenir un vecteur sémantique dense du texte entier\n",
    "\n",
    "Exemple avec Sentence-BERT :\n",
    "\n",
    "from sentence_transformers import SentenceTransformer\n",
    "\n",
    "model = SentenceTransformer('all-MiniLM-L6-v2')\n",
    "X_train_sbert = model.encode(X_train, show_progress_bar=True)\n",
    "✅ Très puissant pour la sémantique\n",
    "✅ Fonctionne bien en downstream task (multi-label)\n",
    "❌ Plus lent et demande des ressources\n",
    "\n",
    "#### 🔹 5. Transformer Fine-Tuning (End-to-End)\n",
    "📌 Description\n",
    "Pas une \"vectorisation\" mais plutôt un fine-tuning complet\n",
    "On entraîne le modèle comme un classifieur\n",
    "\n",
    "from transformers import AutoTokenizer, AutoModelForSequenceClassification\n",
    "#####  Exemple : \"roberta-base\" ou \"distilbert-base-uncased\"\n",
    " Meilleures performances globales\n",
    " Nécessite GPU pour entraînement efficace\n",
    "\n",
    "#### 🧪 Comparatif résumé\n",
    "\n",
    "| Méthode                  | Dense ? | Sémantique ? | Ordre ? | Performance |\n",
    "|--------------------------|---------|--------------|---------|-------------|\n",
    "| **BoW / TF-IDF**         | ❌       | ❌            | ❌       | Moyen        |\n",
    "| **Embeddings Moyens**    | ✅       | 🟡            | ❌       | Moyen+       |\n",
    "| **Doc2Vec**              | ✅       | ✅            | ✅       | Bon          |\n",
    "| **Sentence-BERT / USE**  | ✅       | ✅✅           | ✅       | Très bon     |\n",
    "| **Transformer Fine-Tune**| ✅       | ✅✅✅          | ✅       | Excellent    |\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ee9b6cd2",
   "metadata": {},
   "source": [
    "# Véctorization + Transformers léger"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "badf540e",
   "metadata": {},
   "source": [
    "Objectif : capturer plus de sens, sans faire du finetuning"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fe786d19",
   "metadata": {},
   "source": [
    "## Récupération du jeu de données"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "b9b949cb",
   "metadata": {},
   "outputs": [],
   "source": [
    "label_cols = [col for col in df.columns if col not in ['id', 'text', 'example_very_unclear', 'num_labels', 'text_length']]\n",
    "\n",
    "X_train = df_train['text'].tolist()\n",
    "y_train = df_train[label_cols].values\n",
    "\n",
    "X_val = df_val['text'].tolist()\n",
    "y_val = df_val[label_cols].values\n",
    "\n",
    "X_test = df_test['text'].tolist()\n",
    "y_test = df_test[label_cols].values\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "419aa872",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "ef4a1bc6",
   "metadata": {},
   "source": [
    "### remarques\n",
    "\n",
    "Sentence-BERT = BERT + pooling → encoder de manière sémantique le texte entier.\n",
    "Il doit recevoir le texte brut, tel qu’il est écrit, pour fonctionner comme prévu.\n",
    "\n",
    "si je fais du nettoyage comme je l'ai pour TF-IDF, je risque de dégrader ses performances."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "da5eca0d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: transformers in c:\\users\\yann\\anaconda3\\envs\\hf_gpu_env\\lib\\site-packages (4.41.2)\n",
      "Requirement already satisfied: filelock in c:\\users\\yann\\anaconda3\\envs\\hf_gpu_env\\lib\\site-packages (from transformers) (3.13.1)\n",
      "Requirement already satisfied: huggingface-hub<1.0,>=0.23.0 in c:\\users\\yann\\anaconda3\\envs\\hf_gpu_env\\lib\\site-packages (from transformers) (0.33.2)\n",
      "Requirement already satisfied: numpy>=1.17 in c:\\users\\yann\\anaconda3\\envs\\hf_gpu_env\\lib\\site-packages (from transformers) (2.1.2)\n",
      "Requirement already satisfied: packaging>=20.0 in c:\\users\\yann\\anaconda3\\envs\\hf_gpu_env\\lib\\site-packages (from transformers) (25.0)\n",
      "Requirement already satisfied: pyyaml>=5.1 in c:\\users\\yann\\anaconda3\\envs\\hf_gpu_env\\lib\\site-packages (from transformers) (6.0.2)\n",
      "Requirement already satisfied: regex!=2019.12.17 in c:\\users\\yann\\anaconda3\\envs\\hf_gpu_env\\lib\\site-packages (from transformers) (2024.11.6)\n",
      "Requirement already satisfied: requests in c:\\users\\yann\\anaconda3\\envs\\hf_gpu_env\\lib\\site-packages (from transformers) (2.32.4)\n",
      "Requirement already satisfied: tokenizers<0.20,>=0.19 in c:\\users\\yann\\anaconda3\\envs\\hf_gpu_env\\lib\\site-packages (from transformers) (0.19.1)\n",
      "Requirement already satisfied: safetensors>=0.4.1 in c:\\users\\yann\\anaconda3\\envs\\hf_gpu_env\\lib\\site-packages (from transformers) (0.5.3)\n",
      "Requirement already satisfied: tqdm>=4.27 in c:\\users\\yann\\anaconda3\\envs\\hf_gpu_env\\lib\\site-packages (from transformers) (4.67.1)\n",
      "Requirement already satisfied: fsspec>=2023.5.0 in c:\\users\\yann\\anaconda3\\envs\\hf_gpu_env\\lib\\site-packages (from huggingface-hub<1.0,>=0.23.0->transformers) (2024.6.1)\n",
      "Requirement already satisfied: typing-extensions>=3.7.4.3 in c:\\users\\yann\\anaconda3\\envs\\hf_gpu_env\\lib\\site-packages (from huggingface-hub<1.0,>=0.23.0->transformers) (4.12.2)\n",
      "Requirement already satisfied: colorama in c:\\users\\yann\\anaconda3\\envs\\hf_gpu_env\\lib\\site-packages (from tqdm>=4.27->transformers) (0.4.6)\n",
      "Requirement already satisfied: charset_normalizer<4,>=2 in c:\\users\\yann\\anaconda3\\envs\\hf_gpu_env\\lib\\site-packages (from requests->transformers) (3.4.2)\n",
      "Requirement already satisfied: idna<4,>=2.5 in c:\\users\\yann\\anaconda3\\envs\\hf_gpu_env\\lib\\site-packages (from requests->transformers) (3.10)\n",
      "Requirement already satisfied: urllib3<3,>=1.21.1 in c:\\users\\yann\\anaconda3\\envs\\hf_gpu_env\\lib\\site-packages (from requests->transformers) (2.5.0)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in c:\\users\\yann\\anaconda3\\envs\\hf_gpu_env\\lib\\site-packages (from requests->transformers) (2025.6.15)\n",
      "Collecting sentence-transformers\n",
      "  Using cached sentence_transformers-5.0.0-py3-none-any.whl.metadata (16 kB)\n",
      "Requirement already satisfied: transformers<5.0.0,>=4.41.0 in c:\\users\\yann\\anaconda3\\envs\\hf_gpu_env\\lib\\site-packages (from sentence-transformers) (4.41.2)\n",
      "Requirement already satisfied: tqdm in c:\\users\\yann\\anaconda3\\envs\\hf_gpu_env\\lib\\site-packages (from sentence-transformers) (4.67.1)\n",
      "Requirement already satisfied: torch>=1.11.0 in c:\\users\\yann\\anaconda3\\envs\\hf_gpu_env\\lib\\site-packages (from sentence-transformers) (2.5.1+cu121)\n",
      "Requirement already satisfied: scikit-learn in c:\\users\\yann\\anaconda3\\envs\\hf_gpu_env\\lib\\site-packages (from sentence-transformers) (1.7.0)\n",
      "Requirement already satisfied: scipy in c:\\users\\yann\\anaconda3\\envs\\hf_gpu_env\\lib\\site-packages (from sentence-transformers) (1.15.3)\n",
      "Requirement already satisfied: huggingface-hub>=0.20.0 in c:\\users\\yann\\anaconda3\\envs\\hf_gpu_env\\lib\\site-packages (from sentence-transformers) (0.33.2)\n",
      "Requirement already satisfied: Pillow in c:\\users\\yann\\anaconda3\\envs\\hf_gpu_env\\lib\\site-packages (from sentence-transformers) (11.0.0)\n",
      "Requirement already satisfied: typing_extensions>=4.5.0 in c:\\users\\yann\\anaconda3\\envs\\hf_gpu_env\\lib\\site-packages (from sentence-transformers) (4.12.2)\n",
      "Requirement already satisfied: filelock in c:\\users\\yann\\anaconda3\\envs\\hf_gpu_env\\lib\\site-packages (from transformers<5.0.0,>=4.41.0->sentence-transformers) (3.13.1)\n",
      "Requirement already satisfied: numpy>=1.17 in c:\\users\\yann\\anaconda3\\envs\\hf_gpu_env\\lib\\site-packages (from transformers<5.0.0,>=4.41.0->sentence-transformers) (2.1.2)\n",
      "Requirement already satisfied: packaging>=20.0 in c:\\users\\yann\\anaconda3\\envs\\hf_gpu_env\\lib\\site-packages (from transformers<5.0.0,>=4.41.0->sentence-transformers) (25.0)\n",
      "Requirement already satisfied: pyyaml>=5.1 in c:\\users\\yann\\anaconda3\\envs\\hf_gpu_env\\lib\\site-packages (from transformers<5.0.0,>=4.41.0->sentence-transformers) (6.0.2)\n",
      "Requirement already satisfied: regex!=2019.12.17 in c:\\users\\yann\\anaconda3\\envs\\hf_gpu_env\\lib\\site-packages (from transformers<5.0.0,>=4.41.0->sentence-transformers) (2024.11.6)\n",
      "Requirement already satisfied: requests in c:\\users\\yann\\anaconda3\\envs\\hf_gpu_env\\lib\\site-packages (from transformers<5.0.0,>=4.41.0->sentence-transformers) (2.32.4)\n",
      "Requirement already satisfied: tokenizers<0.20,>=0.19 in c:\\users\\yann\\anaconda3\\envs\\hf_gpu_env\\lib\\site-packages (from transformers<5.0.0,>=4.41.0->sentence-transformers) (0.19.1)\n",
      "Requirement already satisfied: safetensors>=0.4.1 in c:\\users\\yann\\anaconda3\\envs\\hf_gpu_env\\lib\\site-packages (from transformers<5.0.0,>=4.41.0->sentence-transformers) (0.5.3)\n",
      "Requirement already satisfied: fsspec>=2023.5.0 in c:\\users\\yann\\anaconda3\\envs\\hf_gpu_env\\lib\\site-packages (from huggingface-hub>=0.20.0->sentence-transformers) (2024.6.1)\n",
      "Requirement already satisfied: networkx in c:\\users\\yann\\anaconda3\\envs\\hf_gpu_env\\lib\\site-packages (from torch>=1.11.0->sentence-transformers) (3.3)\n",
      "Requirement already satisfied: jinja2 in c:\\users\\yann\\anaconda3\\envs\\hf_gpu_env\\lib\\site-packages (from torch>=1.11.0->sentence-transformers) (3.1.4)\n",
      "Requirement already satisfied: sympy==1.13.1 in c:\\users\\yann\\anaconda3\\envs\\hf_gpu_env\\lib\\site-packages (from torch>=1.11.0->sentence-transformers) (1.13.1)\n",
      "Requirement already satisfied: mpmath<1.4,>=1.1.0 in c:\\users\\yann\\anaconda3\\envs\\hf_gpu_env\\lib\\site-packages (from sympy==1.13.1->torch>=1.11.0->sentence-transformers) (1.3.0)\n",
      "Requirement already satisfied: colorama in c:\\users\\yann\\anaconda3\\envs\\hf_gpu_env\\lib\\site-packages (from tqdm->sentence-transformers) (0.4.6)\n",
      "Requirement already satisfied: MarkupSafe>=2.0 in c:\\users\\yann\\anaconda3\\envs\\hf_gpu_env\\lib\\site-packages (from jinja2->torch>=1.11.0->sentence-transformers) (2.1.5)\n",
      "Requirement already satisfied: charset_normalizer<4,>=2 in c:\\users\\yann\\anaconda3\\envs\\hf_gpu_env\\lib\\site-packages (from requests->transformers<5.0.0,>=4.41.0->sentence-transformers) (3.4.2)\n",
      "Requirement already satisfied: idna<4,>=2.5 in c:\\users\\yann\\anaconda3\\envs\\hf_gpu_env\\lib\\site-packages (from requests->transformers<5.0.0,>=4.41.0->sentence-transformers) (3.10)\n",
      "Requirement already satisfied: urllib3<3,>=1.21.1 in c:\\users\\yann\\anaconda3\\envs\\hf_gpu_env\\lib\\site-packages (from requests->transformers<5.0.0,>=4.41.0->sentence-transformers) (2.5.0)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in c:\\users\\yann\\anaconda3\\envs\\hf_gpu_env\\lib\\site-packages (from requests->transformers<5.0.0,>=4.41.0->sentence-transformers) (2025.6.15)\n",
      "Requirement already satisfied: joblib>=1.2.0 in c:\\users\\yann\\anaconda3\\envs\\hf_gpu_env\\lib\\site-packages (from scikit-learn->sentence-transformers) (1.5.1)\n",
      "Requirement already satisfied: threadpoolctl>=3.1.0 in c:\\users\\yann\\anaconda3\\envs\\hf_gpu_env\\lib\\site-packages (from scikit-learn->sentence-transformers) (3.6.0)\n",
      "Using cached sentence_transformers-5.0.0-py3-none-any.whl (470 kB)\n",
      "Installing collected packages: sentence-transformers\n",
      "Successfully installed sentence-transformers-5.0.0\n"
     ]
    }
   ],
   "source": [
    "!pip install transformers\n",
    "!pip install sentence-transformers\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fae52521",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "e964d636",
   "metadata": {},
   "source": [
    "### Vectorizaition via transformers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "49e92803",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "c7b3ada91b5d4042b4ede44915e33a0d",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Batches:   0%|          | 0/5196 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "7da1aa54b30a4801a1551e6560d05288",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Batches:   0%|          | 0/650 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "f5678649a0c74624b22752ecd41ced93",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Batches:   0%|          | 0/650 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "from sentence_transformers import SentenceTransformer\n",
    "\n",
    "# Charger un modèle rapide et performant\n",
    "sbert_model = SentenceTransformer('all-MiniLM-L6-v2')  # 384 dimensions\n",
    "\n",
    "# Encoder les textes (⚠️ ça peut prendre quelques minutes)\n",
    "X_train_sbert = sbert_model.encode(X_train, show_progress_bar=True, batch_size=32)\n",
    "X_val_sbert = sbert_model.encode(X_val, show_progress_bar=True, batch_size=32)\n",
    "X_test_sbert = sbert_model.encode(X_test, show_progress_bar=True, batch_size=32)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4fd2783d",
   "metadata": {},
   "source": [
    "### entrainement modele"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "d224e9c0",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<style>#sk-container-id-2 {\n",
       "  /* Definition of color scheme common for light and dark mode */\n",
       "  --sklearn-color-text: #000;\n",
       "  --sklearn-color-text-muted: #666;\n",
       "  --sklearn-color-line: gray;\n",
       "  /* Definition of color scheme for unfitted estimators */\n",
       "  --sklearn-color-unfitted-level-0: #fff5e6;\n",
       "  --sklearn-color-unfitted-level-1: #f6e4d2;\n",
       "  --sklearn-color-unfitted-level-2: #ffe0b3;\n",
       "  --sklearn-color-unfitted-level-3: chocolate;\n",
       "  /* Definition of color scheme for fitted estimators */\n",
       "  --sklearn-color-fitted-level-0: #f0f8ff;\n",
       "  --sklearn-color-fitted-level-1: #d4ebff;\n",
       "  --sklearn-color-fitted-level-2: #b3dbfd;\n",
       "  --sklearn-color-fitted-level-3: cornflowerblue;\n",
       "\n",
       "  /* Specific color for light theme */\n",
       "  --sklearn-color-text-on-default-background: var(--sg-text-color, var(--theme-code-foreground, var(--jp-content-font-color1, black)));\n",
       "  --sklearn-color-background: var(--sg-background-color, var(--theme-background, var(--jp-layout-color0, white)));\n",
       "  --sklearn-color-border-box: var(--sg-text-color, var(--theme-code-foreground, var(--jp-content-font-color1, black)));\n",
       "  --sklearn-color-icon: #696969;\n",
       "\n",
       "  @media (prefers-color-scheme: dark) {\n",
       "    /* Redefinition of color scheme for dark theme */\n",
       "    --sklearn-color-text-on-default-background: var(--sg-text-color, var(--theme-code-foreground, var(--jp-content-font-color1, white)));\n",
       "    --sklearn-color-background: var(--sg-background-color, var(--theme-background, var(--jp-layout-color0, #111)));\n",
       "    --sklearn-color-border-box: var(--sg-text-color, var(--theme-code-foreground, var(--jp-content-font-color1, white)));\n",
       "    --sklearn-color-icon: #878787;\n",
       "  }\n",
       "}\n",
       "\n",
       "#sk-container-id-2 {\n",
       "  color: var(--sklearn-color-text);\n",
       "}\n",
       "\n",
       "#sk-container-id-2 pre {\n",
       "  padding: 0;\n",
       "}\n",
       "\n",
       "#sk-container-id-2 input.sk-hidden--visually {\n",
       "  border: 0;\n",
       "  clip: rect(1px 1px 1px 1px);\n",
       "  clip: rect(1px, 1px, 1px, 1px);\n",
       "  height: 1px;\n",
       "  margin: -1px;\n",
       "  overflow: hidden;\n",
       "  padding: 0;\n",
       "  position: absolute;\n",
       "  width: 1px;\n",
       "}\n",
       "\n",
       "#sk-container-id-2 div.sk-dashed-wrapped {\n",
       "  border: 1px dashed var(--sklearn-color-line);\n",
       "  margin: 0 0.4em 0.5em 0.4em;\n",
       "  box-sizing: border-box;\n",
       "  padding-bottom: 0.4em;\n",
       "  background-color: var(--sklearn-color-background);\n",
       "}\n",
       "\n",
       "#sk-container-id-2 div.sk-container {\n",
       "  /* jupyter's `normalize.less` sets `[hidden] { display: none; }`\n",
       "     but bootstrap.min.css set `[hidden] { display: none !important; }`\n",
       "     so we also need the `!important` here to be able to override the\n",
       "     default hidden behavior on the sphinx rendered scikit-learn.org.\n",
       "     See: https://github.com/scikit-learn/scikit-learn/issues/21755 */\n",
       "  display: inline-block !important;\n",
       "  position: relative;\n",
       "}\n",
       "\n",
       "#sk-container-id-2 div.sk-text-repr-fallback {\n",
       "  display: none;\n",
       "}\n",
       "\n",
       "div.sk-parallel-item,\n",
       "div.sk-serial,\n",
       "div.sk-item {\n",
       "  /* draw centered vertical line to link estimators */\n",
       "  background-image: linear-gradient(var(--sklearn-color-text-on-default-background), var(--sklearn-color-text-on-default-background));\n",
       "  background-size: 2px 100%;\n",
       "  background-repeat: no-repeat;\n",
       "  background-position: center center;\n",
       "}\n",
       "\n",
       "/* Parallel-specific style estimator block */\n",
       "\n",
       "#sk-container-id-2 div.sk-parallel-item::after {\n",
       "  content: \"\";\n",
       "  width: 100%;\n",
       "  border-bottom: 2px solid var(--sklearn-color-text-on-default-background);\n",
       "  flex-grow: 1;\n",
       "}\n",
       "\n",
       "#sk-container-id-2 div.sk-parallel {\n",
       "  display: flex;\n",
       "  align-items: stretch;\n",
       "  justify-content: center;\n",
       "  background-color: var(--sklearn-color-background);\n",
       "  position: relative;\n",
       "}\n",
       "\n",
       "#sk-container-id-2 div.sk-parallel-item {\n",
       "  display: flex;\n",
       "  flex-direction: column;\n",
       "}\n",
       "\n",
       "#sk-container-id-2 div.sk-parallel-item:first-child::after {\n",
       "  align-self: flex-end;\n",
       "  width: 50%;\n",
       "}\n",
       "\n",
       "#sk-container-id-2 div.sk-parallel-item:last-child::after {\n",
       "  align-self: flex-start;\n",
       "  width: 50%;\n",
       "}\n",
       "\n",
       "#sk-container-id-2 div.sk-parallel-item:only-child::after {\n",
       "  width: 0;\n",
       "}\n",
       "\n",
       "/* Serial-specific style estimator block */\n",
       "\n",
       "#sk-container-id-2 div.sk-serial {\n",
       "  display: flex;\n",
       "  flex-direction: column;\n",
       "  align-items: center;\n",
       "  background-color: var(--sklearn-color-background);\n",
       "  padding-right: 1em;\n",
       "  padding-left: 1em;\n",
       "}\n",
       "\n",
       "\n",
       "/* Toggleable style: style used for estimator/Pipeline/ColumnTransformer box that is\n",
       "clickable and can be expanded/collapsed.\n",
       "- Pipeline and ColumnTransformer use this feature and define the default style\n",
       "- Estimators will overwrite some part of the style using the `sk-estimator` class\n",
       "*/\n",
       "\n",
       "/* Pipeline and ColumnTransformer style (default) */\n",
       "\n",
       "#sk-container-id-2 div.sk-toggleable {\n",
       "  /* Default theme specific background. It is overwritten whether we have a\n",
       "  specific estimator or a Pipeline/ColumnTransformer */\n",
       "  background-color: var(--sklearn-color-background);\n",
       "}\n",
       "\n",
       "/* Toggleable label */\n",
       "#sk-container-id-2 label.sk-toggleable__label {\n",
       "  cursor: pointer;\n",
       "  display: flex;\n",
       "  width: 100%;\n",
       "  margin-bottom: 0;\n",
       "  padding: 0.5em;\n",
       "  box-sizing: border-box;\n",
       "  text-align: center;\n",
       "  align-items: start;\n",
       "  justify-content: space-between;\n",
       "  gap: 0.5em;\n",
       "}\n",
       "\n",
       "#sk-container-id-2 label.sk-toggleable__label .caption {\n",
       "  font-size: 0.6rem;\n",
       "  font-weight: lighter;\n",
       "  color: var(--sklearn-color-text-muted);\n",
       "}\n",
       "\n",
       "#sk-container-id-2 label.sk-toggleable__label-arrow:before {\n",
       "  /* Arrow on the left of the label */\n",
       "  content: \"▸\";\n",
       "  float: left;\n",
       "  margin-right: 0.25em;\n",
       "  color: var(--sklearn-color-icon);\n",
       "}\n",
       "\n",
       "#sk-container-id-2 label.sk-toggleable__label-arrow:hover:before {\n",
       "  color: var(--sklearn-color-text);\n",
       "}\n",
       "\n",
       "/* Toggleable content - dropdown */\n",
       "\n",
       "#sk-container-id-2 div.sk-toggleable__content {\n",
       "  display: none;\n",
       "  text-align: left;\n",
       "  /* unfitted */\n",
       "  background-color: var(--sklearn-color-unfitted-level-0);\n",
       "}\n",
       "\n",
       "#sk-container-id-2 div.sk-toggleable__content.fitted {\n",
       "  /* fitted */\n",
       "  background-color: var(--sklearn-color-fitted-level-0);\n",
       "}\n",
       "\n",
       "#sk-container-id-2 div.sk-toggleable__content pre {\n",
       "  margin: 0.2em;\n",
       "  border-radius: 0.25em;\n",
       "  color: var(--sklearn-color-text);\n",
       "  /* unfitted */\n",
       "  background-color: var(--sklearn-color-unfitted-level-0);\n",
       "}\n",
       "\n",
       "#sk-container-id-2 div.sk-toggleable__content.fitted pre {\n",
       "  /* unfitted */\n",
       "  background-color: var(--sklearn-color-fitted-level-0);\n",
       "}\n",
       "\n",
       "#sk-container-id-2 input.sk-toggleable__control:checked~div.sk-toggleable__content {\n",
       "  /* Expand drop-down */\n",
       "  display: block;\n",
       "  width: 100%;\n",
       "  overflow: visible;\n",
       "}\n",
       "\n",
       "#sk-container-id-2 input.sk-toggleable__control:checked~label.sk-toggleable__label-arrow:before {\n",
       "  content: \"▾\";\n",
       "}\n",
       "\n",
       "/* Pipeline/ColumnTransformer-specific style */\n",
       "\n",
       "#sk-container-id-2 div.sk-label input.sk-toggleable__control:checked~label.sk-toggleable__label {\n",
       "  color: var(--sklearn-color-text);\n",
       "  background-color: var(--sklearn-color-unfitted-level-2);\n",
       "}\n",
       "\n",
       "#sk-container-id-2 div.sk-label.fitted input.sk-toggleable__control:checked~label.sk-toggleable__label {\n",
       "  background-color: var(--sklearn-color-fitted-level-2);\n",
       "}\n",
       "\n",
       "/* Estimator-specific style */\n",
       "\n",
       "/* Colorize estimator box */\n",
       "#sk-container-id-2 div.sk-estimator input.sk-toggleable__control:checked~label.sk-toggleable__label {\n",
       "  /* unfitted */\n",
       "  background-color: var(--sklearn-color-unfitted-level-2);\n",
       "}\n",
       "\n",
       "#sk-container-id-2 div.sk-estimator.fitted input.sk-toggleable__control:checked~label.sk-toggleable__label {\n",
       "  /* fitted */\n",
       "  background-color: var(--sklearn-color-fitted-level-2);\n",
       "}\n",
       "\n",
       "#sk-container-id-2 div.sk-label label.sk-toggleable__label,\n",
       "#sk-container-id-2 div.sk-label label {\n",
       "  /* The background is the default theme color */\n",
       "  color: var(--sklearn-color-text-on-default-background);\n",
       "}\n",
       "\n",
       "/* On hover, darken the color of the background */\n",
       "#sk-container-id-2 div.sk-label:hover label.sk-toggleable__label {\n",
       "  color: var(--sklearn-color-text);\n",
       "  background-color: var(--sklearn-color-unfitted-level-2);\n",
       "}\n",
       "\n",
       "/* Label box, darken color on hover, fitted */\n",
       "#sk-container-id-2 div.sk-label.fitted:hover label.sk-toggleable__label.fitted {\n",
       "  color: var(--sklearn-color-text);\n",
       "  background-color: var(--sklearn-color-fitted-level-2);\n",
       "}\n",
       "\n",
       "/* Estimator label */\n",
       "\n",
       "#sk-container-id-2 div.sk-label label {\n",
       "  font-family: monospace;\n",
       "  font-weight: bold;\n",
       "  display: inline-block;\n",
       "  line-height: 1.2em;\n",
       "}\n",
       "\n",
       "#sk-container-id-2 div.sk-label-container {\n",
       "  text-align: center;\n",
       "}\n",
       "\n",
       "/* Estimator-specific */\n",
       "#sk-container-id-2 div.sk-estimator {\n",
       "  font-family: monospace;\n",
       "  border: 1px dotted var(--sklearn-color-border-box);\n",
       "  border-radius: 0.25em;\n",
       "  box-sizing: border-box;\n",
       "  margin-bottom: 0.5em;\n",
       "  /* unfitted */\n",
       "  background-color: var(--sklearn-color-unfitted-level-0);\n",
       "}\n",
       "\n",
       "#sk-container-id-2 div.sk-estimator.fitted {\n",
       "  /* fitted */\n",
       "  background-color: var(--sklearn-color-fitted-level-0);\n",
       "}\n",
       "\n",
       "/* on hover */\n",
       "#sk-container-id-2 div.sk-estimator:hover {\n",
       "  /* unfitted */\n",
       "  background-color: var(--sklearn-color-unfitted-level-2);\n",
       "}\n",
       "\n",
       "#sk-container-id-2 div.sk-estimator.fitted:hover {\n",
       "  /* fitted */\n",
       "  background-color: var(--sklearn-color-fitted-level-2);\n",
       "}\n",
       "\n",
       "/* Specification for estimator info (e.g. \"i\" and \"?\") */\n",
       "\n",
       "/* Common style for \"i\" and \"?\" */\n",
       "\n",
       ".sk-estimator-doc-link,\n",
       "a:link.sk-estimator-doc-link,\n",
       "a:visited.sk-estimator-doc-link {\n",
       "  float: right;\n",
       "  font-size: smaller;\n",
       "  line-height: 1em;\n",
       "  font-family: monospace;\n",
       "  background-color: var(--sklearn-color-background);\n",
       "  border-radius: 1em;\n",
       "  height: 1em;\n",
       "  width: 1em;\n",
       "  text-decoration: none !important;\n",
       "  margin-left: 0.5em;\n",
       "  text-align: center;\n",
       "  /* unfitted */\n",
       "  border: var(--sklearn-color-unfitted-level-1) 1pt solid;\n",
       "  color: var(--sklearn-color-unfitted-level-1);\n",
       "}\n",
       "\n",
       ".sk-estimator-doc-link.fitted,\n",
       "a:link.sk-estimator-doc-link.fitted,\n",
       "a:visited.sk-estimator-doc-link.fitted {\n",
       "  /* fitted */\n",
       "  border: var(--sklearn-color-fitted-level-1) 1pt solid;\n",
       "  color: var(--sklearn-color-fitted-level-1);\n",
       "}\n",
       "\n",
       "/* On hover */\n",
       "div.sk-estimator:hover .sk-estimator-doc-link:hover,\n",
       ".sk-estimator-doc-link:hover,\n",
       "div.sk-label-container:hover .sk-estimator-doc-link:hover,\n",
       ".sk-estimator-doc-link:hover {\n",
       "  /* unfitted */\n",
       "  background-color: var(--sklearn-color-unfitted-level-3);\n",
       "  color: var(--sklearn-color-background);\n",
       "  text-decoration: none;\n",
       "}\n",
       "\n",
       "div.sk-estimator.fitted:hover .sk-estimator-doc-link.fitted:hover,\n",
       ".sk-estimator-doc-link.fitted:hover,\n",
       "div.sk-label-container:hover .sk-estimator-doc-link.fitted:hover,\n",
       ".sk-estimator-doc-link.fitted:hover {\n",
       "  /* fitted */\n",
       "  background-color: var(--sklearn-color-fitted-level-3);\n",
       "  color: var(--sklearn-color-background);\n",
       "  text-decoration: none;\n",
       "}\n",
       "\n",
       "/* Span, style for the box shown on hovering the info icon */\n",
       ".sk-estimator-doc-link span {\n",
       "  display: none;\n",
       "  z-index: 9999;\n",
       "  position: relative;\n",
       "  font-weight: normal;\n",
       "  right: .2ex;\n",
       "  padding: .5ex;\n",
       "  margin: .5ex;\n",
       "  width: min-content;\n",
       "  min-width: 20ex;\n",
       "  max-width: 50ex;\n",
       "  color: var(--sklearn-color-text);\n",
       "  box-shadow: 2pt 2pt 4pt #999;\n",
       "  /* unfitted */\n",
       "  background: var(--sklearn-color-unfitted-level-0);\n",
       "  border: .5pt solid var(--sklearn-color-unfitted-level-3);\n",
       "}\n",
       "\n",
       ".sk-estimator-doc-link.fitted span {\n",
       "  /* fitted */\n",
       "  background: var(--sklearn-color-fitted-level-0);\n",
       "  border: var(--sklearn-color-fitted-level-3);\n",
       "}\n",
       "\n",
       ".sk-estimator-doc-link:hover span {\n",
       "  display: block;\n",
       "}\n",
       "\n",
       "/* \"?\"-specific style due to the `<a>` HTML tag */\n",
       "\n",
       "#sk-container-id-2 a.estimator_doc_link {\n",
       "  float: right;\n",
       "  font-size: 1rem;\n",
       "  line-height: 1em;\n",
       "  font-family: monospace;\n",
       "  background-color: var(--sklearn-color-background);\n",
       "  border-radius: 1rem;\n",
       "  height: 1rem;\n",
       "  width: 1rem;\n",
       "  text-decoration: none;\n",
       "  /* unfitted */\n",
       "  color: var(--sklearn-color-unfitted-level-1);\n",
       "  border: var(--sklearn-color-unfitted-level-1) 1pt solid;\n",
       "}\n",
       "\n",
       "#sk-container-id-2 a.estimator_doc_link.fitted {\n",
       "  /* fitted */\n",
       "  border: var(--sklearn-color-fitted-level-1) 1pt solid;\n",
       "  color: var(--sklearn-color-fitted-level-1);\n",
       "}\n",
       "\n",
       "/* On hover */\n",
       "#sk-container-id-2 a.estimator_doc_link:hover {\n",
       "  /* unfitted */\n",
       "  background-color: var(--sklearn-color-unfitted-level-3);\n",
       "  color: var(--sklearn-color-background);\n",
       "  text-decoration: none;\n",
       "}\n",
       "\n",
       "#sk-container-id-2 a.estimator_doc_link.fitted:hover {\n",
       "  /* fitted */\n",
       "  background-color: var(--sklearn-color-fitted-level-3);\n",
       "}\n",
       "\n",
       ".estimator-table summary {\n",
       "    padding: .5rem;\n",
       "    font-family: monospace;\n",
       "    cursor: pointer;\n",
       "}\n",
       "\n",
       ".estimator-table details[open] {\n",
       "    padding-left: 0.1rem;\n",
       "    padding-right: 0.1rem;\n",
       "    padding-bottom: 0.3rem;\n",
       "}\n",
       "\n",
       ".estimator-table .parameters-table {\n",
       "    margin-left: auto !important;\n",
       "    margin-right: auto !important;\n",
       "}\n",
       "\n",
       ".estimator-table .parameters-table tr:nth-child(odd) {\n",
       "    background-color: #fff;\n",
       "}\n",
       "\n",
       ".estimator-table .parameters-table tr:nth-child(even) {\n",
       "    background-color: #f6f6f6;\n",
       "}\n",
       "\n",
       ".estimator-table .parameters-table tr:hover {\n",
       "    background-color: #e0e0e0;\n",
       "}\n",
       "\n",
       ".estimator-table table td {\n",
       "    border: 1px solid rgba(106, 105, 104, 0.232);\n",
       "}\n",
       "\n",
       ".user-set td {\n",
       "    color:rgb(255, 94, 0);\n",
       "    text-align: left;\n",
       "}\n",
       "\n",
       ".user-set td.value pre {\n",
       "    color:rgb(255, 94, 0) !important;\n",
       "    background-color: transparent !important;\n",
       "}\n",
       "\n",
       ".default td {\n",
       "    color: black;\n",
       "    text-align: left;\n",
       "}\n",
       "\n",
       ".user-set td i,\n",
       ".default td i {\n",
       "    color: black;\n",
       "}\n",
       "\n",
       ".copy-paste-icon {\n",
       "    background-image: url(data:image/svg+xml;base64,PHN2ZyB4bWxucz0iaHR0cDovL3d3dy53My5vcmcvMjAwMC9zdmciIHZpZXdCb3g9IjAgMCA0NDggNTEyIj48IS0tIUZvbnQgQXdlc29tZSBGcmVlIDYuNy4yIGJ5IEBmb250YXdlc29tZSAtIGh0dHBzOi8vZm9udGF3ZXNvbWUuY29tIExpY2Vuc2UgLSBodHRwczovL2ZvbnRhd2Vzb21lLmNvbS9saWNlbnNlL2ZyZWUgQ29weXJpZ2h0IDIwMjUgRm9udGljb25zLCBJbmMuLS0+PHBhdGggZD0iTTIwOCAwTDMzMi4xIDBjMTIuNyAwIDI0LjkgNS4xIDMzLjkgMTQuMWw2Ny45IDY3LjljOSA5IDE0LjEgMjEuMiAxNC4xIDMzLjlMNDQ4IDMzNmMwIDI2LjUtMjEuNSA0OC00OCA0OGwtMTkyIDBjLTI2LjUgMC00OC0yMS41LTQ4LTQ4bDAtMjg4YzAtMjYuNSAyMS41LTQ4IDQ4LTQ4ek00OCAxMjhsODAgMCAwIDY0LTY0IDAgMCAyNTYgMTkyIDAgMC0zMiA2NCAwIDAgNDhjMCAyNi41LTIxLjUgNDgtNDggNDhMNDggNTEyYy0yNi41IDAtNDgtMjEuNS00OC00OEwwIDE3NmMwLTI2LjUgMjEuNS00OCA0OC00OHoiLz48L3N2Zz4=);\n",
       "    background-repeat: no-repeat;\n",
       "    background-size: 14px 14px;\n",
       "    background-position: 0;\n",
       "    display: inline-block;\n",
       "    width: 14px;\n",
       "    height: 14px;\n",
       "    cursor: pointer;\n",
       "}\n",
       "</style><body><div id=\"sk-container-id-2\" class=\"sk-top-container\"><div class=\"sk-text-repr-fallback\"><pre>OneVsRestClassifier(estimator=LogisticRegression(max_iter=1000))</pre><b>In a Jupyter environment, please rerun this cell to show the HTML representation or trust the notebook. <br />On GitHub, the HTML representation is unable to render, please try loading this page with nbviewer.org.</b></div><div class=\"sk-container\" hidden><div class=\"sk-item sk-dashed-wrapped\"><div class=\"sk-label-container\"><div class=\"sk-label fitted sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-4\" type=\"checkbox\" ><label for=\"sk-estimator-id-4\" class=\"sk-toggleable__label fitted sk-toggleable__label-arrow\"><div><div>OneVsRestClassifier</div></div><div><a class=\"sk-estimator-doc-link fitted\" rel=\"noreferrer\" target=\"_blank\" href=\"https://scikit-learn.org/1.7/modules/generated/sklearn.multiclass.OneVsRestClassifier.html\">?<span>Documentation for OneVsRestClassifier</span></a><span class=\"sk-estimator-doc-link fitted\">i<span>Fitted</span></span></div></label><div class=\"sk-toggleable__content fitted\" data-param-prefix=\"\">\n",
       "        <div class=\"estimator-table\">\n",
       "            <details>\n",
       "                <summary>Parameters</summary>\n",
       "                <table class=\"parameters-table\">\n",
       "                  <tbody>\n",
       "                    \n",
       "        <tr class=\"user-set\">\n",
       "            <td><i class=\"copy-paste-icon\"\n",
       "                 onclick=\"copyToClipboard('estimator',\n",
       "                          this.parentElement.nextElementSibling)\"\n",
       "            ></i></td>\n",
       "            <td class=\"param\">estimator&nbsp;</td>\n",
       "            <td class=\"value\">LogisticRegre...max_iter=1000)</td>\n",
       "        </tr>\n",
       "    \n",
       "\n",
       "        <tr class=\"default\">\n",
       "            <td><i class=\"copy-paste-icon\"\n",
       "                 onclick=\"copyToClipboard('n_jobs',\n",
       "                          this.parentElement.nextElementSibling)\"\n",
       "            ></i></td>\n",
       "            <td class=\"param\">n_jobs&nbsp;</td>\n",
       "            <td class=\"value\">None</td>\n",
       "        </tr>\n",
       "    \n",
       "\n",
       "        <tr class=\"default\">\n",
       "            <td><i class=\"copy-paste-icon\"\n",
       "                 onclick=\"copyToClipboard('verbose',\n",
       "                          this.parentElement.nextElementSibling)\"\n",
       "            ></i></td>\n",
       "            <td class=\"param\">verbose&nbsp;</td>\n",
       "            <td class=\"value\">0</td>\n",
       "        </tr>\n",
       "    \n",
       "                  </tbody>\n",
       "                </table>\n",
       "            </details>\n",
       "        </div>\n",
       "    </div></div></div><div class=\"sk-parallel\"><div class=\"sk-parallel-item\"><div class=\"sk-item\"><div class=\"sk-label-container\"><div class=\"sk-label fitted sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-5\" type=\"checkbox\" ><label for=\"sk-estimator-id-5\" class=\"sk-toggleable__label fitted sk-toggleable__label-arrow\"><div><div>estimator: LogisticRegression</div></div></label><div class=\"sk-toggleable__content fitted\" data-param-prefix=\"estimator__\"><pre>LogisticRegression(max_iter=1000)</pre></div></div></div><div class=\"sk-serial\"><div class=\"sk-item\"><div class=\"sk-estimator fitted sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-6\" type=\"checkbox\" ><label for=\"sk-estimator-id-6\" class=\"sk-toggleable__label fitted sk-toggleable__label-arrow\"><div><div>LogisticRegression</div></div><div><a class=\"sk-estimator-doc-link fitted\" rel=\"noreferrer\" target=\"_blank\" href=\"https://scikit-learn.org/1.7/modules/generated/sklearn.linear_model.LogisticRegression.html\">?<span>Documentation for LogisticRegression</span></a></div></label><div class=\"sk-toggleable__content fitted\" data-param-prefix=\"estimator__\">\n",
       "        <div class=\"estimator-table\">\n",
       "            <details>\n",
       "                <summary>Parameters</summary>\n",
       "                <table class=\"parameters-table\">\n",
       "                  <tbody>\n",
       "                    \n",
       "        <tr class=\"default\">\n",
       "            <td><i class=\"copy-paste-icon\"\n",
       "                 onclick=\"copyToClipboard('penalty',\n",
       "                          this.parentElement.nextElementSibling)\"\n",
       "            ></i></td>\n",
       "            <td class=\"param\">penalty&nbsp;</td>\n",
       "            <td class=\"value\">&#x27;l2&#x27;</td>\n",
       "        </tr>\n",
       "    \n",
       "\n",
       "        <tr class=\"default\">\n",
       "            <td><i class=\"copy-paste-icon\"\n",
       "                 onclick=\"copyToClipboard('dual',\n",
       "                          this.parentElement.nextElementSibling)\"\n",
       "            ></i></td>\n",
       "            <td class=\"param\">dual&nbsp;</td>\n",
       "            <td class=\"value\">False</td>\n",
       "        </tr>\n",
       "    \n",
       "\n",
       "        <tr class=\"default\">\n",
       "            <td><i class=\"copy-paste-icon\"\n",
       "                 onclick=\"copyToClipboard('tol',\n",
       "                          this.parentElement.nextElementSibling)\"\n",
       "            ></i></td>\n",
       "            <td class=\"param\">tol&nbsp;</td>\n",
       "            <td class=\"value\">0.0001</td>\n",
       "        </tr>\n",
       "    \n",
       "\n",
       "        <tr class=\"default\">\n",
       "            <td><i class=\"copy-paste-icon\"\n",
       "                 onclick=\"copyToClipboard('C',\n",
       "                          this.parentElement.nextElementSibling)\"\n",
       "            ></i></td>\n",
       "            <td class=\"param\">C&nbsp;</td>\n",
       "            <td class=\"value\">1.0</td>\n",
       "        </tr>\n",
       "    \n",
       "\n",
       "        <tr class=\"default\">\n",
       "            <td><i class=\"copy-paste-icon\"\n",
       "                 onclick=\"copyToClipboard('fit_intercept',\n",
       "                          this.parentElement.nextElementSibling)\"\n",
       "            ></i></td>\n",
       "            <td class=\"param\">fit_intercept&nbsp;</td>\n",
       "            <td class=\"value\">True</td>\n",
       "        </tr>\n",
       "    \n",
       "\n",
       "        <tr class=\"default\">\n",
       "            <td><i class=\"copy-paste-icon\"\n",
       "                 onclick=\"copyToClipboard('intercept_scaling',\n",
       "                          this.parentElement.nextElementSibling)\"\n",
       "            ></i></td>\n",
       "            <td class=\"param\">intercept_scaling&nbsp;</td>\n",
       "            <td class=\"value\">1</td>\n",
       "        </tr>\n",
       "    \n",
       "\n",
       "        <tr class=\"default\">\n",
       "            <td><i class=\"copy-paste-icon\"\n",
       "                 onclick=\"copyToClipboard('class_weight',\n",
       "                          this.parentElement.nextElementSibling)\"\n",
       "            ></i></td>\n",
       "            <td class=\"param\">class_weight&nbsp;</td>\n",
       "            <td class=\"value\">None</td>\n",
       "        </tr>\n",
       "    \n",
       "\n",
       "        <tr class=\"default\">\n",
       "            <td><i class=\"copy-paste-icon\"\n",
       "                 onclick=\"copyToClipboard('random_state',\n",
       "                          this.parentElement.nextElementSibling)\"\n",
       "            ></i></td>\n",
       "            <td class=\"param\">random_state&nbsp;</td>\n",
       "            <td class=\"value\">None</td>\n",
       "        </tr>\n",
       "    \n",
       "\n",
       "        <tr class=\"default\">\n",
       "            <td><i class=\"copy-paste-icon\"\n",
       "                 onclick=\"copyToClipboard('solver',\n",
       "                          this.parentElement.nextElementSibling)\"\n",
       "            ></i></td>\n",
       "            <td class=\"param\">solver&nbsp;</td>\n",
       "            <td class=\"value\">&#x27;lbfgs&#x27;</td>\n",
       "        </tr>\n",
       "    \n",
       "\n",
       "        <tr class=\"user-set\">\n",
       "            <td><i class=\"copy-paste-icon\"\n",
       "                 onclick=\"copyToClipboard('max_iter',\n",
       "                          this.parentElement.nextElementSibling)\"\n",
       "            ></i></td>\n",
       "            <td class=\"param\">max_iter&nbsp;</td>\n",
       "            <td class=\"value\">1000</td>\n",
       "        </tr>\n",
       "    \n",
       "\n",
       "        <tr class=\"default\">\n",
       "            <td><i class=\"copy-paste-icon\"\n",
       "                 onclick=\"copyToClipboard('multi_class',\n",
       "                          this.parentElement.nextElementSibling)\"\n",
       "            ></i></td>\n",
       "            <td class=\"param\">multi_class&nbsp;</td>\n",
       "            <td class=\"value\">&#x27;deprecated&#x27;</td>\n",
       "        </tr>\n",
       "    \n",
       "\n",
       "        <tr class=\"default\">\n",
       "            <td><i class=\"copy-paste-icon\"\n",
       "                 onclick=\"copyToClipboard('verbose',\n",
       "                          this.parentElement.nextElementSibling)\"\n",
       "            ></i></td>\n",
       "            <td class=\"param\">verbose&nbsp;</td>\n",
       "            <td class=\"value\">0</td>\n",
       "        </tr>\n",
       "    \n",
       "\n",
       "        <tr class=\"default\">\n",
       "            <td><i class=\"copy-paste-icon\"\n",
       "                 onclick=\"copyToClipboard('warm_start',\n",
       "                          this.parentElement.nextElementSibling)\"\n",
       "            ></i></td>\n",
       "            <td class=\"param\">warm_start&nbsp;</td>\n",
       "            <td class=\"value\">False</td>\n",
       "        </tr>\n",
       "    \n",
       "\n",
       "        <tr class=\"default\">\n",
       "            <td><i class=\"copy-paste-icon\"\n",
       "                 onclick=\"copyToClipboard('n_jobs',\n",
       "                          this.parentElement.nextElementSibling)\"\n",
       "            ></i></td>\n",
       "            <td class=\"param\">n_jobs&nbsp;</td>\n",
       "            <td class=\"value\">None</td>\n",
       "        </tr>\n",
       "    \n",
       "\n",
       "        <tr class=\"default\">\n",
       "            <td><i class=\"copy-paste-icon\"\n",
       "                 onclick=\"copyToClipboard('l1_ratio',\n",
       "                          this.parentElement.nextElementSibling)\"\n",
       "            ></i></td>\n",
       "            <td class=\"param\">l1_ratio&nbsp;</td>\n",
       "            <td class=\"value\">None</td>\n",
       "        </tr>\n",
       "    \n",
       "                  </tbody>\n",
       "                </table>\n",
       "            </details>\n",
       "        </div>\n",
       "    </div></div></div></div></div></div></div></div></div></div><script>function copyToClipboard(text, element) {\n",
       "    // Get the parameter prefix from the closest toggleable content\n",
       "    const toggleableContent = element.closest('.sk-toggleable__content');\n",
       "    const paramPrefix = toggleableContent ? toggleableContent.dataset.paramPrefix : '';\n",
       "    const fullParamName = paramPrefix ? `${paramPrefix}${text}` : text;\n",
       "\n",
       "    const originalStyle = element.style;\n",
       "    const computedStyle = window.getComputedStyle(element);\n",
       "    const originalWidth = computedStyle.width;\n",
       "    const originalHTML = element.innerHTML.replace('Copied!', '');\n",
       "\n",
       "    navigator.clipboard.writeText(fullParamName)\n",
       "        .then(() => {\n",
       "            element.style.width = originalWidth;\n",
       "            element.style.color = 'green';\n",
       "            element.innerHTML = \"Copied!\";\n",
       "\n",
       "            setTimeout(() => {\n",
       "                element.innerHTML = originalHTML;\n",
       "                element.style = originalStyle;\n",
       "            }, 2000);\n",
       "        })\n",
       "        .catch(err => {\n",
       "            console.error('Failed to copy:', err);\n",
       "            element.style.color = 'red';\n",
       "            element.innerHTML = \"Failed!\";\n",
       "            setTimeout(() => {\n",
       "                element.innerHTML = originalHTML;\n",
       "                element.style = originalStyle;\n",
       "            }, 2000);\n",
       "        });\n",
       "    return false;\n",
       "}\n",
       "\n",
       "document.querySelectorAll('.fa-regular.fa-copy').forEach(function(element) {\n",
       "    const toggleableContent = element.closest('.sk-toggleable__content');\n",
       "    const paramPrefix = toggleableContent ? toggleableContent.dataset.paramPrefix : '';\n",
       "    const paramName = element.parentElement.nextElementSibling.textContent.trim();\n",
       "    const fullParamName = paramPrefix ? `${paramPrefix}${paramName}` : paramName;\n",
       "\n",
       "    element.setAttribute('title', fullParamName);\n",
       "});\n",
       "</script></body>"
      ],
      "text/plain": [
       "OneVsRestClassifier(estimator=LogisticRegression(max_iter=1000))"
      ]
     },
     "execution_count": 32,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.multiclass import OneVsRestClassifier\n",
    "\n",
    "lr = LogisticRegression(max_iter=1000)\n",
    "clf_sbert = OneVsRestClassifier(lr)\n",
    "\n",
    "clf_sbert.fit(X_train_sbert, y_train)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0fb18f6d",
   "metadata": {},
   "source": [
    "### évaluation\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "0f3544d6",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "F1 micro : 0.18433903630092546\n",
      "F1 macro : 0.12375796103516999\n",
      "Hamming loss : 0.04105080434483707\n",
      "\n",
      "Rapport détaillé par classe :\n",
      "                precision    recall  f1-score   support\n",
      "\n",
      "    admiration       0.61      0.20      0.30      1691\n",
      "     amusement       0.63      0.29      0.40       926\n",
      "         anger       0.71      0.07      0.12       861\n",
      "     annoyance       0.44      0.00      0.01      1353\n",
      "      approval       0.58      0.01      0.02      1794\n",
      "        caring       0.38      0.03      0.05       577\n",
      "     confusion       0.52      0.02      0.03       721\n",
      "     curiosity       0.43      0.03      0.06       947\n",
      "        desire       0.46      0.03      0.06       361\n",
      "disappointment       0.00      0.00      0.00       849\n",
      "   disapproval       0.52      0.01      0.02      1184\n",
      "       disgust       0.52      0.05      0.09       550\n",
      " embarrassment       0.33      0.00      0.01       264\n",
      "    excitement       0.72      0.03      0.06       553\n",
      "          fear       0.66      0.17      0.27       318\n",
      "     gratitude       0.79      0.53      0.64      1162\n",
      "         grief       0.00      0.00      0.00        66\n",
      "           joy       0.50      0.07      0.12       779\n",
      "          love       0.66      0.36      0.46       812\n",
      "   nervousness       0.67      0.02      0.04       186\n",
      "      optimism       0.64      0.06      0.10       875\n",
      "         pride       0.60      0.02      0.05       124\n",
      "   realization       0.00      0.00      0.00       870\n",
      "        relief       0.00      0.00      0.00       146\n",
      "       remorse       0.36      0.08      0.13       266\n",
      "       sadness       0.67      0.12      0.20       677\n",
      "      surprise       0.45      0.02      0.05       548\n",
      "       neutral       0.55      0.13      0.21      5484\n",
      "\n",
      "     micro avg       0.62      0.11      0.18     24944\n",
      "     macro avg       0.48      0.08      0.12     24944\n",
      "  weighted avg       0.52      0.11      0.16     24944\n",
      "   samples avg       0.12      0.11      0.11     24944\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\Yann\\Desktop\\DEV\\School\\ml_m1\\NLP\\CustomGPT\\scraper_env\\Lib\\site-packages\\sklearn\\metrics\\_classification.py:1706: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", result.shape[0])\n",
      "c:\\Users\\Yann\\Desktop\\DEV\\School\\ml_m1\\NLP\\CustomGPT\\scraper_env\\Lib\\site-packages\\sklearn\\metrics\\_classification.py:1706: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in samples with no predicted labels. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", result.shape[0])\n"
     ]
    }
   ],
   "source": [
    "from sklearn.metrics import f1_score, classification_report, hamming_loss\n",
    "\n",
    "y_val_pred_sbert = clf_sbert.predict(X_val_sbert)\n",
    "\n",
    "print(\"F1 micro :\", f1_score(y_val, y_val_pred_sbert, average='micro'))\n",
    "print(\"F1 macro :\", f1_score(y_val, y_val_pred_sbert, average='macro'))\n",
    "print(\"Hamming loss :\", hamming_loss(y_val, y_val_pred_sbert))\n",
    "\n",
    "print(\"\\nRapport détaillé par classe :\")\n",
    "print(classification_report(y_val, y_val_pred_sbert, target_names=label_cols))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dd2b3cec",
   "metadata": {},
   "source": [
    "## modèles plus lourds sans fine tine : mpnet "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "76e2a3cf",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "5a822b0dfd72483497b986ea269fd5d7",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Batches:   0%|          | 0/5196 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "d9da1d3b1f8545deb58b23f7008f6489",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Batches:   0%|          | 0/650 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "42e815efd37248d3ad5432d188e71171",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Batches:   0%|          | 0/650 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "from sentence_transformers import SentenceTransformer\n",
    "\n",
    "# Modèle puissant (768 dimensions)\n",
    "sbert_model = SentenceTransformer('all-mpnet-base-v2')\n",
    "\n",
    "# Encodage (attention : plus lent que MiniLM)\n",
    "X_train_sbert = sbert_model.encode(X_train, show_progress_bar=True, batch_size=32)\n",
    "X_val_sbert = sbert_model.encode(X_val, show_progress_bar=True, batch_size=32)\n",
    "X_test_sbert = sbert_model.encode(X_test, show_progress_bar=True, batch_size=32)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e8e29f81",
   "metadata": {},
   "source": [
    "### avec logistic regression"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "0d05d4f1",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<style>#sk-container-id-3 {\n",
       "  /* Definition of color scheme common for light and dark mode */\n",
       "  --sklearn-color-text: #000;\n",
       "  --sklearn-color-text-muted: #666;\n",
       "  --sklearn-color-line: gray;\n",
       "  /* Definition of color scheme for unfitted estimators */\n",
       "  --sklearn-color-unfitted-level-0: #fff5e6;\n",
       "  --sklearn-color-unfitted-level-1: #f6e4d2;\n",
       "  --sklearn-color-unfitted-level-2: #ffe0b3;\n",
       "  --sklearn-color-unfitted-level-3: chocolate;\n",
       "  /* Definition of color scheme for fitted estimators */\n",
       "  --sklearn-color-fitted-level-0: #f0f8ff;\n",
       "  --sklearn-color-fitted-level-1: #d4ebff;\n",
       "  --sklearn-color-fitted-level-2: #b3dbfd;\n",
       "  --sklearn-color-fitted-level-3: cornflowerblue;\n",
       "\n",
       "  /* Specific color for light theme */\n",
       "  --sklearn-color-text-on-default-background: var(--sg-text-color, var(--theme-code-foreground, var(--jp-content-font-color1, black)));\n",
       "  --sklearn-color-background: var(--sg-background-color, var(--theme-background, var(--jp-layout-color0, white)));\n",
       "  --sklearn-color-border-box: var(--sg-text-color, var(--theme-code-foreground, var(--jp-content-font-color1, black)));\n",
       "  --sklearn-color-icon: #696969;\n",
       "\n",
       "  @media (prefers-color-scheme: dark) {\n",
       "    /* Redefinition of color scheme for dark theme */\n",
       "    --sklearn-color-text-on-default-background: var(--sg-text-color, var(--theme-code-foreground, var(--jp-content-font-color1, white)));\n",
       "    --sklearn-color-background: var(--sg-background-color, var(--theme-background, var(--jp-layout-color0, #111)));\n",
       "    --sklearn-color-border-box: var(--sg-text-color, var(--theme-code-foreground, var(--jp-content-font-color1, white)));\n",
       "    --sklearn-color-icon: #878787;\n",
       "  }\n",
       "}\n",
       "\n",
       "#sk-container-id-3 {\n",
       "  color: var(--sklearn-color-text);\n",
       "}\n",
       "\n",
       "#sk-container-id-3 pre {\n",
       "  padding: 0;\n",
       "}\n",
       "\n",
       "#sk-container-id-3 input.sk-hidden--visually {\n",
       "  border: 0;\n",
       "  clip: rect(1px 1px 1px 1px);\n",
       "  clip: rect(1px, 1px, 1px, 1px);\n",
       "  height: 1px;\n",
       "  margin: -1px;\n",
       "  overflow: hidden;\n",
       "  padding: 0;\n",
       "  position: absolute;\n",
       "  width: 1px;\n",
       "}\n",
       "\n",
       "#sk-container-id-3 div.sk-dashed-wrapped {\n",
       "  border: 1px dashed var(--sklearn-color-line);\n",
       "  margin: 0 0.4em 0.5em 0.4em;\n",
       "  box-sizing: border-box;\n",
       "  padding-bottom: 0.4em;\n",
       "  background-color: var(--sklearn-color-background);\n",
       "}\n",
       "\n",
       "#sk-container-id-3 div.sk-container {\n",
       "  /* jupyter's `normalize.less` sets `[hidden] { display: none; }`\n",
       "     but bootstrap.min.css set `[hidden] { display: none !important; }`\n",
       "     so we also need the `!important` here to be able to override the\n",
       "     default hidden behavior on the sphinx rendered scikit-learn.org.\n",
       "     See: https://github.com/scikit-learn/scikit-learn/issues/21755 */\n",
       "  display: inline-block !important;\n",
       "  position: relative;\n",
       "}\n",
       "\n",
       "#sk-container-id-3 div.sk-text-repr-fallback {\n",
       "  display: none;\n",
       "}\n",
       "\n",
       "div.sk-parallel-item,\n",
       "div.sk-serial,\n",
       "div.sk-item {\n",
       "  /* draw centered vertical line to link estimators */\n",
       "  background-image: linear-gradient(var(--sklearn-color-text-on-default-background), var(--sklearn-color-text-on-default-background));\n",
       "  background-size: 2px 100%;\n",
       "  background-repeat: no-repeat;\n",
       "  background-position: center center;\n",
       "}\n",
       "\n",
       "/* Parallel-specific style estimator block */\n",
       "\n",
       "#sk-container-id-3 div.sk-parallel-item::after {\n",
       "  content: \"\";\n",
       "  width: 100%;\n",
       "  border-bottom: 2px solid var(--sklearn-color-text-on-default-background);\n",
       "  flex-grow: 1;\n",
       "}\n",
       "\n",
       "#sk-container-id-3 div.sk-parallel {\n",
       "  display: flex;\n",
       "  align-items: stretch;\n",
       "  justify-content: center;\n",
       "  background-color: var(--sklearn-color-background);\n",
       "  position: relative;\n",
       "}\n",
       "\n",
       "#sk-container-id-3 div.sk-parallel-item {\n",
       "  display: flex;\n",
       "  flex-direction: column;\n",
       "}\n",
       "\n",
       "#sk-container-id-3 div.sk-parallel-item:first-child::after {\n",
       "  align-self: flex-end;\n",
       "  width: 50%;\n",
       "}\n",
       "\n",
       "#sk-container-id-3 div.sk-parallel-item:last-child::after {\n",
       "  align-self: flex-start;\n",
       "  width: 50%;\n",
       "}\n",
       "\n",
       "#sk-container-id-3 div.sk-parallel-item:only-child::after {\n",
       "  width: 0;\n",
       "}\n",
       "\n",
       "/* Serial-specific style estimator block */\n",
       "\n",
       "#sk-container-id-3 div.sk-serial {\n",
       "  display: flex;\n",
       "  flex-direction: column;\n",
       "  align-items: center;\n",
       "  background-color: var(--sklearn-color-background);\n",
       "  padding-right: 1em;\n",
       "  padding-left: 1em;\n",
       "}\n",
       "\n",
       "\n",
       "/* Toggleable style: style used for estimator/Pipeline/ColumnTransformer box that is\n",
       "clickable and can be expanded/collapsed.\n",
       "- Pipeline and ColumnTransformer use this feature and define the default style\n",
       "- Estimators will overwrite some part of the style using the `sk-estimator` class\n",
       "*/\n",
       "\n",
       "/* Pipeline and ColumnTransformer style (default) */\n",
       "\n",
       "#sk-container-id-3 div.sk-toggleable {\n",
       "  /* Default theme specific background. It is overwritten whether we have a\n",
       "  specific estimator or a Pipeline/ColumnTransformer */\n",
       "  background-color: var(--sklearn-color-background);\n",
       "}\n",
       "\n",
       "/* Toggleable label */\n",
       "#sk-container-id-3 label.sk-toggleable__label {\n",
       "  cursor: pointer;\n",
       "  display: flex;\n",
       "  width: 100%;\n",
       "  margin-bottom: 0;\n",
       "  padding: 0.5em;\n",
       "  box-sizing: border-box;\n",
       "  text-align: center;\n",
       "  align-items: start;\n",
       "  justify-content: space-between;\n",
       "  gap: 0.5em;\n",
       "}\n",
       "\n",
       "#sk-container-id-3 label.sk-toggleable__label .caption {\n",
       "  font-size: 0.6rem;\n",
       "  font-weight: lighter;\n",
       "  color: var(--sklearn-color-text-muted);\n",
       "}\n",
       "\n",
       "#sk-container-id-3 label.sk-toggleable__label-arrow:before {\n",
       "  /* Arrow on the left of the label */\n",
       "  content: \"▸\";\n",
       "  float: left;\n",
       "  margin-right: 0.25em;\n",
       "  color: var(--sklearn-color-icon);\n",
       "}\n",
       "\n",
       "#sk-container-id-3 label.sk-toggleable__label-arrow:hover:before {\n",
       "  color: var(--sklearn-color-text);\n",
       "}\n",
       "\n",
       "/* Toggleable content - dropdown */\n",
       "\n",
       "#sk-container-id-3 div.sk-toggleable__content {\n",
       "  display: none;\n",
       "  text-align: left;\n",
       "  /* unfitted */\n",
       "  background-color: var(--sklearn-color-unfitted-level-0);\n",
       "}\n",
       "\n",
       "#sk-container-id-3 div.sk-toggleable__content.fitted {\n",
       "  /* fitted */\n",
       "  background-color: var(--sklearn-color-fitted-level-0);\n",
       "}\n",
       "\n",
       "#sk-container-id-3 div.sk-toggleable__content pre {\n",
       "  margin: 0.2em;\n",
       "  border-radius: 0.25em;\n",
       "  color: var(--sklearn-color-text);\n",
       "  /* unfitted */\n",
       "  background-color: var(--sklearn-color-unfitted-level-0);\n",
       "}\n",
       "\n",
       "#sk-container-id-3 div.sk-toggleable__content.fitted pre {\n",
       "  /* unfitted */\n",
       "  background-color: var(--sklearn-color-fitted-level-0);\n",
       "}\n",
       "\n",
       "#sk-container-id-3 input.sk-toggleable__control:checked~div.sk-toggleable__content {\n",
       "  /* Expand drop-down */\n",
       "  display: block;\n",
       "  width: 100%;\n",
       "  overflow: visible;\n",
       "}\n",
       "\n",
       "#sk-container-id-3 input.sk-toggleable__control:checked~label.sk-toggleable__label-arrow:before {\n",
       "  content: \"▾\";\n",
       "}\n",
       "\n",
       "/* Pipeline/ColumnTransformer-specific style */\n",
       "\n",
       "#sk-container-id-3 div.sk-label input.sk-toggleable__control:checked~label.sk-toggleable__label {\n",
       "  color: var(--sklearn-color-text);\n",
       "  background-color: var(--sklearn-color-unfitted-level-2);\n",
       "}\n",
       "\n",
       "#sk-container-id-3 div.sk-label.fitted input.sk-toggleable__control:checked~label.sk-toggleable__label {\n",
       "  background-color: var(--sklearn-color-fitted-level-2);\n",
       "}\n",
       "\n",
       "/* Estimator-specific style */\n",
       "\n",
       "/* Colorize estimator box */\n",
       "#sk-container-id-3 div.sk-estimator input.sk-toggleable__control:checked~label.sk-toggleable__label {\n",
       "  /* unfitted */\n",
       "  background-color: var(--sklearn-color-unfitted-level-2);\n",
       "}\n",
       "\n",
       "#sk-container-id-3 div.sk-estimator.fitted input.sk-toggleable__control:checked~label.sk-toggleable__label {\n",
       "  /* fitted */\n",
       "  background-color: var(--sklearn-color-fitted-level-2);\n",
       "}\n",
       "\n",
       "#sk-container-id-3 div.sk-label label.sk-toggleable__label,\n",
       "#sk-container-id-3 div.sk-label label {\n",
       "  /* The background is the default theme color */\n",
       "  color: var(--sklearn-color-text-on-default-background);\n",
       "}\n",
       "\n",
       "/* On hover, darken the color of the background */\n",
       "#sk-container-id-3 div.sk-label:hover label.sk-toggleable__label {\n",
       "  color: var(--sklearn-color-text);\n",
       "  background-color: var(--sklearn-color-unfitted-level-2);\n",
       "}\n",
       "\n",
       "/* Label box, darken color on hover, fitted */\n",
       "#sk-container-id-3 div.sk-label.fitted:hover label.sk-toggleable__label.fitted {\n",
       "  color: var(--sklearn-color-text);\n",
       "  background-color: var(--sklearn-color-fitted-level-2);\n",
       "}\n",
       "\n",
       "/* Estimator label */\n",
       "\n",
       "#sk-container-id-3 div.sk-label label {\n",
       "  font-family: monospace;\n",
       "  font-weight: bold;\n",
       "  display: inline-block;\n",
       "  line-height: 1.2em;\n",
       "}\n",
       "\n",
       "#sk-container-id-3 div.sk-label-container {\n",
       "  text-align: center;\n",
       "}\n",
       "\n",
       "/* Estimator-specific */\n",
       "#sk-container-id-3 div.sk-estimator {\n",
       "  font-family: monospace;\n",
       "  border: 1px dotted var(--sklearn-color-border-box);\n",
       "  border-radius: 0.25em;\n",
       "  box-sizing: border-box;\n",
       "  margin-bottom: 0.5em;\n",
       "  /* unfitted */\n",
       "  background-color: var(--sklearn-color-unfitted-level-0);\n",
       "}\n",
       "\n",
       "#sk-container-id-3 div.sk-estimator.fitted {\n",
       "  /* fitted */\n",
       "  background-color: var(--sklearn-color-fitted-level-0);\n",
       "}\n",
       "\n",
       "/* on hover */\n",
       "#sk-container-id-3 div.sk-estimator:hover {\n",
       "  /* unfitted */\n",
       "  background-color: var(--sklearn-color-unfitted-level-2);\n",
       "}\n",
       "\n",
       "#sk-container-id-3 div.sk-estimator.fitted:hover {\n",
       "  /* fitted */\n",
       "  background-color: var(--sklearn-color-fitted-level-2);\n",
       "}\n",
       "\n",
       "/* Specification for estimator info (e.g. \"i\" and \"?\") */\n",
       "\n",
       "/* Common style for \"i\" and \"?\" */\n",
       "\n",
       ".sk-estimator-doc-link,\n",
       "a:link.sk-estimator-doc-link,\n",
       "a:visited.sk-estimator-doc-link {\n",
       "  float: right;\n",
       "  font-size: smaller;\n",
       "  line-height: 1em;\n",
       "  font-family: monospace;\n",
       "  background-color: var(--sklearn-color-background);\n",
       "  border-radius: 1em;\n",
       "  height: 1em;\n",
       "  width: 1em;\n",
       "  text-decoration: none !important;\n",
       "  margin-left: 0.5em;\n",
       "  text-align: center;\n",
       "  /* unfitted */\n",
       "  border: var(--sklearn-color-unfitted-level-1) 1pt solid;\n",
       "  color: var(--sklearn-color-unfitted-level-1);\n",
       "}\n",
       "\n",
       ".sk-estimator-doc-link.fitted,\n",
       "a:link.sk-estimator-doc-link.fitted,\n",
       "a:visited.sk-estimator-doc-link.fitted {\n",
       "  /* fitted */\n",
       "  border: var(--sklearn-color-fitted-level-1) 1pt solid;\n",
       "  color: var(--sklearn-color-fitted-level-1);\n",
       "}\n",
       "\n",
       "/* On hover */\n",
       "div.sk-estimator:hover .sk-estimator-doc-link:hover,\n",
       ".sk-estimator-doc-link:hover,\n",
       "div.sk-label-container:hover .sk-estimator-doc-link:hover,\n",
       ".sk-estimator-doc-link:hover {\n",
       "  /* unfitted */\n",
       "  background-color: var(--sklearn-color-unfitted-level-3);\n",
       "  color: var(--sklearn-color-background);\n",
       "  text-decoration: none;\n",
       "}\n",
       "\n",
       "div.sk-estimator.fitted:hover .sk-estimator-doc-link.fitted:hover,\n",
       ".sk-estimator-doc-link.fitted:hover,\n",
       "div.sk-label-container:hover .sk-estimator-doc-link.fitted:hover,\n",
       ".sk-estimator-doc-link.fitted:hover {\n",
       "  /* fitted */\n",
       "  background-color: var(--sklearn-color-fitted-level-3);\n",
       "  color: var(--sklearn-color-background);\n",
       "  text-decoration: none;\n",
       "}\n",
       "\n",
       "/* Span, style for the box shown on hovering the info icon */\n",
       ".sk-estimator-doc-link span {\n",
       "  display: none;\n",
       "  z-index: 9999;\n",
       "  position: relative;\n",
       "  font-weight: normal;\n",
       "  right: .2ex;\n",
       "  padding: .5ex;\n",
       "  margin: .5ex;\n",
       "  width: min-content;\n",
       "  min-width: 20ex;\n",
       "  max-width: 50ex;\n",
       "  color: var(--sklearn-color-text);\n",
       "  box-shadow: 2pt 2pt 4pt #999;\n",
       "  /* unfitted */\n",
       "  background: var(--sklearn-color-unfitted-level-0);\n",
       "  border: .5pt solid var(--sklearn-color-unfitted-level-3);\n",
       "}\n",
       "\n",
       ".sk-estimator-doc-link.fitted span {\n",
       "  /* fitted */\n",
       "  background: var(--sklearn-color-fitted-level-0);\n",
       "  border: var(--sklearn-color-fitted-level-3);\n",
       "}\n",
       "\n",
       ".sk-estimator-doc-link:hover span {\n",
       "  display: block;\n",
       "}\n",
       "\n",
       "/* \"?\"-specific style due to the `<a>` HTML tag */\n",
       "\n",
       "#sk-container-id-3 a.estimator_doc_link {\n",
       "  float: right;\n",
       "  font-size: 1rem;\n",
       "  line-height: 1em;\n",
       "  font-family: monospace;\n",
       "  background-color: var(--sklearn-color-background);\n",
       "  border-radius: 1rem;\n",
       "  height: 1rem;\n",
       "  width: 1rem;\n",
       "  text-decoration: none;\n",
       "  /* unfitted */\n",
       "  color: var(--sklearn-color-unfitted-level-1);\n",
       "  border: var(--sklearn-color-unfitted-level-1) 1pt solid;\n",
       "}\n",
       "\n",
       "#sk-container-id-3 a.estimator_doc_link.fitted {\n",
       "  /* fitted */\n",
       "  border: var(--sklearn-color-fitted-level-1) 1pt solid;\n",
       "  color: var(--sklearn-color-fitted-level-1);\n",
       "}\n",
       "\n",
       "/* On hover */\n",
       "#sk-container-id-3 a.estimator_doc_link:hover {\n",
       "  /* unfitted */\n",
       "  background-color: var(--sklearn-color-unfitted-level-3);\n",
       "  color: var(--sklearn-color-background);\n",
       "  text-decoration: none;\n",
       "}\n",
       "\n",
       "#sk-container-id-3 a.estimator_doc_link.fitted:hover {\n",
       "  /* fitted */\n",
       "  background-color: var(--sklearn-color-fitted-level-3);\n",
       "}\n",
       "\n",
       ".estimator-table summary {\n",
       "    padding: .5rem;\n",
       "    font-family: monospace;\n",
       "    cursor: pointer;\n",
       "}\n",
       "\n",
       ".estimator-table details[open] {\n",
       "    padding-left: 0.1rem;\n",
       "    padding-right: 0.1rem;\n",
       "    padding-bottom: 0.3rem;\n",
       "}\n",
       "\n",
       ".estimator-table .parameters-table {\n",
       "    margin-left: auto !important;\n",
       "    margin-right: auto !important;\n",
       "}\n",
       "\n",
       ".estimator-table .parameters-table tr:nth-child(odd) {\n",
       "    background-color: #fff;\n",
       "}\n",
       "\n",
       ".estimator-table .parameters-table tr:nth-child(even) {\n",
       "    background-color: #f6f6f6;\n",
       "}\n",
       "\n",
       ".estimator-table .parameters-table tr:hover {\n",
       "    background-color: #e0e0e0;\n",
       "}\n",
       "\n",
       ".estimator-table table td {\n",
       "    border: 1px solid rgba(106, 105, 104, 0.232);\n",
       "}\n",
       "\n",
       ".user-set td {\n",
       "    color:rgb(255, 94, 0);\n",
       "    text-align: left;\n",
       "}\n",
       "\n",
       ".user-set td.value pre {\n",
       "    color:rgb(255, 94, 0) !important;\n",
       "    background-color: transparent !important;\n",
       "}\n",
       "\n",
       ".default td {\n",
       "    color: black;\n",
       "    text-align: left;\n",
       "}\n",
       "\n",
       ".user-set td i,\n",
       ".default td i {\n",
       "    color: black;\n",
       "}\n",
       "\n",
       ".copy-paste-icon {\n",
       "    background-image: url(data:image/svg+xml;base64,PHN2ZyB4bWxucz0iaHR0cDovL3d3dy53My5vcmcvMjAwMC9zdmciIHZpZXdCb3g9IjAgMCA0NDggNTEyIj48IS0tIUZvbnQgQXdlc29tZSBGcmVlIDYuNy4yIGJ5IEBmb250YXdlc29tZSAtIGh0dHBzOi8vZm9udGF3ZXNvbWUuY29tIExpY2Vuc2UgLSBodHRwczovL2ZvbnRhd2Vzb21lLmNvbS9saWNlbnNlL2ZyZWUgQ29weXJpZ2h0IDIwMjUgRm9udGljb25zLCBJbmMuLS0+PHBhdGggZD0iTTIwOCAwTDMzMi4xIDBjMTIuNyAwIDI0LjkgNS4xIDMzLjkgMTQuMWw2Ny45IDY3LjljOSA5IDE0LjEgMjEuMiAxNC4xIDMzLjlMNDQ4IDMzNmMwIDI2LjUtMjEuNSA0OC00OCA0OGwtMTkyIDBjLTI2LjUgMC00OC0yMS41LTQ4LTQ4bDAtMjg4YzAtMjYuNSAyMS41LTQ4IDQ4LTQ4ek00OCAxMjhsODAgMCAwIDY0LTY0IDAgMCAyNTYgMTkyIDAgMC0zMiA2NCAwIDAgNDhjMCAyNi41LTIxLjUgNDgtNDggNDhMNDggNTEyYy0yNi41IDAtNDgtMjEuNS00OC00OEwwIDE3NmMwLTI2LjUgMjEuNS00OCA0OC00OHoiLz48L3N2Zz4=);\n",
       "    background-repeat: no-repeat;\n",
       "    background-size: 14px 14px;\n",
       "    background-position: 0;\n",
       "    display: inline-block;\n",
       "    width: 14px;\n",
       "    height: 14px;\n",
       "    cursor: pointer;\n",
       "}\n",
       "</style><body><div id=\"sk-container-id-3\" class=\"sk-top-container\"><div class=\"sk-text-repr-fallback\"><pre>OneVsRestClassifier(estimator=LogisticRegression(max_iter=1000))</pre><b>In a Jupyter environment, please rerun this cell to show the HTML representation or trust the notebook. <br />On GitHub, the HTML representation is unable to render, please try loading this page with nbviewer.org.</b></div><div class=\"sk-container\" hidden><div class=\"sk-item sk-dashed-wrapped\"><div class=\"sk-label-container\"><div class=\"sk-label fitted sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-7\" type=\"checkbox\" ><label for=\"sk-estimator-id-7\" class=\"sk-toggleable__label fitted sk-toggleable__label-arrow\"><div><div>OneVsRestClassifier</div></div><div><a class=\"sk-estimator-doc-link fitted\" rel=\"noreferrer\" target=\"_blank\" href=\"https://scikit-learn.org/1.7/modules/generated/sklearn.multiclass.OneVsRestClassifier.html\">?<span>Documentation for OneVsRestClassifier</span></a><span class=\"sk-estimator-doc-link fitted\">i<span>Fitted</span></span></div></label><div class=\"sk-toggleable__content fitted\" data-param-prefix=\"\">\n",
       "        <div class=\"estimator-table\">\n",
       "            <details>\n",
       "                <summary>Parameters</summary>\n",
       "                <table class=\"parameters-table\">\n",
       "                  <tbody>\n",
       "                    \n",
       "        <tr class=\"user-set\">\n",
       "            <td><i class=\"copy-paste-icon\"\n",
       "                 onclick=\"copyToClipboard('estimator',\n",
       "                          this.parentElement.nextElementSibling)\"\n",
       "            ></i></td>\n",
       "            <td class=\"param\">estimator&nbsp;</td>\n",
       "            <td class=\"value\">LogisticRegre...max_iter=1000)</td>\n",
       "        </tr>\n",
       "    \n",
       "\n",
       "        <tr class=\"default\">\n",
       "            <td><i class=\"copy-paste-icon\"\n",
       "                 onclick=\"copyToClipboard('n_jobs',\n",
       "                          this.parentElement.nextElementSibling)\"\n",
       "            ></i></td>\n",
       "            <td class=\"param\">n_jobs&nbsp;</td>\n",
       "            <td class=\"value\">None</td>\n",
       "        </tr>\n",
       "    \n",
       "\n",
       "        <tr class=\"default\">\n",
       "            <td><i class=\"copy-paste-icon\"\n",
       "                 onclick=\"copyToClipboard('verbose',\n",
       "                          this.parentElement.nextElementSibling)\"\n",
       "            ></i></td>\n",
       "            <td class=\"param\">verbose&nbsp;</td>\n",
       "            <td class=\"value\">0</td>\n",
       "        </tr>\n",
       "    \n",
       "                  </tbody>\n",
       "                </table>\n",
       "            </details>\n",
       "        </div>\n",
       "    </div></div></div><div class=\"sk-parallel\"><div class=\"sk-parallel-item\"><div class=\"sk-item\"><div class=\"sk-label-container\"><div class=\"sk-label fitted sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-8\" type=\"checkbox\" ><label for=\"sk-estimator-id-8\" class=\"sk-toggleable__label fitted sk-toggleable__label-arrow\"><div><div>estimator: LogisticRegression</div></div></label><div class=\"sk-toggleable__content fitted\" data-param-prefix=\"estimator__\"><pre>LogisticRegression(max_iter=1000)</pre></div></div></div><div class=\"sk-serial\"><div class=\"sk-item\"><div class=\"sk-estimator fitted sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-9\" type=\"checkbox\" ><label for=\"sk-estimator-id-9\" class=\"sk-toggleable__label fitted sk-toggleable__label-arrow\"><div><div>LogisticRegression</div></div><div><a class=\"sk-estimator-doc-link fitted\" rel=\"noreferrer\" target=\"_blank\" href=\"https://scikit-learn.org/1.7/modules/generated/sklearn.linear_model.LogisticRegression.html\">?<span>Documentation for LogisticRegression</span></a></div></label><div class=\"sk-toggleable__content fitted\" data-param-prefix=\"estimator__\">\n",
       "        <div class=\"estimator-table\">\n",
       "            <details>\n",
       "                <summary>Parameters</summary>\n",
       "                <table class=\"parameters-table\">\n",
       "                  <tbody>\n",
       "                    \n",
       "        <tr class=\"default\">\n",
       "            <td><i class=\"copy-paste-icon\"\n",
       "                 onclick=\"copyToClipboard('penalty',\n",
       "                          this.parentElement.nextElementSibling)\"\n",
       "            ></i></td>\n",
       "            <td class=\"param\">penalty&nbsp;</td>\n",
       "            <td class=\"value\">&#x27;l2&#x27;</td>\n",
       "        </tr>\n",
       "    \n",
       "\n",
       "        <tr class=\"default\">\n",
       "            <td><i class=\"copy-paste-icon\"\n",
       "                 onclick=\"copyToClipboard('dual',\n",
       "                          this.parentElement.nextElementSibling)\"\n",
       "            ></i></td>\n",
       "            <td class=\"param\">dual&nbsp;</td>\n",
       "            <td class=\"value\">False</td>\n",
       "        </tr>\n",
       "    \n",
       "\n",
       "        <tr class=\"default\">\n",
       "            <td><i class=\"copy-paste-icon\"\n",
       "                 onclick=\"copyToClipboard('tol',\n",
       "                          this.parentElement.nextElementSibling)\"\n",
       "            ></i></td>\n",
       "            <td class=\"param\">tol&nbsp;</td>\n",
       "            <td class=\"value\">0.0001</td>\n",
       "        </tr>\n",
       "    \n",
       "\n",
       "        <tr class=\"default\">\n",
       "            <td><i class=\"copy-paste-icon\"\n",
       "                 onclick=\"copyToClipboard('C',\n",
       "                          this.parentElement.nextElementSibling)\"\n",
       "            ></i></td>\n",
       "            <td class=\"param\">C&nbsp;</td>\n",
       "            <td class=\"value\">1.0</td>\n",
       "        </tr>\n",
       "    \n",
       "\n",
       "        <tr class=\"default\">\n",
       "            <td><i class=\"copy-paste-icon\"\n",
       "                 onclick=\"copyToClipboard('fit_intercept',\n",
       "                          this.parentElement.nextElementSibling)\"\n",
       "            ></i></td>\n",
       "            <td class=\"param\">fit_intercept&nbsp;</td>\n",
       "            <td class=\"value\">True</td>\n",
       "        </tr>\n",
       "    \n",
       "\n",
       "        <tr class=\"default\">\n",
       "            <td><i class=\"copy-paste-icon\"\n",
       "                 onclick=\"copyToClipboard('intercept_scaling',\n",
       "                          this.parentElement.nextElementSibling)\"\n",
       "            ></i></td>\n",
       "            <td class=\"param\">intercept_scaling&nbsp;</td>\n",
       "            <td class=\"value\">1</td>\n",
       "        </tr>\n",
       "    \n",
       "\n",
       "        <tr class=\"default\">\n",
       "            <td><i class=\"copy-paste-icon\"\n",
       "                 onclick=\"copyToClipboard('class_weight',\n",
       "                          this.parentElement.nextElementSibling)\"\n",
       "            ></i></td>\n",
       "            <td class=\"param\">class_weight&nbsp;</td>\n",
       "            <td class=\"value\">None</td>\n",
       "        </tr>\n",
       "    \n",
       "\n",
       "        <tr class=\"default\">\n",
       "            <td><i class=\"copy-paste-icon\"\n",
       "                 onclick=\"copyToClipboard('random_state',\n",
       "                          this.parentElement.nextElementSibling)\"\n",
       "            ></i></td>\n",
       "            <td class=\"param\">random_state&nbsp;</td>\n",
       "            <td class=\"value\">None</td>\n",
       "        </tr>\n",
       "    \n",
       "\n",
       "        <tr class=\"default\">\n",
       "            <td><i class=\"copy-paste-icon\"\n",
       "                 onclick=\"copyToClipboard('solver',\n",
       "                          this.parentElement.nextElementSibling)\"\n",
       "            ></i></td>\n",
       "            <td class=\"param\">solver&nbsp;</td>\n",
       "            <td class=\"value\">&#x27;lbfgs&#x27;</td>\n",
       "        </tr>\n",
       "    \n",
       "\n",
       "        <tr class=\"user-set\">\n",
       "            <td><i class=\"copy-paste-icon\"\n",
       "                 onclick=\"copyToClipboard('max_iter',\n",
       "                          this.parentElement.nextElementSibling)\"\n",
       "            ></i></td>\n",
       "            <td class=\"param\">max_iter&nbsp;</td>\n",
       "            <td class=\"value\">1000</td>\n",
       "        </tr>\n",
       "    \n",
       "\n",
       "        <tr class=\"default\">\n",
       "            <td><i class=\"copy-paste-icon\"\n",
       "                 onclick=\"copyToClipboard('multi_class',\n",
       "                          this.parentElement.nextElementSibling)\"\n",
       "            ></i></td>\n",
       "            <td class=\"param\">multi_class&nbsp;</td>\n",
       "            <td class=\"value\">&#x27;deprecated&#x27;</td>\n",
       "        </tr>\n",
       "    \n",
       "\n",
       "        <tr class=\"default\">\n",
       "            <td><i class=\"copy-paste-icon\"\n",
       "                 onclick=\"copyToClipboard('verbose',\n",
       "                          this.parentElement.nextElementSibling)\"\n",
       "            ></i></td>\n",
       "            <td class=\"param\">verbose&nbsp;</td>\n",
       "            <td class=\"value\">0</td>\n",
       "        </tr>\n",
       "    \n",
       "\n",
       "        <tr class=\"default\">\n",
       "            <td><i class=\"copy-paste-icon\"\n",
       "                 onclick=\"copyToClipboard('warm_start',\n",
       "                          this.parentElement.nextElementSibling)\"\n",
       "            ></i></td>\n",
       "            <td class=\"param\">warm_start&nbsp;</td>\n",
       "            <td class=\"value\">False</td>\n",
       "        </tr>\n",
       "    \n",
       "\n",
       "        <tr class=\"default\">\n",
       "            <td><i class=\"copy-paste-icon\"\n",
       "                 onclick=\"copyToClipboard('n_jobs',\n",
       "                          this.parentElement.nextElementSibling)\"\n",
       "            ></i></td>\n",
       "            <td class=\"param\">n_jobs&nbsp;</td>\n",
       "            <td class=\"value\">None</td>\n",
       "        </tr>\n",
       "    \n",
       "\n",
       "        <tr class=\"default\">\n",
       "            <td><i class=\"copy-paste-icon\"\n",
       "                 onclick=\"copyToClipboard('l1_ratio',\n",
       "                          this.parentElement.nextElementSibling)\"\n",
       "            ></i></td>\n",
       "            <td class=\"param\">l1_ratio&nbsp;</td>\n",
       "            <td class=\"value\">None</td>\n",
       "        </tr>\n",
       "    \n",
       "                  </tbody>\n",
       "                </table>\n",
       "            </details>\n",
       "        </div>\n",
       "    </div></div></div></div></div></div></div></div></div></div><script>function copyToClipboard(text, element) {\n",
       "    // Get the parameter prefix from the closest toggleable content\n",
       "    const toggleableContent = element.closest('.sk-toggleable__content');\n",
       "    const paramPrefix = toggleableContent ? toggleableContent.dataset.paramPrefix : '';\n",
       "    const fullParamName = paramPrefix ? `${paramPrefix}${text}` : text;\n",
       "\n",
       "    const originalStyle = element.style;\n",
       "    const computedStyle = window.getComputedStyle(element);\n",
       "    const originalWidth = computedStyle.width;\n",
       "    const originalHTML = element.innerHTML.replace('Copied!', '');\n",
       "\n",
       "    navigator.clipboard.writeText(fullParamName)\n",
       "        .then(() => {\n",
       "            element.style.width = originalWidth;\n",
       "            element.style.color = 'green';\n",
       "            element.innerHTML = \"Copied!\";\n",
       "\n",
       "            setTimeout(() => {\n",
       "                element.innerHTML = originalHTML;\n",
       "                element.style = originalStyle;\n",
       "            }, 2000);\n",
       "        })\n",
       "        .catch(err => {\n",
       "            console.error('Failed to copy:', err);\n",
       "            element.style.color = 'red';\n",
       "            element.innerHTML = \"Failed!\";\n",
       "            setTimeout(() => {\n",
       "                element.innerHTML = originalHTML;\n",
       "                element.style = originalStyle;\n",
       "            }, 2000);\n",
       "        });\n",
       "    return false;\n",
       "}\n",
       "\n",
       "document.querySelectorAll('.fa-regular.fa-copy').forEach(function(element) {\n",
       "    const toggleableContent = element.closest('.sk-toggleable__content');\n",
       "    const paramPrefix = toggleableContent ? toggleableContent.dataset.paramPrefix : '';\n",
       "    const paramName = element.parentElement.nextElementSibling.textContent.trim();\n",
       "    const fullParamName = paramPrefix ? `${paramPrefix}${paramName}` : paramName;\n",
       "\n",
       "    element.setAttribute('title', fullParamName);\n",
       "});\n",
       "</script></body>"
      ],
      "text/plain": [
       "OneVsRestClassifier(estimator=LogisticRegression(max_iter=1000))"
      ]
     },
     "execution_count": 35,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.multiclass import OneVsRestClassifier\n",
    "\n",
    "clf = OneVsRestClassifier(LogisticRegression(max_iter=1000))\n",
    "clf.fit(X_train_sbert, y_train)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "0604b82a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "F1 micro : 0.17145418807545088\n",
      "F1 macro : 0.11193620140416258\n",
      "Hamming loss : 0.04129485769283652\n",
      "\n",
      "Classification report:\n",
      "                precision    recall  f1-score   support\n",
      "\n",
      "    admiration       0.56      0.18      0.28      1691\n",
      "     amusement       0.59      0.24      0.34       926\n",
      "         anger       0.64      0.07      0.12       861\n",
      "     annoyance       0.50      0.00      0.00      1353\n",
      "      approval       0.55      0.01      0.02      1794\n",
      "        caring       0.41      0.02      0.04       577\n",
      "     confusion       0.37      0.01      0.02       721\n",
      "     curiosity       0.38      0.02      0.04       947\n",
      "        desire       0.41      0.03      0.06       361\n",
      "disappointment       0.50      0.00      0.01       849\n",
      "   disapproval       0.32      0.01      0.01      1184\n",
      "       disgust       0.55      0.04      0.08       550\n",
      " embarrassment       0.67      0.01      0.01       264\n",
      "    excitement       0.69      0.02      0.04       553\n",
      "          fear       0.64      0.12      0.21       318\n",
      "     gratitude       0.80      0.53      0.64      1162\n",
      "         grief       0.57      0.06      0.11        66\n",
      "           joy       0.52      0.06      0.11       779\n",
      "          love       0.65      0.25      0.36       812\n",
      "   nervousness       0.00      0.00      0.00       186\n",
      "      optimism       0.62      0.07      0.13       875\n",
      "         pride       0.50      0.01      0.02       124\n",
      "   realization       0.67      0.00      0.00       870\n",
      "        relief       0.00      0.00      0.00       146\n",
      "       remorse       0.39      0.07      0.12       266\n",
      "       sadness       0.49      0.07      0.12       677\n",
      "      surprise       0.52      0.02      0.04       548\n",
      "       neutral       0.58      0.13      0.22      5484\n",
      "\n",
      "     micro avg       0.61      0.10      0.17     24944\n",
      "     macro avg       0.50      0.07      0.11     24944\n",
      "  weighted avg       0.54      0.10      0.15     24944\n",
      "   samples avg       0.11      0.10      0.11     24944\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\Yann\\Desktop\\DEV\\School\\ml_m1\\NLP\\CustomGPT\\scraper_env\\Lib\\site-packages\\sklearn\\metrics\\_classification.py:1706: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", result.shape[0])\n",
      "c:\\Users\\Yann\\Desktop\\DEV\\School\\ml_m1\\NLP\\CustomGPT\\scraper_env\\Lib\\site-packages\\sklearn\\metrics\\_classification.py:1706: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in samples with no predicted labels. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", result.shape[0])\n"
     ]
    }
   ],
   "source": [
    "from sklearn.metrics import f1_score, hamming_loss, classification_report\n",
    "\n",
    "y_val_pred = clf.predict(X_val_sbert)\n",
    "\n",
    "print(\"F1 micro :\", f1_score(y_val, y_val_pred, average='micro'))\n",
    "print(\"F1 macro :\", f1_score(y_val, y_val_pred, average='macro'))\n",
    "print(\"Hamming loss :\", hamming_loss(y_val, y_val_pred))\n",
    "\n",
    "print(\"\\nClassification report:\")\n",
    "print(classification_report(y_val, y_val_pred, target_names=label_cols))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4a12d87b",
   "metadata": {},
   "source": [
    "### avec mlp classifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "7fa45871",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Iteration 1, loss = 0.21986692\n",
      "Iteration 2, loss = 0.19305314\n",
      "Iteration 3, loss = 0.17824142\n",
      "Iteration 4, loss = 0.16471129\n",
      "Iteration 5, loss = 0.15467911\n",
      "Iteration 6, loss = 0.14669098\n",
      "Iteration 7, loss = 0.13943275\n",
      "Iteration 8, loss = 0.13369726\n",
      "Iteration 9, loss = 0.12865318\n",
      "Iteration 10, loss = 0.12350687\n",
      "Iteration 11, loss = 0.11949993\n",
      "Iteration 12, loss = 0.11643600\n",
      "Iteration 13, loss = 0.11331633\n",
      "Iteration 14, loss = 0.11076156\n",
      "Iteration 15, loss = 0.10934652\n",
      "Iteration 16, loss = 0.10726288\n",
      "Iteration 17, loss = 0.10634303\n",
      "Iteration 18, loss = 0.10477844\n",
      "Iteration 19, loss = 0.10327573\n",
      "Iteration 20, loss = 0.10274079\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\Yann\\Desktop\\DEV\\School\\ml_m1\\NLP\\CustomGPT\\scraper_env\\Lib\\site-packages\\sklearn\\neural_network\\_multilayer_perceptron.py:780: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (20) reached and the optimization hasn't converged yet.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Iteration 1, loss = 0.12599606\n",
      "Iteration 2, loss = 0.10311343\n",
      "Iteration 3, loss = 0.09457339\n",
      "Iteration 4, loss = 0.08712915\n",
      "Iteration 5, loss = 0.08078063\n",
      "Iteration 6, loss = 0.07554254\n",
      "Iteration 7, loss = 0.07154427\n",
      "Iteration 8, loss = 0.06826224\n",
      "Iteration 9, loss = 0.06548278\n",
      "Iteration 10, loss = 0.06318733\n",
      "Iteration 11, loss = 0.06140198\n",
      "Iteration 12, loss = 0.06017107\n",
      "Iteration 13, loss = 0.05899674\n",
      "Iteration 14, loss = 0.05787746\n",
      "Iteration 15, loss = 0.05764246\n",
      "Iteration 16, loss = 0.05706182\n",
      "Iteration 17, loss = 0.05579393\n",
      "Iteration 18, loss = 0.05525192\n",
      "Iteration 19, loss = 0.05450841\n",
      "Iteration 20, loss = 0.05426705\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\Yann\\Desktop\\DEV\\School\\ml_m1\\NLP\\CustomGPT\\scraper_env\\Lib\\site-packages\\sklearn\\neural_network\\_multilayer_perceptron.py:780: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (20) reached and the optimization hasn't converged yet.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Iteration 1, loss = 0.14220202\n",
      "Iteration 2, loss = 0.12456014\n",
      "Iteration 3, loss = 0.11656936\n",
      "Iteration 4, loss = 0.10790627\n",
      "Iteration 5, loss = 0.10010375\n",
      "Iteration 6, loss = 0.09336265\n",
      "Iteration 7, loss = 0.08858336\n",
      "Iteration 8, loss = 0.08356459\n",
      "Iteration 9, loss = 0.07949730\n",
      "Iteration 10, loss = 0.07604662\n",
      "Iteration 11, loss = 0.07322515\n",
      "Iteration 12, loss = 0.07111472\n",
      "Iteration 13, loss = 0.06953017\n",
      "Iteration 14, loss = 0.06815846\n",
      "Iteration 15, loss = 0.06689049\n",
      "Iteration 16, loss = 0.06627899\n",
      "Iteration 17, loss = 0.06571420\n",
      "Iteration 18, loss = 0.06483582\n",
      "Iteration 19, loss = 0.06420318\n",
      "Iteration 20, loss = 0.06382241\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\Yann\\Desktop\\DEV\\School\\ml_m1\\NLP\\CustomGPT\\scraper_env\\Lib\\site-packages\\sklearn\\neural_network\\_multilayer_perceptron.py:780: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (20) reached and the optimization hasn't converged yet.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Iteration 1, loss = 0.22484454\n",
      "Iteration 2, loss = 0.21000523\n",
      "Iteration 3, loss = 0.20194615\n",
      "Iteration 4, loss = 0.19118952\n",
      "Iteration 5, loss = 0.18036498\n",
      "Iteration 6, loss = 0.17031885\n",
      "Iteration 7, loss = 0.16249609\n",
      "Iteration 8, loss = 0.15467265\n",
      "Iteration 9, loss = 0.14807867\n",
      "Iteration 10, loss = 0.14222257\n",
      "Iteration 11, loss = 0.13715812\n",
      "Iteration 12, loss = 0.13267870\n",
      "Iteration 13, loss = 0.13049360\n",
      "Iteration 14, loss = 0.12798267\n",
      "Iteration 15, loss = 0.12625500\n",
      "Iteration 16, loss = 0.12489548\n",
      "Iteration 17, loss = 0.12339525\n",
      "Iteration 18, loss = 0.12248488\n",
      "Iteration 19, loss = 0.12163333\n",
      "Iteration 20, loss = 0.12077859\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\Yann\\Desktop\\DEV\\School\\ml_m1\\NLP\\CustomGPT\\scraper_env\\Lib\\site-packages\\sklearn\\neural_network\\_multilayer_perceptron.py:780: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (20) reached and the optimization hasn't converged yet.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Iteration 1, loss = 0.28106834\n",
      "Iteration 2, loss = 0.26721938\n",
      "Iteration 3, loss = 0.25799075\n",
      "Iteration 4, loss = 0.24541936\n",
      "Iteration 5, loss = 0.23291305\n",
      "Iteration 6, loss = 0.22204109\n",
      "Iteration 7, loss = 0.21304375\n",
      "Iteration 8, loss = 0.20522299\n",
      "Iteration 9, loss = 0.19819914\n",
      "Iteration 10, loss = 0.19127076\n",
      "Iteration 11, loss = 0.18524697\n",
      "Iteration 12, loss = 0.17940470\n",
      "Iteration 13, loss = 0.17397063\n",
      "Iteration 14, loss = 0.16970803\n",
      "Iteration 15, loss = 0.16580636\n",
      "Iteration 16, loss = 0.16275250\n",
      "Iteration 17, loss = 0.16005243\n",
      "Iteration 18, loss = 0.15919306\n",
      "Iteration 19, loss = 0.15672173\n",
      "Iteration 20, loss = 0.15579056\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\Yann\\Desktop\\DEV\\School\\ml_m1\\NLP\\CustomGPT\\scraper_env\\Lib\\site-packages\\sklearn\\neural_network\\_multilayer_perceptron.py:780: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (20) reached and the optimization hasn't converged yet.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Iteration 1, loss = 0.11658256\n",
      "Iteration 2, loss = 0.10127100\n",
      "Iteration 3, loss = 0.09525753\n",
      "Iteration 4, loss = 0.08832716\n",
      "Iteration 5, loss = 0.08178068\n",
      "Iteration 6, loss = 0.07587272\n",
      "Iteration 7, loss = 0.07099567\n",
      "Iteration 8, loss = 0.06646199\n",
      "Iteration 9, loss = 0.06274055\n",
      "Iteration 10, loss = 0.05954075\n",
      "Iteration 11, loss = 0.05740272\n",
      "Iteration 12, loss = 0.05629848\n",
      "Iteration 13, loss = 0.05501615\n",
      "Iteration 14, loss = 0.05428924\n",
      "Iteration 15, loss = 0.05364764\n",
      "Iteration 16, loss = 0.05294039\n",
      "Iteration 17, loss = 0.05282167\n",
      "Iteration 18, loss = 0.05208909\n",
      "Iteration 19, loss = 0.05213623\n",
      "Iteration 20, loss = 0.05154515\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\Yann\\Desktop\\DEV\\School\\ml_m1\\NLP\\CustomGPT\\scraper_env\\Lib\\site-packages\\sklearn\\neural_network\\_multilayer_perceptron.py:780: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (20) reached and the optimization hasn't converged yet.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Iteration 1, loss = 0.14070392\n",
      "Iteration 2, loss = 0.12460201\n",
      "Iteration 3, loss = 0.11570904\n",
      "Iteration 4, loss = 0.10573691\n",
      "Iteration 5, loss = 0.09752443\n",
      "Iteration 6, loss = 0.09094967\n",
      "Iteration 7, loss = 0.08545545\n",
      "Iteration 8, loss = 0.08046631\n",
      "Iteration 9, loss = 0.07570058\n",
      "Iteration 10, loss = 0.07249880\n",
      "Iteration 11, loss = 0.06946358\n",
      "Iteration 12, loss = 0.06774599\n",
      "Iteration 13, loss = 0.06580001\n",
      "Iteration 14, loss = 0.06485614\n",
      "Iteration 15, loss = 0.06377250\n",
      "Iteration 16, loss = 0.06366162\n",
      "Iteration 17, loss = 0.06225785\n",
      "Iteration 18, loss = 0.06229789\n",
      "Iteration 19, loss = 0.06193088\n",
      "Iteration 20, loss = 0.06129057\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\Yann\\Desktop\\DEV\\School\\ml_m1\\NLP\\CustomGPT\\scraper_env\\Lib\\site-packages\\sklearn\\neural_network\\_multilayer_perceptron.py:780: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (20) reached and the optimization hasn't converged yet.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Iteration 1, loss = 0.16380833\n",
      "Iteration 2, loss = 0.14141260\n",
      "Iteration 3, loss = 0.12780949\n",
      "Iteration 4, loss = 0.11654256\n",
      "Iteration 5, loss = 0.10750771\n",
      "Iteration 6, loss = 0.10055853\n",
      "Iteration 7, loss = 0.09516022\n",
      "Iteration 8, loss = 0.09013545\n",
      "Iteration 9, loss = 0.08591178\n",
      "Iteration 10, loss = 0.08238027\n",
      "Iteration 11, loss = 0.07936420\n",
      "Iteration 12, loss = 0.07772272\n",
      "Iteration 13, loss = 0.07592918\n",
      "Iteration 14, loss = 0.07484652\n",
      "Iteration 15, loss = 0.07392341\n",
      "Iteration 16, loss = 0.07265243\n",
      "Iteration 17, loss = 0.07285233\n",
      "Iteration 18, loss = 0.07147269\n",
      "Iteration 19, loss = 0.07032109\n",
      "Iteration 20, loss = 0.06980505\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\Yann\\Desktop\\DEV\\School\\ml_m1\\NLP\\CustomGPT\\scraper_env\\Lib\\site-packages\\sklearn\\neural_network\\_multilayer_perceptron.py:780: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (20) reached and the optimization hasn't converged yet.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Iteration 1, loss = 0.08602253\n",
      "Iteration 2, loss = 0.07097477\n",
      "Iteration 3, loss = 0.06652403\n",
      "Iteration 4, loss = 0.06128657\n",
      "Iteration 5, loss = 0.05606116\n",
      "Iteration 6, loss = 0.05159494\n",
      "Iteration 7, loss = 0.04796888\n",
      "Iteration 8, loss = 0.04423474\n",
      "Iteration 9, loss = 0.04147941\n",
      "Iteration 10, loss = 0.03908884\n",
      "Iteration 11, loss = 0.03726738\n",
      "Iteration 12, loss = 0.03619322\n",
      "Iteration 13, loss = 0.03536247\n",
      "Iteration 14, loss = 0.03514320\n",
      "Iteration 15, loss = 0.03457453\n",
      "Iteration 16, loss = 0.03398341\n",
      "Iteration 17, loss = 0.03383317\n",
      "Iteration 18, loss = 0.03380058\n",
      "Iteration 19, loss = 0.03323805\n",
      "Iteration 20, loss = 0.03313045\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\Yann\\Desktop\\DEV\\School\\ml_m1\\NLP\\CustomGPT\\scraper_env\\Lib\\site-packages\\sklearn\\neural_network\\_multilayer_perceptron.py:780: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (20) reached and the optimization hasn't converged yet.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Iteration 1, loss = 0.16286041\n",
      "Iteration 2, loss = 0.14890656\n",
      "Iteration 3, loss = 0.14288651\n",
      "Iteration 4, loss = 0.13491183\n",
      "Iteration 5, loss = 0.12594343\n",
      "Iteration 6, loss = 0.11831690\n",
      "Iteration 7, loss = 0.11169527\n",
      "Iteration 8, loss = 0.10572752\n",
      "Iteration 9, loss = 0.09984867\n",
      "Iteration 10, loss = 0.09469124\n",
      "Iteration 11, loss = 0.09077607\n",
      "Iteration 12, loss = 0.08802819\n",
      "Iteration 13, loss = 0.08561424\n",
      "Iteration 14, loss = 0.08408451\n",
      "Iteration 15, loss = 0.08319266\n",
      "Iteration 16, loss = 0.08201582\n",
      "Iteration 17, loss = 0.08131265\n",
      "Iteration 18, loss = 0.08031399\n",
      "Iteration 19, loss = 0.07986766\n",
      "Iteration 20, loss = 0.07932615\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\Yann\\Desktop\\DEV\\School\\ml_m1\\NLP\\CustomGPT\\scraper_env\\Lib\\site-packages\\sklearn\\neural_network\\_multilayer_perceptron.py:780: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (20) reached and the optimization hasn't converged yet.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Iteration 1, loss = 0.19535814\n",
      "Iteration 2, loss = 0.17958074\n",
      "Iteration 3, loss = 0.17149224\n",
      "Iteration 4, loss = 0.16124002\n",
      "Iteration 5, loss = 0.15114734\n",
      "Iteration 6, loss = 0.14206360\n",
      "Iteration 7, loss = 0.13529789\n",
      "Iteration 8, loss = 0.12889064\n",
      "Iteration 9, loss = 0.12303168\n",
      "Iteration 10, loss = 0.11773935\n",
      "Iteration 11, loss = 0.11291431\n",
      "Iteration 12, loss = 0.10955768\n",
      "Iteration 13, loss = 0.10675005\n",
      "Iteration 14, loss = 0.10507680\n",
      "Iteration 15, loss = 0.10271345\n",
      "Iteration 16, loss = 0.10182105\n",
      "Iteration 17, loss = 0.10171381\n",
      "Iteration 18, loss = 0.09980111\n",
      "Iteration 19, loss = 0.09941791\n",
      "Iteration 20, loss = 0.09885785\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\Yann\\Desktop\\DEV\\School\\ml_m1\\NLP\\CustomGPT\\scraper_env\\Lib\\site-packages\\sklearn\\neural_network\\_multilayer_perceptron.py:780: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (20) reached and the optimization hasn't converged yet.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Iteration 1, loss = 0.10817597\n",
      "Iteration 2, loss = 0.09301056\n",
      "Iteration 3, loss = 0.08743686\n",
      "Iteration 4, loss = 0.08113946\n",
      "Iteration 5, loss = 0.07474996\n",
      "Iteration 6, loss = 0.06923454\n",
      "Iteration 7, loss = 0.06464009\n",
      "Iteration 8, loss = 0.06021698\n",
      "Iteration 9, loss = 0.05675162\n",
      "Iteration 10, loss = 0.05405974\n",
      "Iteration 11, loss = 0.05173599\n",
      "Iteration 12, loss = 0.05070184\n",
      "Iteration 13, loss = 0.04988718\n",
      "Iteration 14, loss = 0.04927632\n",
      "Iteration 15, loss = 0.04870519\n",
      "Iteration 16, loss = 0.04802581\n",
      "Iteration 17, loss = 0.04788623\n",
      "Iteration 18, loss = 0.04701611\n",
      "Iteration 19, loss = 0.04701618\n",
      "Iteration 20, loss = 0.04675985\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\Yann\\Desktop\\DEV\\School\\ml_m1\\NLP\\CustomGPT\\scraper_env\\Lib\\site-packages\\sklearn\\neural_network\\_multilayer_perceptron.py:780: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (20) reached and the optimization hasn't converged yet.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Iteration 1, loss = 0.06690853\n",
      "Iteration 2, loss = 0.05286465\n",
      "Iteration 3, loss = 0.04883753\n",
      "Iteration 4, loss = 0.04436532\n",
      "Iteration 5, loss = 0.04019703\n",
      "Iteration 6, loss = 0.03640592\n",
      "Iteration 7, loss = 0.03345410\n",
      "Iteration 8, loss = 0.03043449\n",
      "Iteration 9, loss = 0.02840380\n",
      "Iteration 10, loss = 0.02670081\n",
      "Iteration 11, loss = 0.02574117\n",
      "Iteration 12, loss = 0.02529667\n",
      "Iteration 13, loss = 0.02454839\n",
      "Iteration 14, loss = 0.02444286\n",
      "Iteration 15, loss = 0.02482531\n",
      "Iteration 16, loss = 0.02383873\n",
      "Iteration 17, loss = 0.02388661\n",
      "Iteration 18, loss = 0.02350931\n",
      "Iteration 19, loss = 0.02370081\n",
      "Iteration 20, loss = 0.02315832\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\Yann\\Desktop\\DEV\\School\\ml_m1\\NLP\\CustomGPT\\scraper_env\\Lib\\site-packages\\sklearn\\neural_network\\_multilayer_perceptron.py:780: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (20) reached and the optimization hasn't converged yet.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Iteration 1, loss = 0.11505455\n",
      "Iteration 2, loss = 0.10036071\n",
      "Iteration 3, loss = 0.09503470\n",
      "Iteration 4, loss = 0.08890145\n",
      "Iteration 5, loss = 0.08186268\n",
      "Iteration 6, loss = 0.07593448\n",
      "Iteration 7, loss = 0.07058536\n",
      "Iteration 8, loss = 0.06613515\n",
      "Iteration 9, loss = 0.06206822\n",
      "Iteration 10, loss = 0.05889191\n",
      "Iteration 11, loss = 0.05669696\n",
      "Iteration 12, loss = 0.05526415\n",
      "Iteration 13, loss = 0.05416003\n",
      "Iteration 14, loss = 0.05336752\n",
      "Iteration 15, loss = 0.05308538\n",
      "Iteration 16, loss = 0.05226486\n",
      "Iteration 17, loss = 0.05173460\n",
      "Iteration 18, loss = 0.05141752\n",
      "Iteration 19, loss = 0.05064400\n",
      "Iteration 20, loss = 0.05110541\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\Yann\\Desktop\\DEV\\School\\ml_m1\\NLP\\CustomGPT\\scraper_env\\Lib\\site-packages\\sklearn\\neural_network\\_multilayer_perceptron.py:780: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (20) reached and the optimization hasn't converged yet.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Iteration 1, loss = 0.06902676\n",
      "Iteration 2, loss = 0.05334634\n",
      "Iteration 3, loss = 0.04863715\n",
      "Iteration 4, loss = 0.04386135\n",
      "Iteration 5, loss = 0.03977990\n",
      "Iteration 6, loss = 0.03668959\n",
      "Iteration 7, loss = 0.03414646\n",
      "Iteration 8, loss = 0.03185608\n",
      "Iteration 9, loss = 0.02965885\n",
      "Iteration 10, loss = 0.02816574\n",
      "Iteration 11, loss = 0.02713219\n",
      "Iteration 12, loss = 0.02626935\n",
      "Iteration 13, loss = 0.02569828\n",
      "Iteration 14, loss = 0.02544194\n",
      "Iteration 15, loss = 0.02505619\n",
      "Iteration 16, loss = 0.02450042\n",
      "Iteration 17, loss = 0.02438995\n",
      "Iteration 18, loss = 0.02451284\n",
      "Iteration 19, loss = 0.02388589\n",
      "Iteration 20, loss = 0.02420353\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\Yann\\Desktop\\DEV\\School\\ml_m1\\NLP\\CustomGPT\\scraper_env\\Lib\\site-packages\\sklearn\\neural_network\\_multilayer_perceptron.py:780: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (20) reached and the optimization hasn't converged yet.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Iteration 1, loss = 0.11112797\n",
      "Iteration 2, loss = 0.08202046\n",
      "Iteration 3, loss = 0.07205983\n",
      "Iteration 4, loss = 0.06549094\n",
      "Iteration 5, loss = 0.05989625\n",
      "Iteration 6, loss = 0.05594452\n",
      "Iteration 7, loss = 0.05201981\n",
      "Iteration 8, loss = 0.04939538\n",
      "Iteration 9, loss = 0.04660989\n",
      "Iteration 10, loss = 0.04474338\n",
      "Iteration 11, loss = 0.04301300\n",
      "Iteration 12, loss = 0.04170901\n",
      "Iteration 13, loss = 0.04061672\n",
      "Iteration 14, loss = 0.03978419\n",
      "Iteration 15, loss = 0.03924132\n",
      "Iteration 16, loss = 0.03858203\n",
      "Iteration 17, loss = 0.03761487\n",
      "Iteration 18, loss = 0.03717774\n",
      "Iteration 19, loss = 0.03663401\n",
      "Iteration 20, loss = 0.03593018\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\Yann\\Desktop\\DEV\\School\\ml_m1\\NLP\\CustomGPT\\scraper_env\\Lib\\site-packages\\sklearn\\neural_network\\_multilayer_perceptron.py:780: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (20) reached and the optimization hasn't converged yet.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Iteration 1, loss = 0.02763814\n",
      "Iteration 2, loss = 0.01583096\n",
      "Iteration 3, loss = 0.01455048\n",
      "Iteration 4, loss = 0.01329556\n",
      "Iteration 5, loss = 0.01207277\n",
      "Iteration 6, loss = 0.01071651\n",
      "Iteration 7, loss = 0.00955657\n",
      "Iteration 8, loss = 0.00876616\n",
      "Iteration 9, loss = 0.00822972\n",
      "Iteration 10, loss = 0.00784523\n",
      "Iteration 11, loss = 0.00777890\n",
      "Iteration 12, loss = 0.00764137\n",
      "Iteration 13, loss = 0.00763616\n",
      "Iteration 14, loss = 0.00738454\n",
      "Iteration 15, loss = 0.00746235\n",
      "Iteration 16, loss = 0.00745161\n",
      "Iteration 17, loss = 0.00731057\n",
      "Iteration 18, loss = 0.00730013\n",
      "Iteration 19, loss = 0.00725803\n",
      "Iteration 20, loss = 0.00733322\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\Yann\\Desktop\\DEV\\School\\ml_m1\\NLP\\CustomGPT\\scraper_env\\Lib\\site-packages\\sklearn\\neural_network\\_multilayer_perceptron.py:780: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (20) reached and the optimization hasn't converged yet.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Iteration 1, loss = 0.14197987\n",
      "Iteration 2, loss = 0.12468423\n",
      "Iteration 3, loss = 0.11703386\n",
      "Iteration 4, loss = 0.10866064\n",
      "Iteration 5, loss = 0.10071975\n",
      "Iteration 6, loss = 0.09444843\n",
      "Iteration 7, loss = 0.08880284\n",
      "Iteration 8, loss = 0.08405653\n",
      "Iteration 9, loss = 0.07989156\n",
      "Iteration 10, loss = 0.07630331\n",
      "Iteration 11, loss = 0.07353374\n",
      "Iteration 12, loss = 0.07092211\n",
      "Iteration 13, loss = 0.06956470\n",
      "Iteration 14, loss = 0.06858303\n",
      "Iteration 15, loss = 0.06766008\n",
      "Iteration 16, loss = 0.06666340\n",
      "Iteration 17, loss = 0.06581681\n",
      "Iteration 18, loss = 0.06544484\n",
      "Iteration 19, loss = 0.06469750\n",
      "Iteration 20, loss = 0.06395559\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\Yann\\Desktop\\DEV\\School\\ml_m1\\NLP\\CustomGPT\\scraper_env\\Lib\\site-packages\\sklearn\\neural_network\\_multilayer_perceptron.py:780: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (20) reached and the optimization hasn't converged yet.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Iteration 1, loss = 0.11302744\n",
      "Iteration 2, loss = 0.08873964\n",
      "Iteration 3, loss = 0.07906562\n",
      "Iteration 4, loss = 0.07121962\n",
      "Iteration 5, loss = 0.06559820\n",
      "Iteration 6, loss = 0.06157832\n",
      "Iteration 7, loss = 0.05879101\n",
      "Iteration 8, loss = 0.05581812\n",
      "Iteration 9, loss = 0.05378522\n",
      "Iteration 10, loss = 0.05193468\n",
      "Iteration 11, loss = 0.05014802\n",
      "Iteration 12, loss = 0.04880574\n",
      "Iteration 13, loss = 0.04768527\n",
      "Iteration 14, loss = 0.04684928\n",
      "Iteration 15, loss = 0.04585848\n",
      "Iteration 16, loss = 0.04558884\n",
      "Iteration 17, loss = 0.04476257\n",
      "Iteration 18, loss = 0.04422596\n",
      "Iteration 19, loss = 0.04427024\n",
      "Iteration 20, loss = 0.04324533\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\Yann\\Desktop\\DEV\\School\\ml_m1\\NLP\\CustomGPT\\scraper_env\\Lib\\site-packages\\sklearn\\neural_network\\_multilayer_perceptron.py:780: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (20) reached and the optimization hasn't converged yet.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Iteration 1, loss = 0.05322185\n",
      "Iteration 2, loss = 0.04066343\n",
      "Iteration 3, loss = 0.03813088\n",
      "Iteration 4, loss = 0.03507599\n",
      "Iteration 5, loss = 0.03157612\n",
      "Iteration 6, loss = 0.02836487\n",
      "Iteration 7, loss = 0.02541628\n",
      "Iteration 8, loss = 0.02297511\n",
      "Iteration 9, loss = 0.02112148\n",
      "Iteration 10, loss = 0.02021175\n",
      "Iteration 11, loss = 0.01940890\n",
      "Iteration 12, loss = 0.01903354\n",
      "Iteration 13, loss = 0.01889126\n",
      "Iteration 14, loss = 0.01878952\n",
      "Iteration 15, loss = 0.01850361\n",
      "Iteration 16, loss = 0.01829892\n",
      "Iteration 17, loss = 0.01830303\n",
      "Iteration 18, loss = 0.01802578\n",
      "Iteration 19, loss = 0.01796645\n",
      "Iteration 20, loss = 0.01794031\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\Yann\\Desktop\\DEV\\School\\ml_m1\\NLP\\CustomGPT\\scraper_env\\Lib\\site-packages\\sklearn\\neural_network\\_multilayer_perceptron.py:780: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (20) reached and the optimization hasn't converged yet.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Iteration 1, loss = 0.15302809\n",
      "Iteration 2, loss = 0.13702803\n",
      "Iteration 3, loss = 0.12887174\n",
      "Iteration 4, loss = 0.12015634\n",
      "Iteration 5, loss = 0.11154347\n",
      "Iteration 6, loss = 0.10495176\n",
      "Iteration 7, loss = 0.09941668\n",
      "Iteration 8, loss = 0.09372627\n",
      "Iteration 9, loss = 0.09010163\n",
      "Iteration 10, loss = 0.08586969\n",
      "Iteration 11, loss = 0.08224388\n",
      "Iteration 12, loss = 0.07941818\n",
      "Iteration 13, loss = 0.07724380\n",
      "Iteration 14, loss = 0.07517376\n",
      "Iteration 15, loss = 0.07435162\n",
      "Iteration 16, loss = 0.07335034\n",
      "Iteration 17, loss = 0.07238931\n",
      "Iteration 18, loss = 0.07162154\n",
      "Iteration 19, loss = 0.07122480\n",
      "Iteration 20, loss = 0.07011413\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\Yann\\Desktop\\DEV\\School\\ml_m1\\NLP\\CustomGPT\\scraper_env\\Lib\\site-packages\\sklearn\\neural_network\\_multilayer_perceptron.py:780: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (20) reached and the optimization hasn't converged yet.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Iteration 1, loss = 0.04415253\n",
      "Iteration 2, loss = 0.03200970\n",
      "Iteration 3, loss = 0.02986606\n",
      "Iteration 4, loss = 0.02707106\n",
      "Iteration 5, loss = 0.02418485\n",
      "Iteration 6, loss = 0.02143494\n",
      "Iteration 7, loss = 0.01891345\n",
      "Iteration 8, loss = 0.01716271\n",
      "Iteration 9, loss = 0.01574071\n",
      "Iteration 10, loss = 0.01498298\n",
      "Iteration 11, loss = 0.01454859\n",
      "Iteration 12, loss = 0.01425185\n",
      "Iteration 13, loss = 0.01431676\n",
      "Iteration 14, loss = 0.01387720\n",
      "Iteration 15, loss = 0.01366061\n",
      "Iteration 16, loss = 0.01383680\n",
      "Iteration 17, loss = 0.01376801\n",
      "Iteration 18, loss = 0.01351573\n",
      "Iteration 19, loss = 0.01351111\n",
      "Iteration 20, loss = 0.01364468\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\Yann\\Desktop\\DEV\\School\\ml_m1\\NLP\\CustomGPT\\scraper_env\\Lib\\site-packages\\sklearn\\neural_network\\_multilayer_perceptron.py:780: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (20) reached and the optimization hasn't converged yet.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Iteration 1, loss = 0.17356787\n",
      "Iteration 2, loss = 0.16072728\n",
      "Iteration 3, loss = 0.15442358\n",
      "Iteration 4, loss = 0.14560434\n",
      "Iteration 5, loss = 0.13559328\n",
      "Iteration 6, loss = 0.12641299\n",
      "Iteration 7, loss = 0.11936253\n",
      "Iteration 8, loss = 0.11276043\n",
      "Iteration 9, loss = 0.10672125\n",
      "Iteration 10, loss = 0.10125894\n",
      "Iteration 11, loss = 0.09616919\n",
      "Iteration 12, loss = 0.09344387\n",
      "Iteration 13, loss = 0.09084049\n",
      "Iteration 14, loss = 0.08873157\n",
      "Iteration 15, loss = 0.08737248\n",
      "Iteration 16, loss = 0.08631135\n",
      "Iteration 17, loss = 0.08549653\n",
      "Iteration 18, loss = 0.08454730\n",
      "Iteration 19, loss = 0.08353776\n",
      "Iteration 20, loss = 0.08309167\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\Yann\\Desktop\\DEV\\School\\ml_m1\\NLP\\CustomGPT\\scraper_env\\Lib\\site-packages\\sklearn\\neural_network\\_multilayer_perceptron.py:780: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (20) reached and the optimization hasn't converged yet.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Iteration 1, loss = 0.04354122\n",
      "Iteration 2, loss = 0.03044390\n",
      "Iteration 3, loss = 0.02830864\n",
      "Iteration 4, loss = 0.02565419\n",
      "Iteration 5, loss = 0.02270127\n",
      "Iteration 6, loss = 0.02030025\n",
      "Iteration 7, loss = 0.01808602\n",
      "Iteration 8, loss = 0.01624441\n",
      "Iteration 9, loss = 0.01522417\n",
      "Iteration 10, loss = 0.01427573\n",
      "Iteration 11, loss = 0.01411033\n",
      "Iteration 12, loss = 0.01393278\n",
      "Iteration 13, loss = 0.01363864\n",
      "Iteration 14, loss = 0.01343269\n",
      "Iteration 15, loss = 0.01355809\n",
      "Iteration 16, loss = 0.01332113\n",
      "Iteration 17, loss = 0.01308031\n",
      "Iteration 18, loss = 0.01303931\n",
      "Iteration 19, loss = 0.01331016\n",
      "Iteration 20, loss = 0.01295032\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\Yann\\Desktop\\DEV\\School\\ml_m1\\NLP\\CustomGPT\\scraper_env\\Lib\\site-packages\\sklearn\\neural_network\\_multilayer_perceptron.py:780: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (20) reached and the optimization hasn't converged yet.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Iteration 1, loss = 0.05795269\n",
      "Iteration 2, loss = 0.04255196\n",
      "Iteration 3, loss = 0.03855637\n",
      "Iteration 4, loss = 0.03444878\n",
      "Iteration 5, loss = 0.03084770\n",
      "Iteration 6, loss = 0.02804317\n",
      "Iteration 7, loss = 0.02574265\n",
      "Iteration 8, loss = 0.02400435\n",
      "Iteration 9, loss = 0.02241114\n",
      "Iteration 10, loss = 0.02174906\n",
      "Iteration 11, loss = 0.02129824\n",
      "Iteration 12, loss = 0.02065870\n",
      "Iteration 13, loss = 0.02048138\n",
      "Iteration 14, loss = 0.02006424\n",
      "Iteration 15, loss = 0.01994440\n",
      "Iteration 16, loss = 0.02001213\n",
      "Iteration 17, loss = 0.01979881\n",
      "Iteration 18, loss = 0.01971657\n",
      "Iteration 19, loss = 0.01976974\n",
      "Iteration 20, loss = 0.01935669\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\Yann\\Desktop\\DEV\\School\\ml_m1\\NLP\\CustomGPT\\scraper_env\\Lib\\site-packages\\sklearn\\neural_network\\_multilayer_perceptron.py:780: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (20) reached and the optimization hasn't converged yet.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Iteration 1, loss = 0.12301517\n",
      "Iteration 2, loss = 0.10570285\n",
      "Iteration 3, loss = 0.09796888\n",
      "Iteration 4, loss = 0.09026852\n",
      "Iteration 5, loss = 0.08369714\n",
      "Iteration 6, loss = 0.07815925\n",
      "Iteration 7, loss = 0.07334826\n",
      "Iteration 8, loss = 0.06932704\n",
      "Iteration 9, loss = 0.06572730\n",
      "Iteration 10, loss = 0.06260721\n",
      "Iteration 11, loss = 0.06004691\n",
      "Iteration 12, loss = 0.05876481\n",
      "Iteration 13, loss = 0.05716512\n",
      "Iteration 14, loss = 0.05610670\n",
      "Iteration 15, loss = 0.05576520\n",
      "Iteration 16, loss = 0.05516378\n",
      "Iteration 17, loss = 0.05420250\n",
      "Iteration 18, loss = 0.05371004\n",
      "Iteration 19, loss = 0.05365214\n",
      "Iteration 20, loss = 0.05306532\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\Yann\\Desktop\\DEV\\School\\ml_m1\\NLP\\CustomGPT\\scraper_env\\Lib\\site-packages\\sklearn\\neural_network\\_multilayer_perceptron.py:780: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (20) reached and the optimization hasn't converged yet.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Iteration 1, loss = 0.11291589\n",
      "Iteration 2, loss = 0.09449249\n",
      "Iteration 3, loss = 0.08643902\n",
      "Iteration 4, loss = 0.07832517\n",
      "Iteration 5, loss = 0.07104563\n",
      "Iteration 6, loss = 0.06609949\n",
      "Iteration 7, loss = 0.06136418\n",
      "Iteration 8, loss = 0.05788745\n",
      "Iteration 9, loss = 0.05434005\n",
      "Iteration 10, loss = 0.05172277\n",
      "Iteration 11, loss = 0.04974597\n",
      "Iteration 12, loss = 0.04838614\n",
      "Iteration 13, loss = 0.04761345\n",
      "Iteration 14, loss = 0.04701968\n",
      "Iteration 15, loss = 0.04618861\n",
      "Iteration 16, loss = 0.04563381\n",
      "Iteration 17, loss = 0.04515845\n",
      "Iteration 18, loss = 0.04497259\n",
      "Iteration 19, loss = 0.04439057\n",
      "Iteration 20, loss = 0.04488172\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\Yann\\Desktop\\DEV\\School\\ml_m1\\NLP\\CustomGPT\\scraper_env\\Lib\\site-packages\\sklearn\\neural_network\\_multilayer_perceptron.py:780: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (20) reached and the optimization hasn't converged yet.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Iteration 1, loss = 0.53153437\n",
      "Iteration 2, loss = 0.51015658\n",
      "Iteration 3, loss = 0.49031114\n",
      "Iteration 4, loss = 0.47004409\n",
      "Iteration 5, loss = 0.45244934\n",
      "Iteration 6, loss = 0.43727421\n",
      "Iteration 7, loss = 0.42417862\n",
      "Iteration 8, loss = 0.41392867\n",
      "Iteration 9, loss = 0.40489105\n",
      "Iteration 10, loss = 0.39679347\n",
      "Iteration 11, loss = 0.39046795\n",
      "Iteration 12, loss = 0.38483285\n",
      "Iteration 13, loss = 0.37956390\n",
      "Iteration 14, loss = 0.37501145\n",
      "Iteration 15, loss = 0.36990656\n",
      "Iteration 16, loss = 0.36658136\n",
      "Iteration 17, loss = 0.36344834\n",
      "Iteration 18, loss = 0.35993986\n",
      "Iteration 19, loss = 0.35640361\n",
      "Iteration 20, loss = 0.35295308\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\Yann\\Desktop\\DEV\\School\\ml_m1\\NLP\\CustomGPT\\scraper_env\\Lib\\site-packages\\sklearn\\neural_network\\_multilayer_perceptron.py:780: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (20) reached and the optimization hasn't converged yet.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<style>#sk-container-id-4 {\n",
       "  /* Definition of color scheme common for light and dark mode */\n",
       "  --sklearn-color-text: #000;\n",
       "  --sklearn-color-text-muted: #666;\n",
       "  --sklearn-color-line: gray;\n",
       "  /* Definition of color scheme for unfitted estimators */\n",
       "  --sklearn-color-unfitted-level-0: #fff5e6;\n",
       "  --sklearn-color-unfitted-level-1: #f6e4d2;\n",
       "  --sklearn-color-unfitted-level-2: #ffe0b3;\n",
       "  --sklearn-color-unfitted-level-3: chocolate;\n",
       "  /* Definition of color scheme for fitted estimators */\n",
       "  --sklearn-color-fitted-level-0: #f0f8ff;\n",
       "  --sklearn-color-fitted-level-1: #d4ebff;\n",
       "  --sklearn-color-fitted-level-2: #b3dbfd;\n",
       "  --sklearn-color-fitted-level-3: cornflowerblue;\n",
       "\n",
       "  /* Specific color for light theme */\n",
       "  --sklearn-color-text-on-default-background: var(--sg-text-color, var(--theme-code-foreground, var(--jp-content-font-color1, black)));\n",
       "  --sklearn-color-background: var(--sg-background-color, var(--theme-background, var(--jp-layout-color0, white)));\n",
       "  --sklearn-color-border-box: var(--sg-text-color, var(--theme-code-foreground, var(--jp-content-font-color1, black)));\n",
       "  --sklearn-color-icon: #696969;\n",
       "\n",
       "  @media (prefers-color-scheme: dark) {\n",
       "    /* Redefinition of color scheme for dark theme */\n",
       "    --sklearn-color-text-on-default-background: var(--sg-text-color, var(--theme-code-foreground, var(--jp-content-font-color1, white)));\n",
       "    --sklearn-color-background: var(--sg-background-color, var(--theme-background, var(--jp-layout-color0, #111)));\n",
       "    --sklearn-color-border-box: var(--sg-text-color, var(--theme-code-foreground, var(--jp-content-font-color1, white)));\n",
       "    --sklearn-color-icon: #878787;\n",
       "  }\n",
       "}\n",
       "\n",
       "#sk-container-id-4 {\n",
       "  color: var(--sklearn-color-text);\n",
       "}\n",
       "\n",
       "#sk-container-id-4 pre {\n",
       "  padding: 0;\n",
       "}\n",
       "\n",
       "#sk-container-id-4 input.sk-hidden--visually {\n",
       "  border: 0;\n",
       "  clip: rect(1px 1px 1px 1px);\n",
       "  clip: rect(1px, 1px, 1px, 1px);\n",
       "  height: 1px;\n",
       "  margin: -1px;\n",
       "  overflow: hidden;\n",
       "  padding: 0;\n",
       "  position: absolute;\n",
       "  width: 1px;\n",
       "}\n",
       "\n",
       "#sk-container-id-4 div.sk-dashed-wrapped {\n",
       "  border: 1px dashed var(--sklearn-color-line);\n",
       "  margin: 0 0.4em 0.5em 0.4em;\n",
       "  box-sizing: border-box;\n",
       "  padding-bottom: 0.4em;\n",
       "  background-color: var(--sklearn-color-background);\n",
       "}\n",
       "\n",
       "#sk-container-id-4 div.sk-container {\n",
       "  /* jupyter's `normalize.less` sets `[hidden] { display: none; }`\n",
       "     but bootstrap.min.css set `[hidden] { display: none !important; }`\n",
       "     so we also need the `!important` here to be able to override the\n",
       "     default hidden behavior on the sphinx rendered scikit-learn.org.\n",
       "     See: https://github.com/scikit-learn/scikit-learn/issues/21755 */\n",
       "  display: inline-block !important;\n",
       "  position: relative;\n",
       "}\n",
       "\n",
       "#sk-container-id-4 div.sk-text-repr-fallback {\n",
       "  display: none;\n",
       "}\n",
       "\n",
       "div.sk-parallel-item,\n",
       "div.sk-serial,\n",
       "div.sk-item {\n",
       "  /* draw centered vertical line to link estimators */\n",
       "  background-image: linear-gradient(var(--sklearn-color-text-on-default-background), var(--sklearn-color-text-on-default-background));\n",
       "  background-size: 2px 100%;\n",
       "  background-repeat: no-repeat;\n",
       "  background-position: center center;\n",
       "}\n",
       "\n",
       "/* Parallel-specific style estimator block */\n",
       "\n",
       "#sk-container-id-4 div.sk-parallel-item::after {\n",
       "  content: \"\";\n",
       "  width: 100%;\n",
       "  border-bottom: 2px solid var(--sklearn-color-text-on-default-background);\n",
       "  flex-grow: 1;\n",
       "}\n",
       "\n",
       "#sk-container-id-4 div.sk-parallel {\n",
       "  display: flex;\n",
       "  align-items: stretch;\n",
       "  justify-content: center;\n",
       "  background-color: var(--sklearn-color-background);\n",
       "  position: relative;\n",
       "}\n",
       "\n",
       "#sk-container-id-4 div.sk-parallel-item {\n",
       "  display: flex;\n",
       "  flex-direction: column;\n",
       "}\n",
       "\n",
       "#sk-container-id-4 div.sk-parallel-item:first-child::after {\n",
       "  align-self: flex-end;\n",
       "  width: 50%;\n",
       "}\n",
       "\n",
       "#sk-container-id-4 div.sk-parallel-item:last-child::after {\n",
       "  align-self: flex-start;\n",
       "  width: 50%;\n",
       "}\n",
       "\n",
       "#sk-container-id-4 div.sk-parallel-item:only-child::after {\n",
       "  width: 0;\n",
       "}\n",
       "\n",
       "/* Serial-specific style estimator block */\n",
       "\n",
       "#sk-container-id-4 div.sk-serial {\n",
       "  display: flex;\n",
       "  flex-direction: column;\n",
       "  align-items: center;\n",
       "  background-color: var(--sklearn-color-background);\n",
       "  padding-right: 1em;\n",
       "  padding-left: 1em;\n",
       "}\n",
       "\n",
       "\n",
       "/* Toggleable style: style used for estimator/Pipeline/ColumnTransformer box that is\n",
       "clickable and can be expanded/collapsed.\n",
       "- Pipeline and ColumnTransformer use this feature and define the default style\n",
       "- Estimators will overwrite some part of the style using the `sk-estimator` class\n",
       "*/\n",
       "\n",
       "/* Pipeline and ColumnTransformer style (default) */\n",
       "\n",
       "#sk-container-id-4 div.sk-toggleable {\n",
       "  /* Default theme specific background. It is overwritten whether we have a\n",
       "  specific estimator or a Pipeline/ColumnTransformer */\n",
       "  background-color: var(--sklearn-color-background);\n",
       "}\n",
       "\n",
       "/* Toggleable label */\n",
       "#sk-container-id-4 label.sk-toggleable__label {\n",
       "  cursor: pointer;\n",
       "  display: flex;\n",
       "  width: 100%;\n",
       "  margin-bottom: 0;\n",
       "  padding: 0.5em;\n",
       "  box-sizing: border-box;\n",
       "  text-align: center;\n",
       "  align-items: start;\n",
       "  justify-content: space-between;\n",
       "  gap: 0.5em;\n",
       "}\n",
       "\n",
       "#sk-container-id-4 label.sk-toggleable__label .caption {\n",
       "  font-size: 0.6rem;\n",
       "  font-weight: lighter;\n",
       "  color: var(--sklearn-color-text-muted);\n",
       "}\n",
       "\n",
       "#sk-container-id-4 label.sk-toggleable__label-arrow:before {\n",
       "  /* Arrow on the left of the label */\n",
       "  content: \"▸\";\n",
       "  float: left;\n",
       "  margin-right: 0.25em;\n",
       "  color: var(--sklearn-color-icon);\n",
       "}\n",
       "\n",
       "#sk-container-id-4 label.sk-toggleable__label-arrow:hover:before {\n",
       "  color: var(--sklearn-color-text);\n",
       "}\n",
       "\n",
       "/* Toggleable content - dropdown */\n",
       "\n",
       "#sk-container-id-4 div.sk-toggleable__content {\n",
       "  display: none;\n",
       "  text-align: left;\n",
       "  /* unfitted */\n",
       "  background-color: var(--sklearn-color-unfitted-level-0);\n",
       "}\n",
       "\n",
       "#sk-container-id-4 div.sk-toggleable__content.fitted {\n",
       "  /* fitted */\n",
       "  background-color: var(--sklearn-color-fitted-level-0);\n",
       "}\n",
       "\n",
       "#sk-container-id-4 div.sk-toggleable__content pre {\n",
       "  margin: 0.2em;\n",
       "  border-radius: 0.25em;\n",
       "  color: var(--sklearn-color-text);\n",
       "  /* unfitted */\n",
       "  background-color: var(--sklearn-color-unfitted-level-0);\n",
       "}\n",
       "\n",
       "#sk-container-id-4 div.sk-toggleable__content.fitted pre {\n",
       "  /* unfitted */\n",
       "  background-color: var(--sklearn-color-fitted-level-0);\n",
       "}\n",
       "\n",
       "#sk-container-id-4 input.sk-toggleable__control:checked~div.sk-toggleable__content {\n",
       "  /* Expand drop-down */\n",
       "  display: block;\n",
       "  width: 100%;\n",
       "  overflow: visible;\n",
       "}\n",
       "\n",
       "#sk-container-id-4 input.sk-toggleable__control:checked~label.sk-toggleable__label-arrow:before {\n",
       "  content: \"▾\";\n",
       "}\n",
       "\n",
       "/* Pipeline/ColumnTransformer-specific style */\n",
       "\n",
       "#sk-container-id-4 div.sk-label input.sk-toggleable__control:checked~label.sk-toggleable__label {\n",
       "  color: var(--sklearn-color-text);\n",
       "  background-color: var(--sklearn-color-unfitted-level-2);\n",
       "}\n",
       "\n",
       "#sk-container-id-4 div.sk-label.fitted input.sk-toggleable__control:checked~label.sk-toggleable__label {\n",
       "  background-color: var(--sklearn-color-fitted-level-2);\n",
       "}\n",
       "\n",
       "/* Estimator-specific style */\n",
       "\n",
       "/* Colorize estimator box */\n",
       "#sk-container-id-4 div.sk-estimator input.sk-toggleable__control:checked~label.sk-toggleable__label {\n",
       "  /* unfitted */\n",
       "  background-color: var(--sklearn-color-unfitted-level-2);\n",
       "}\n",
       "\n",
       "#sk-container-id-4 div.sk-estimator.fitted input.sk-toggleable__control:checked~label.sk-toggleable__label {\n",
       "  /* fitted */\n",
       "  background-color: var(--sklearn-color-fitted-level-2);\n",
       "}\n",
       "\n",
       "#sk-container-id-4 div.sk-label label.sk-toggleable__label,\n",
       "#sk-container-id-4 div.sk-label label {\n",
       "  /* The background is the default theme color */\n",
       "  color: var(--sklearn-color-text-on-default-background);\n",
       "}\n",
       "\n",
       "/* On hover, darken the color of the background */\n",
       "#sk-container-id-4 div.sk-label:hover label.sk-toggleable__label {\n",
       "  color: var(--sklearn-color-text);\n",
       "  background-color: var(--sklearn-color-unfitted-level-2);\n",
       "}\n",
       "\n",
       "/* Label box, darken color on hover, fitted */\n",
       "#sk-container-id-4 div.sk-label.fitted:hover label.sk-toggleable__label.fitted {\n",
       "  color: var(--sklearn-color-text);\n",
       "  background-color: var(--sklearn-color-fitted-level-2);\n",
       "}\n",
       "\n",
       "/* Estimator label */\n",
       "\n",
       "#sk-container-id-4 div.sk-label label {\n",
       "  font-family: monospace;\n",
       "  font-weight: bold;\n",
       "  display: inline-block;\n",
       "  line-height: 1.2em;\n",
       "}\n",
       "\n",
       "#sk-container-id-4 div.sk-label-container {\n",
       "  text-align: center;\n",
       "}\n",
       "\n",
       "/* Estimator-specific */\n",
       "#sk-container-id-4 div.sk-estimator {\n",
       "  font-family: monospace;\n",
       "  border: 1px dotted var(--sklearn-color-border-box);\n",
       "  border-radius: 0.25em;\n",
       "  box-sizing: border-box;\n",
       "  margin-bottom: 0.5em;\n",
       "  /* unfitted */\n",
       "  background-color: var(--sklearn-color-unfitted-level-0);\n",
       "}\n",
       "\n",
       "#sk-container-id-4 div.sk-estimator.fitted {\n",
       "  /* fitted */\n",
       "  background-color: var(--sklearn-color-fitted-level-0);\n",
       "}\n",
       "\n",
       "/* on hover */\n",
       "#sk-container-id-4 div.sk-estimator:hover {\n",
       "  /* unfitted */\n",
       "  background-color: var(--sklearn-color-unfitted-level-2);\n",
       "}\n",
       "\n",
       "#sk-container-id-4 div.sk-estimator.fitted:hover {\n",
       "  /* fitted */\n",
       "  background-color: var(--sklearn-color-fitted-level-2);\n",
       "}\n",
       "\n",
       "/* Specification for estimator info (e.g. \"i\" and \"?\") */\n",
       "\n",
       "/* Common style for \"i\" and \"?\" */\n",
       "\n",
       ".sk-estimator-doc-link,\n",
       "a:link.sk-estimator-doc-link,\n",
       "a:visited.sk-estimator-doc-link {\n",
       "  float: right;\n",
       "  font-size: smaller;\n",
       "  line-height: 1em;\n",
       "  font-family: monospace;\n",
       "  background-color: var(--sklearn-color-background);\n",
       "  border-radius: 1em;\n",
       "  height: 1em;\n",
       "  width: 1em;\n",
       "  text-decoration: none !important;\n",
       "  margin-left: 0.5em;\n",
       "  text-align: center;\n",
       "  /* unfitted */\n",
       "  border: var(--sklearn-color-unfitted-level-1) 1pt solid;\n",
       "  color: var(--sklearn-color-unfitted-level-1);\n",
       "}\n",
       "\n",
       ".sk-estimator-doc-link.fitted,\n",
       "a:link.sk-estimator-doc-link.fitted,\n",
       "a:visited.sk-estimator-doc-link.fitted {\n",
       "  /* fitted */\n",
       "  border: var(--sklearn-color-fitted-level-1) 1pt solid;\n",
       "  color: var(--sklearn-color-fitted-level-1);\n",
       "}\n",
       "\n",
       "/* On hover */\n",
       "div.sk-estimator:hover .sk-estimator-doc-link:hover,\n",
       ".sk-estimator-doc-link:hover,\n",
       "div.sk-label-container:hover .sk-estimator-doc-link:hover,\n",
       ".sk-estimator-doc-link:hover {\n",
       "  /* unfitted */\n",
       "  background-color: var(--sklearn-color-unfitted-level-3);\n",
       "  color: var(--sklearn-color-background);\n",
       "  text-decoration: none;\n",
       "}\n",
       "\n",
       "div.sk-estimator.fitted:hover .sk-estimator-doc-link.fitted:hover,\n",
       ".sk-estimator-doc-link.fitted:hover,\n",
       "div.sk-label-container:hover .sk-estimator-doc-link.fitted:hover,\n",
       ".sk-estimator-doc-link.fitted:hover {\n",
       "  /* fitted */\n",
       "  background-color: var(--sklearn-color-fitted-level-3);\n",
       "  color: var(--sklearn-color-background);\n",
       "  text-decoration: none;\n",
       "}\n",
       "\n",
       "/* Span, style for the box shown on hovering the info icon */\n",
       ".sk-estimator-doc-link span {\n",
       "  display: none;\n",
       "  z-index: 9999;\n",
       "  position: relative;\n",
       "  font-weight: normal;\n",
       "  right: .2ex;\n",
       "  padding: .5ex;\n",
       "  margin: .5ex;\n",
       "  width: min-content;\n",
       "  min-width: 20ex;\n",
       "  max-width: 50ex;\n",
       "  color: var(--sklearn-color-text);\n",
       "  box-shadow: 2pt 2pt 4pt #999;\n",
       "  /* unfitted */\n",
       "  background: var(--sklearn-color-unfitted-level-0);\n",
       "  border: .5pt solid var(--sklearn-color-unfitted-level-3);\n",
       "}\n",
       "\n",
       ".sk-estimator-doc-link.fitted span {\n",
       "  /* fitted */\n",
       "  background: var(--sklearn-color-fitted-level-0);\n",
       "  border: var(--sklearn-color-fitted-level-3);\n",
       "}\n",
       "\n",
       ".sk-estimator-doc-link:hover span {\n",
       "  display: block;\n",
       "}\n",
       "\n",
       "/* \"?\"-specific style due to the `<a>` HTML tag */\n",
       "\n",
       "#sk-container-id-4 a.estimator_doc_link {\n",
       "  float: right;\n",
       "  font-size: 1rem;\n",
       "  line-height: 1em;\n",
       "  font-family: monospace;\n",
       "  background-color: var(--sklearn-color-background);\n",
       "  border-radius: 1rem;\n",
       "  height: 1rem;\n",
       "  width: 1rem;\n",
       "  text-decoration: none;\n",
       "  /* unfitted */\n",
       "  color: var(--sklearn-color-unfitted-level-1);\n",
       "  border: var(--sklearn-color-unfitted-level-1) 1pt solid;\n",
       "}\n",
       "\n",
       "#sk-container-id-4 a.estimator_doc_link.fitted {\n",
       "  /* fitted */\n",
       "  border: var(--sklearn-color-fitted-level-1) 1pt solid;\n",
       "  color: var(--sklearn-color-fitted-level-1);\n",
       "}\n",
       "\n",
       "/* On hover */\n",
       "#sk-container-id-4 a.estimator_doc_link:hover {\n",
       "  /* unfitted */\n",
       "  background-color: var(--sklearn-color-unfitted-level-3);\n",
       "  color: var(--sklearn-color-background);\n",
       "  text-decoration: none;\n",
       "}\n",
       "\n",
       "#sk-container-id-4 a.estimator_doc_link.fitted:hover {\n",
       "  /* fitted */\n",
       "  background-color: var(--sklearn-color-fitted-level-3);\n",
       "}\n",
       "\n",
       ".estimator-table summary {\n",
       "    padding: .5rem;\n",
       "    font-family: monospace;\n",
       "    cursor: pointer;\n",
       "}\n",
       "\n",
       ".estimator-table details[open] {\n",
       "    padding-left: 0.1rem;\n",
       "    padding-right: 0.1rem;\n",
       "    padding-bottom: 0.3rem;\n",
       "}\n",
       "\n",
       ".estimator-table .parameters-table {\n",
       "    margin-left: auto !important;\n",
       "    margin-right: auto !important;\n",
       "}\n",
       "\n",
       ".estimator-table .parameters-table tr:nth-child(odd) {\n",
       "    background-color: #fff;\n",
       "}\n",
       "\n",
       ".estimator-table .parameters-table tr:nth-child(even) {\n",
       "    background-color: #f6f6f6;\n",
       "}\n",
       "\n",
       ".estimator-table .parameters-table tr:hover {\n",
       "    background-color: #e0e0e0;\n",
       "}\n",
       "\n",
       ".estimator-table table td {\n",
       "    border: 1px solid rgba(106, 105, 104, 0.232);\n",
       "}\n",
       "\n",
       ".user-set td {\n",
       "    color:rgb(255, 94, 0);\n",
       "    text-align: left;\n",
       "}\n",
       "\n",
       ".user-set td.value pre {\n",
       "    color:rgb(255, 94, 0) !important;\n",
       "    background-color: transparent !important;\n",
       "}\n",
       "\n",
       ".default td {\n",
       "    color: black;\n",
       "    text-align: left;\n",
       "}\n",
       "\n",
       ".user-set td i,\n",
       ".default td i {\n",
       "    color: black;\n",
       "}\n",
       "\n",
       ".copy-paste-icon {\n",
       "    background-image: url(data:image/svg+xml;base64,PHN2ZyB4bWxucz0iaHR0cDovL3d3dy53My5vcmcvMjAwMC9zdmciIHZpZXdCb3g9IjAgMCA0NDggNTEyIj48IS0tIUZvbnQgQXdlc29tZSBGcmVlIDYuNy4yIGJ5IEBmb250YXdlc29tZSAtIGh0dHBzOi8vZm9udGF3ZXNvbWUuY29tIExpY2Vuc2UgLSBodHRwczovL2ZvbnRhd2Vzb21lLmNvbS9saWNlbnNlL2ZyZWUgQ29weXJpZ2h0IDIwMjUgRm9udGljb25zLCBJbmMuLS0+PHBhdGggZD0iTTIwOCAwTDMzMi4xIDBjMTIuNyAwIDI0LjkgNS4xIDMzLjkgMTQuMWw2Ny45IDY3LjljOSA5IDE0LjEgMjEuMiAxNC4xIDMzLjlMNDQ4IDMzNmMwIDI2LjUtMjEuNSA0OC00OCA0OGwtMTkyIDBjLTI2LjUgMC00OC0yMS41LTQ4LTQ4bDAtMjg4YzAtMjYuNSAyMS41LTQ4IDQ4LTQ4ek00OCAxMjhsODAgMCAwIDY0LTY0IDAgMCAyNTYgMTkyIDAgMC0zMiA2NCAwIDAgNDhjMCAyNi41LTIxLjUgNDgtNDggNDhMNDggNTEyYy0yNi41IDAtNDgtMjEuNS00OC00OEwwIDE3NmMwLTI2LjUgMjEuNS00OCA0OC00OHoiLz48L3N2Zz4=);\n",
       "    background-repeat: no-repeat;\n",
       "    background-size: 14px 14px;\n",
       "    background-position: 0;\n",
       "    display: inline-block;\n",
       "    width: 14px;\n",
       "    height: 14px;\n",
       "    cursor: pointer;\n",
       "}\n",
       "</style><body><div id=\"sk-container-id-4\" class=\"sk-top-container\"><div class=\"sk-text-repr-fallback\"><pre>OneVsRestClassifier(estimator=MLPClassifier(hidden_layer_sizes=(256, 128),\n",
       "                                            max_iter=20, random_state=42,\n",
       "                                            verbose=True))</pre><b>In a Jupyter environment, please rerun this cell to show the HTML representation or trust the notebook. <br />On GitHub, the HTML representation is unable to render, please try loading this page with nbviewer.org.</b></div><div class=\"sk-container\" hidden><div class=\"sk-item sk-dashed-wrapped\"><div class=\"sk-label-container\"><div class=\"sk-label fitted sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-10\" type=\"checkbox\" ><label for=\"sk-estimator-id-10\" class=\"sk-toggleable__label fitted sk-toggleable__label-arrow\"><div><div>OneVsRestClassifier</div></div><div><a class=\"sk-estimator-doc-link fitted\" rel=\"noreferrer\" target=\"_blank\" href=\"https://scikit-learn.org/1.7/modules/generated/sklearn.multiclass.OneVsRestClassifier.html\">?<span>Documentation for OneVsRestClassifier</span></a><span class=\"sk-estimator-doc-link fitted\">i<span>Fitted</span></span></div></label><div class=\"sk-toggleable__content fitted\" data-param-prefix=\"\">\n",
       "        <div class=\"estimator-table\">\n",
       "            <details>\n",
       "                <summary>Parameters</summary>\n",
       "                <table class=\"parameters-table\">\n",
       "                  <tbody>\n",
       "                    \n",
       "        <tr class=\"user-set\">\n",
       "            <td><i class=\"copy-paste-icon\"\n",
       "                 onclick=\"copyToClipboard('estimator',\n",
       "                          this.parentElement.nextElementSibling)\"\n",
       "            ></i></td>\n",
       "            <td class=\"param\">estimator&nbsp;</td>\n",
       "            <td class=\"value\">MLPClassifier... verbose=True)</td>\n",
       "        </tr>\n",
       "    \n",
       "\n",
       "        <tr class=\"default\">\n",
       "            <td><i class=\"copy-paste-icon\"\n",
       "                 onclick=\"copyToClipboard('n_jobs',\n",
       "                          this.parentElement.nextElementSibling)\"\n",
       "            ></i></td>\n",
       "            <td class=\"param\">n_jobs&nbsp;</td>\n",
       "            <td class=\"value\">None</td>\n",
       "        </tr>\n",
       "    \n",
       "\n",
       "        <tr class=\"default\">\n",
       "            <td><i class=\"copy-paste-icon\"\n",
       "                 onclick=\"copyToClipboard('verbose',\n",
       "                          this.parentElement.nextElementSibling)\"\n",
       "            ></i></td>\n",
       "            <td class=\"param\">verbose&nbsp;</td>\n",
       "            <td class=\"value\">0</td>\n",
       "        </tr>\n",
       "    \n",
       "                  </tbody>\n",
       "                </table>\n",
       "            </details>\n",
       "        </div>\n",
       "    </div></div></div><div class=\"sk-parallel\"><div class=\"sk-parallel-item\"><div class=\"sk-item\"><div class=\"sk-label-container\"><div class=\"sk-label fitted sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-11\" type=\"checkbox\" ><label for=\"sk-estimator-id-11\" class=\"sk-toggleable__label fitted sk-toggleable__label-arrow\"><div><div>estimator: MLPClassifier</div></div></label><div class=\"sk-toggleable__content fitted\" data-param-prefix=\"estimator__\"><pre>MLPClassifier(hidden_layer_sizes=(256, 128), max_iter=20, random_state=42,\n",
       "              verbose=True)</pre></div></div></div><div class=\"sk-serial\"><div class=\"sk-item\"><div class=\"sk-estimator fitted sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-12\" type=\"checkbox\" ><label for=\"sk-estimator-id-12\" class=\"sk-toggleable__label fitted sk-toggleable__label-arrow\"><div><div>MLPClassifier</div></div><div><a class=\"sk-estimator-doc-link fitted\" rel=\"noreferrer\" target=\"_blank\" href=\"https://scikit-learn.org/1.7/modules/generated/sklearn.neural_network.MLPClassifier.html\">?<span>Documentation for MLPClassifier</span></a></div></label><div class=\"sk-toggleable__content fitted\" data-param-prefix=\"estimator__\">\n",
       "        <div class=\"estimator-table\">\n",
       "            <details>\n",
       "                <summary>Parameters</summary>\n",
       "                <table class=\"parameters-table\">\n",
       "                  <tbody>\n",
       "                    \n",
       "        <tr class=\"user-set\">\n",
       "            <td><i class=\"copy-paste-icon\"\n",
       "                 onclick=\"copyToClipboard('hidden_layer_sizes',\n",
       "                          this.parentElement.nextElementSibling)\"\n",
       "            ></i></td>\n",
       "            <td class=\"param\">hidden_layer_sizes&nbsp;</td>\n",
       "            <td class=\"value\">(256, ...)</td>\n",
       "        </tr>\n",
       "    \n",
       "\n",
       "        <tr class=\"default\">\n",
       "            <td><i class=\"copy-paste-icon\"\n",
       "                 onclick=\"copyToClipboard('activation',\n",
       "                          this.parentElement.nextElementSibling)\"\n",
       "            ></i></td>\n",
       "            <td class=\"param\">activation&nbsp;</td>\n",
       "            <td class=\"value\">&#x27;relu&#x27;</td>\n",
       "        </tr>\n",
       "    \n",
       "\n",
       "        <tr class=\"default\">\n",
       "            <td><i class=\"copy-paste-icon\"\n",
       "                 onclick=\"copyToClipboard('solver',\n",
       "                          this.parentElement.nextElementSibling)\"\n",
       "            ></i></td>\n",
       "            <td class=\"param\">solver&nbsp;</td>\n",
       "            <td class=\"value\">&#x27;adam&#x27;</td>\n",
       "        </tr>\n",
       "    \n",
       "\n",
       "        <tr class=\"default\">\n",
       "            <td><i class=\"copy-paste-icon\"\n",
       "                 onclick=\"copyToClipboard('alpha',\n",
       "                          this.parentElement.nextElementSibling)\"\n",
       "            ></i></td>\n",
       "            <td class=\"param\">alpha&nbsp;</td>\n",
       "            <td class=\"value\">0.0001</td>\n",
       "        </tr>\n",
       "    \n",
       "\n",
       "        <tr class=\"default\">\n",
       "            <td><i class=\"copy-paste-icon\"\n",
       "                 onclick=\"copyToClipboard('batch_size',\n",
       "                          this.parentElement.nextElementSibling)\"\n",
       "            ></i></td>\n",
       "            <td class=\"param\">batch_size&nbsp;</td>\n",
       "            <td class=\"value\">&#x27;auto&#x27;</td>\n",
       "        </tr>\n",
       "    \n",
       "\n",
       "        <tr class=\"default\">\n",
       "            <td><i class=\"copy-paste-icon\"\n",
       "                 onclick=\"copyToClipboard('learning_rate',\n",
       "                          this.parentElement.nextElementSibling)\"\n",
       "            ></i></td>\n",
       "            <td class=\"param\">learning_rate&nbsp;</td>\n",
       "            <td class=\"value\">&#x27;constant&#x27;</td>\n",
       "        </tr>\n",
       "    \n",
       "\n",
       "        <tr class=\"default\">\n",
       "            <td><i class=\"copy-paste-icon\"\n",
       "                 onclick=\"copyToClipboard('learning_rate_init',\n",
       "                          this.parentElement.nextElementSibling)\"\n",
       "            ></i></td>\n",
       "            <td class=\"param\">learning_rate_init&nbsp;</td>\n",
       "            <td class=\"value\">0.001</td>\n",
       "        </tr>\n",
       "    \n",
       "\n",
       "        <tr class=\"default\">\n",
       "            <td><i class=\"copy-paste-icon\"\n",
       "                 onclick=\"copyToClipboard('power_t',\n",
       "                          this.parentElement.nextElementSibling)\"\n",
       "            ></i></td>\n",
       "            <td class=\"param\">power_t&nbsp;</td>\n",
       "            <td class=\"value\">0.5</td>\n",
       "        </tr>\n",
       "    \n",
       "\n",
       "        <tr class=\"user-set\">\n",
       "            <td><i class=\"copy-paste-icon\"\n",
       "                 onclick=\"copyToClipboard('max_iter',\n",
       "                          this.parentElement.nextElementSibling)\"\n",
       "            ></i></td>\n",
       "            <td class=\"param\">max_iter&nbsp;</td>\n",
       "            <td class=\"value\">20</td>\n",
       "        </tr>\n",
       "    \n",
       "\n",
       "        <tr class=\"default\">\n",
       "            <td><i class=\"copy-paste-icon\"\n",
       "                 onclick=\"copyToClipboard('shuffle',\n",
       "                          this.parentElement.nextElementSibling)\"\n",
       "            ></i></td>\n",
       "            <td class=\"param\">shuffle&nbsp;</td>\n",
       "            <td class=\"value\">True</td>\n",
       "        </tr>\n",
       "    \n",
       "\n",
       "        <tr class=\"user-set\">\n",
       "            <td><i class=\"copy-paste-icon\"\n",
       "                 onclick=\"copyToClipboard('random_state',\n",
       "                          this.parentElement.nextElementSibling)\"\n",
       "            ></i></td>\n",
       "            <td class=\"param\">random_state&nbsp;</td>\n",
       "            <td class=\"value\">42</td>\n",
       "        </tr>\n",
       "    \n",
       "\n",
       "        <tr class=\"default\">\n",
       "            <td><i class=\"copy-paste-icon\"\n",
       "                 onclick=\"copyToClipboard('tol',\n",
       "                          this.parentElement.nextElementSibling)\"\n",
       "            ></i></td>\n",
       "            <td class=\"param\">tol&nbsp;</td>\n",
       "            <td class=\"value\">0.0001</td>\n",
       "        </tr>\n",
       "    \n",
       "\n",
       "        <tr class=\"user-set\">\n",
       "            <td><i class=\"copy-paste-icon\"\n",
       "                 onclick=\"copyToClipboard('verbose',\n",
       "                          this.parentElement.nextElementSibling)\"\n",
       "            ></i></td>\n",
       "            <td class=\"param\">verbose&nbsp;</td>\n",
       "            <td class=\"value\">True</td>\n",
       "        </tr>\n",
       "    \n",
       "\n",
       "        <tr class=\"default\">\n",
       "            <td><i class=\"copy-paste-icon\"\n",
       "                 onclick=\"copyToClipboard('warm_start',\n",
       "                          this.parentElement.nextElementSibling)\"\n",
       "            ></i></td>\n",
       "            <td class=\"param\">warm_start&nbsp;</td>\n",
       "            <td class=\"value\">False</td>\n",
       "        </tr>\n",
       "    \n",
       "\n",
       "        <tr class=\"default\">\n",
       "            <td><i class=\"copy-paste-icon\"\n",
       "                 onclick=\"copyToClipboard('momentum',\n",
       "                          this.parentElement.nextElementSibling)\"\n",
       "            ></i></td>\n",
       "            <td class=\"param\">momentum&nbsp;</td>\n",
       "            <td class=\"value\">0.9</td>\n",
       "        </tr>\n",
       "    \n",
       "\n",
       "        <tr class=\"default\">\n",
       "            <td><i class=\"copy-paste-icon\"\n",
       "                 onclick=\"copyToClipboard('nesterovs_momentum',\n",
       "                          this.parentElement.nextElementSibling)\"\n",
       "            ></i></td>\n",
       "            <td class=\"param\">nesterovs_momentum&nbsp;</td>\n",
       "            <td class=\"value\">True</td>\n",
       "        </tr>\n",
       "    \n",
       "\n",
       "        <tr class=\"default\">\n",
       "            <td><i class=\"copy-paste-icon\"\n",
       "                 onclick=\"copyToClipboard('early_stopping',\n",
       "                          this.parentElement.nextElementSibling)\"\n",
       "            ></i></td>\n",
       "            <td class=\"param\">early_stopping&nbsp;</td>\n",
       "            <td class=\"value\">False</td>\n",
       "        </tr>\n",
       "    \n",
       "\n",
       "        <tr class=\"default\">\n",
       "            <td><i class=\"copy-paste-icon\"\n",
       "                 onclick=\"copyToClipboard('validation_fraction',\n",
       "                          this.parentElement.nextElementSibling)\"\n",
       "            ></i></td>\n",
       "            <td class=\"param\">validation_fraction&nbsp;</td>\n",
       "            <td class=\"value\">0.1</td>\n",
       "        </tr>\n",
       "    \n",
       "\n",
       "        <tr class=\"default\">\n",
       "            <td><i class=\"copy-paste-icon\"\n",
       "                 onclick=\"copyToClipboard('beta_1',\n",
       "                          this.parentElement.nextElementSibling)\"\n",
       "            ></i></td>\n",
       "            <td class=\"param\">beta_1&nbsp;</td>\n",
       "            <td class=\"value\">0.9</td>\n",
       "        </tr>\n",
       "    \n",
       "\n",
       "        <tr class=\"default\">\n",
       "            <td><i class=\"copy-paste-icon\"\n",
       "                 onclick=\"copyToClipboard('beta_2',\n",
       "                          this.parentElement.nextElementSibling)\"\n",
       "            ></i></td>\n",
       "            <td class=\"param\">beta_2&nbsp;</td>\n",
       "            <td class=\"value\">0.999</td>\n",
       "        </tr>\n",
       "    \n",
       "\n",
       "        <tr class=\"default\">\n",
       "            <td><i class=\"copy-paste-icon\"\n",
       "                 onclick=\"copyToClipboard('epsilon',\n",
       "                          this.parentElement.nextElementSibling)\"\n",
       "            ></i></td>\n",
       "            <td class=\"param\">epsilon&nbsp;</td>\n",
       "            <td class=\"value\">1e-08</td>\n",
       "        </tr>\n",
       "    \n",
       "\n",
       "        <tr class=\"default\">\n",
       "            <td><i class=\"copy-paste-icon\"\n",
       "                 onclick=\"copyToClipboard('n_iter_no_change',\n",
       "                          this.parentElement.nextElementSibling)\"\n",
       "            ></i></td>\n",
       "            <td class=\"param\">n_iter_no_change&nbsp;</td>\n",
       "            <td class=\"value\">10</td>\n",
       "        </tr>\n",
       "    \n",
       "\n",
       "        <tr class=\"default\">\n",
       "            <td><i class=\"copy-paste-icon\"\n",
       "                 onclick=\"copyToClipboard('max_fun',\n",
       "                          this.parentElement.nextElementSibling)\"\n",
       "            ></i></td>\n",
       "            <td class=\"param\">max_fun&nbsp;</td>\n",
       "            <td class=\"value\">15000</td>\n",
       "        </tr>\n",
       "    \n",
       "                  </tbody>\n",
       "                </table>\n",
       "            </details>\n",
       "        </div>\n",
       "    </div></div></div></div></div></div></div></div></div></div><script>function copyToClipboard(text, element) {\n",
       "    // Get the parameter prefix from the closest toggleable content\n",
       "    const toggleableContent = element.closest('.sk-toggleable__content');\n",
       "    const paramPrefix = toggleableContent ? toggleableContent.dataset.paramPrefix : '';\n",
       "    const fullParamName = paramPrefix ? `${paramPrefix}${text}` : text;\n",
       "\n",
       "    const originalStyle = element.style;\n",
       "    const computedStyle = window.getComputedStyle(element);\n",
       "    const originalWidth = computedStyle.width;\n",
       "    const originalHTML = element.innerHTML.replace('Copied!', '');\n",
       "\n",
       "    navigator.clipboard.writeText(fullParamName)\n",
       "        .then(() => {\n",
       "            element.style.width = originalWidth;\n",
       "            element.style.color = 'green';\n",
       "            element.innerHTML = \"Copied!\";\n",
       "\n",
       "            setTimeout(() => {\n",
       "                element.innerHTML = originalHTML;\n",
       "                element.style = originalStyle;\n",
       "            }, 2000);\n",
       "        })\n",
       "        .catch(err => {\n",
       "            console.error('Failed to copy:', err);\n",
       "            element.style.color = 'red';\n",
       "            element.innerHTML = \"Failed!\";\n",
       "            setTimeout(() => {\n",
       "                element.innerHTML = originalHTML;\n",
       "                element.style = originalStyle;\n",
       "            }, 2000);\n",
       "        });\n",
       "    return false;\n",
       "}\n",
       "\n",
       "document.querySelectorAll('.fa-regular.fa-copy').forEach(function(element) {\n",
       "    const toggleableContent = element.closest('.sk-toggleable__content');\n",
       "    const paramPrefix = toggleableContent ? toggleableContent.dataset.paramPrefix : '';\n",
       "    const paramName = element.parentElement.nextElementSibling.textContent.trim();\n",
       "    const fullParamName = paramPrefix ? `${paramPrefix}${paramName}` : paramName;\n",
       "\n",
       "    element.setAttribute('title', fullParamName);\n",
       "});\n",
       "</script></body>"
      ],
      "text/plain": [
       "OneVsRestClassifier(estimator=MLPClassifier(hidden_layer_sizes=(256, 128),\n",
       "                                            max_iter=20, random_state=42,\n",
       "                                            verbose=True))"
      ]
     },
     "execution_count": 37,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.neural_network import MLPClassifier\n",
    "from sklearn.multiclass import OneVsRestClassifier\n",
    "\n",
    "# Définir un MLP simple\n",
    "mlp = MLPClassifier(hidden_layer_sizes=(256, 128), \n",
    "                    activation='relu', \n",
    "                    max_iter=20, \n",
    "                    random_state=42, \n",
    "                    verbose=True)\n",
    "\n",
    "clf_mlp = OneVsRestClassifier(mlp)\n",
    "\n",
    "# Entraîner sur les embeddings SBERT\n",
    "clf_mlp.fit(X_train_sbert, y_train)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "id": "ba83caf4",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "F1 micro : 0.35009047281881833\n",
      "F1 macro : 0.2669807818737127\n",
      "Hamming loss : 0.0425941839681012\n",
      "\n",
      "Classification report:\n",
      "                precision    recall  f1-score   support\n",
      "\n",
      "    admiration       0.60      0.38      0.47      1691\n",
      "     amusement       0.56      0.41      0.47       926\n",
      "         anger       0.51      0.22      0.30       861\n",
      "     annoyance       0.31      0.11      0.16      1353\n",
      "      approval       0.38      0.12      0.19      1794\n",
      "        caring       0.35      0.13      0.19       577\n",
      "     confusion       0.40      0.15      0.22       721\n",
      "     curiosity       0.43      0.24      0.31       947\n",
      "        desire       0.35      0.16      0.22       361\n",
      "disappointment       0.30      0.07      0.11       849\n",
      "   disapproval       0.33      0.13      0.18      1184\n",
      "       disgust       0.43      0.15      0.22       550\n",
      " embarrassment       0.43      0.14      0.21       264\n",
      "    excitement       0.39      0.15      0.22       553\n",
      "          fear       0.56      0.25      0.35       318\n",
      "     gratitude       0.85      0.70      0.77      1162\n",
      "         grief       0.31      0.06      0.10        66\n",
      "           joy       0.45      0.17      0.25       779\n",
      "          love       0.63      0.47      0.54       812\n",
      "   nervousness       0.20      0.07      0.10       186\n",
      "      optimism       0.50      0.23      0.32       875\n",
      "         pride       0.19      0.03      0.06       124\n",
      "   realization       0.26      0.07      0.11       870\n",
      "        relief       0.26      0.03      0.06       146\n",
      "       remorse       0.50      0.24      0.33       266\n",
      "       sadness       0.42      0.22      0.29       677\n",
      "      surprise       0.45      0.20      0.28       548\n",
      "       neutral       0.52      0.40      0.45      5484\n",
      "\n",
      "     micro avg       0.51      0.27      0.35     24944\n",
      "     macro avg       0.42      0.20      0.27     24944\n",
      "  weighted avg       0.47      0.27      0.33     24944\n",
      "   samples avg       0.30      0.28      0.28     24944\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\Yann\\Desktop\\DEV\\School\\ml_m1\\NLP\\CustomGPT\\scraper_env\\Lib\\site-packages\\sklearn\\metrics\\_classification.py:1706: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in samples with no predicted labels. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", result.shape[0])\n"
     ]
    }
   ],
   "source": [
    "from sklearn.metrics import f1_score, hamming_loss, classification_report\n",
    "\n",
    "y_val_pred_mlp = clf_mlp.predict(X_val_sbert)\n",
    "\n",
    "print(\"F1 micro :\", f1_score(y_val, y_val_pred_mlp, average='micro'))\n",
    "print(\"F1 macro :\", f1_score(y_val, y_val_pred_mlp, average='macro'))\n",
    "print(\"Hamming loss :\", hamming_loss(y_val, y_val_pred_mlp))\n",
    "\n",
    "print(\"\\nClassification report:\")\n",
    "print(classification_report(y_val, y_val_pred_mlp, target_names=label_cols))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7cbe6821",
   "metadata": {},
   "source": [
    "## light gbm avec mlp"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "b21169dc",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting lightgbm\n",
      "  Using cached lightgbm-4.6.0-py3-none-win_amd64.whl.metadata (17 kB)\n",
      "Requirement already satisfied: numpy>=1.17.0 in c:\\users\\yann\\anaconda3\\envs\\hf_gpu_env\\lib\\site-packages (from lightgbm) (2.1.2)\n",
      "Requirement already satisfied: scipy in c:\\users\\yann\\anaconda3\\envs\\hf_gpu_env\\lib\\site-packages (from lightgbm) (1.15.3)\n",
      "Using cached lightgbm-4.6.0-py3-none-win_amd64.whl (1.5 MB)\n",
      "Installing collected packages: lightgbm\n",
      "Successfully installed lightgbm-4.6.0\n"
     ]
    }
   ],
   "source": [
    "!pip install lightgbm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "id": "ba5fca1f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[LightGBM] [Info] Number of positive: 13701, number of negative: 152541\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.175336 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 195840\n",
      "[LightGBM] [Info] Number of data points in the train set: 166242, number of used features: 768\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.082416 -> initscore=-2.409965\n",
      "[LightGBM] [Info] Start training from score -2.409965\n",
      "[LightGBM] [Info] Number of positive: 7404, number of negative: 158838\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.164419 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 195840\n",
      "[LightGBM] [Info] Number of data points in the train set: 166242, number of used features: 768\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.044537 -> initscore=-3.065864\n",
      "[LightGBM] [Info] Start training from score -3.065864\n",
      "[LightGBM] [Info] Number of positive: 6446, number of negative: 159796\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.161018 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 195840\n",
      "[LightGBM] [Info] Number of data points in the train set: 166242, number of used features: 768\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.038775 -> initscore=-3.210438\n",
      "[LightGBM] [Info] Start training from score -3.210438\n",
      "[LightGBM] [Info] Number of positive: 10918, number of negative: 155324\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.161311 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 195840\n",
      "[LightGBM] [Info] Number of data points in the train set: 166242, number of used features: 768\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.065675 -> initscore=-2.655100\n",
      "[LightGBM] [Info] Start training from score -2.655100\n",
      "[LightGBM] [Info] Number of positive: 14068, number of negative: 152174\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.165133 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 195840\n",
      "[LightGBM] [Info] Number of data points in the train set: 166242, number of used features: 768\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.084624 -> initscore=-2.381122\n",
      "[LightGBM] [Info] Start training from score -2.381122\n",
      "[LightGBM] [Info] Number of positive: 4801, number of negative: 161441\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.172014 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 195840\n",
      "[LightGBM] [Info] Number of data points in the train set: 166242, number of used features: 768\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.028880 -> initscore=-3.515316\n",
      "[LightGBM] [Info] Start training from score -3.515316\n",
      "[LightGBM] [Info] Number of positive: 5909, number of negative: 160333\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.167231 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 195840\n",
      "[LightGBM] [Info] Number of data points in the train set: 166242, number of used features: 768\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.035545 -> initscore=-3.300776\n",
      "[LightGBM] [Info] Start training from score -3.300776\n",
      "[LightGBM] [Info] Number of positive: 7781, number of negative: 158461\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.174012 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 195840\n",
      "[LightGBM] [Info] Number of data points in the train set: 166242, number of used features: 768\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.046805 -> initscore=-3.013824\n",
      "[LightGBM] [Info] Start training from score -3.013824\n",
      "[LightGBM] [Info] Number of positive: 3053, number of negative: 163189\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.180031 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 195840\n",
      "[LightGBM] [Info] Number of data points in the train set: 166242, number of used features: 768\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.018365 -> initscore=-3.978784\n",
      "[LightGBM] [Info] Start training from score -3.978784\n",
      "[LightGBM] [Info] Number of positive: 6759, number of negative: 159483\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.165409 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 195840\n",
      "[LightGBM] [Info] Number of data points in the train set: 166242, number of used features: 768\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.040658 -> initscore=-3.161062\n",
      "[LightGBM] [Info] Start training from score -3.161062\n",
      "[LightGBM] [Info] Number of positive: 9170, number of negative: 157072\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.161264 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 195840\n",
      "[LightGBM] [Info] Number of data points in the train set: 166242, number of used features: 768\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.055161 -> initscore=-2.840767\n",
      "[LightGBM] [Info] Start training from score -2.840767\n",
      "[LightGBM] [Info] Number of positive: 4232, number of negative: 162010\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.177815 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 195840\n",
      "[LightGBM] [Info] Number of data points in the train set: 166242, number of used features: 768\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.025457 -> initscore=-3.644983\n",
      "[LightGBM] [Info] Start training from score -3.644983\n",
      "[LightGBM] [Info] Number of positive: 1954, number of negative: 164288\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.171253 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 195840\n",
      "[LightGBM] [Info] Number of data points in the train set: 166242, number of used features: 768\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.011754 -> initscore=-4.431742\n",
      "[LightGBM] [Info] Start training from score -4.431742\n",
      "[LightGBM] [Info] Number of positive: 4556, number of negative: 161686\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.183642 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 195840\n",
      "[LightGBM] [Info] Number of data points in the train set: 166242, number of used features: 768\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.027406 -> initscore=-3.569211\n",
      "[LightGBM] [Info] Start training from score -3.569211\n",
      "[LightGBM] [Info] Number of positive: 2552, number of negative: 163690\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.162175 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 195840\n",
      "[LightGBM] [Info] Number of data points in the train set: 166242, number of used features: 768\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.015351 -> initscore=-4.161097\n",
      "[LightGBM] [Info] Start training from score -4.161097\n",
      "[LightGBM] [Info] Number of positive: 9243, number of negative: 156999\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.168213 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 195840\n",
      "[LightGBM] [Info] Number of data points in the train set: 166242, number of used features: 768\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.055600 -> initscore=-2.832373\n",
      "[LightGBM] [Info] Start training from score -2.832373\n",
      "[LightGBM] [Info] Number of positive: 538, number of negative: 165704\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.182010 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 195840\n",
      "[LightGBM] [Info] Number of data points in the train set: 166242, number of used features: 768\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.003236 -> initscore=-5.730100\n",
      "[LightGBM] [Info] Start training from score -5.730100\n",
      "[LightGBM] [Info] Number of positive: 6425, number of negative: 159817\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.153941 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 195840\n",
      "[LightGBM] [Info] Number of data points in the train set: 166242, number of used features: 768\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.038648 -> initscore=-3.213833\n",
      "[LightGBM] [Info] Start training from score -3.213833\n",
      "[LightGBM] [Info] Number of positive: 6568, number of negative: 159674\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.170395 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 195840\n",
      "[LightGBM] [Info] Number of data points in the train set: 166242, number of used features: 768\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.039509 -> initscore=-3.190925\n",
      "[LightGBM] [Info] Start training from score -3.190925\n",
      "[LightGBM] [Info] Number of positive: 1424, number of negative: 164818\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.175224 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 195840\n",
      "[LightGBM] [Info] Number of data points in the train set: 166242, number of used features: 768\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.008566 -> initscore=-4.751372\n",
      "[LightGBM] [Info] Start training from score -4.751372\n",
      "[LightGBM] [Info] Number of positive: 6915, number of negative: 159327\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.171166 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 195840\n",
      "[LightGBM] [Info] Number of data points in the train set: 166242, number of used features: 768\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.041596 -> initscore=-3.137266\n",
      "[LightGBM] [Info] Start training from score -3.137266\n",
      "[LightGBM] [Info] Number of positive: 1033, number of negative: 165209\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.167304 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 195840\n",
      "[LightGBM] [Info] Number of data points in the train set: 166242, number of used features: 768\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.006214 -> initscore=-5.074744\n",
      "[LightGBM] [Info] Start training from score -5.074744\n",
      "[LightGBM] [Info] Number of positive: 6986, number of negative: 159256\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.153624 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 195840\n",
      "[LightGBM] [Info] Number of data points in the train set: 166242, number of used features: 768\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.042023 -> initscore=-3.126605\n",
      "[LightGBM] [Info] Start training from score -3.126605\n",
      "[LightGBM] [Info] Number of positive: 1017, number of negative: 165225\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.177614 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 195840\n",
      "[LightGBM] [Info] Number of data points in the train set: 166242, number of used features: 768\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.006118 -> initscore=-5.090451\n",
      "[LightGBM] [Info] Start training from score -5.090451\n",
      "[LightGBM] [Info] Number of positive: 2005, number of negative: 164237\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.162244 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 195840\n",
      "[LightGBM] [Info] Number of data points in the train set: 166242, number of used features: 768\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.012061 -> initscore=-4.405666\n",
      "[LightGBM] [Info] Start training from score -4.405666\n",
      "[LightGBM] [Info] Number of positive: 5393, number of negative: 160849\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.160847 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 195840\n",
      "[LightGBM] [Info] Number of data points in the train set: 166242, number of used features: 768\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.032441 -> initscore=-3.395364\n",
      "[LightGBM] [Info] Start training from score -3.395364\n",
      "[LightGBM] [Info] Number of positive: 4394, number of negative: 161848\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.163588 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 195840\n",
      "[LightGBM] [Info] Number of data points in the train set: 166242, number of used features: 768\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.026431 -> initscore=-3.606418\n",
      "[LightGBM] [Info] Start training from score -3.606418\n",
      "[LightGBM] [Info] Number of positive: 44298, number of negative: 121944\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.172865 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 195840\n",
      "[LightGBM] [Info] Number of data points in the train set: 166242, number of used features: 768\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.266467 -> initscore=-1.012622\n",
      "[LightGBM] [Info] Start training from score -1.012622\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\Yann\\Desktop\\DEV\\School\\ml_m1\\NLP\\CustomGPT\\scraper_env\\Lib\\site-packages\\sklearn\\utils\\validation.py:2749: UserWarning: X does not have valid feature names, but LGBMClassifier was fitted with feature names\n",
      "  warnings.warn(\n",
      "c:\\Users\\Yann\\Desktop\\DEV\\School\\ml_m1\\NLP\\CustomGPT\\scraper_env\\Lib\\site-packages\\sklearn\\utils\\validation.py:2749: UserWarning: X does not have valid feature names, but LGBMClassifier was fitted with feature names\n",
      "  warnings.warn(\n",
      "c:\\Users\\Yann\\Desktop\\DEV\\School\\ml_m1\\NLP\\CustomGPT\\scraper_env\\Lib\\site-packages\\sklearn\\utils\\validation.py:2749: UserWarning: X does not have valid feature names, but LGBMClassifier was fitted with feature names\n",
      "  warnings.warn(\n",
      "c:\\Users\\Yann\\Desktop\\DEV\\School\\ml_m1\\NLP\\CustomGPT\\scraper_env\\Lib\\site-packages\\sklearn\\utils\\validation.py:2749: UserWarning: X does not have valid feature names, but LGBMClassifier was fitted with feature names\n",
      "  warnings.warn(\n",
      "c:\\Users\\Yann\\Desktop\\DEV\\School\\ml_m1\\NLP\\CustomGPT\\scraper_env\\Lib\\site-packages\\sklearn\\utils\\validation.py:2749: UserWarning: X does not have valid feature names, but LGBMClassifier was fitted with feature names\n",
      "  warnings.warn(\n",
      "c:\\Users\\Yann\\Desktop\\DEV\\School\\ml_m1\\NLP\\CustomGPT\\scraper_env\\Lib\\site-packages\\sklearn\\utils\\validation.py:2749: UserWarning: X does not have valid feature names, but LGBMClassifier was fitted with feature names\n",
      "  warnings.warn(\n",
      "c:\\Users\\Yann\\Desktop\\DEV\\School\\ml_m1\\NLP\\CustomGPT\\scraper_env\\Lib\\site-packages\\sklearn\\utils\\validation.py:2749: UserWarning: X does not have valid feature names, but LGBMClassifier was fitted with feature names\n",
      "  warnings.warn(\n",
      "c:\\Users\\Yann\\Desktop\\DEV\\School\\ml_m1\\NLP\\CustomGPT\\scraper_env\\Lib\\site-packages\\sklearn\\utils\\validation.py:2749: UserWarning: X does not have valid feature names, but LGBMClassifier was fitted with feature names\n",
      "  warnings.warn(\n",
      "c:\\Users\\Yann\\Desktop\\DEV\\School\\ml_m1\\NLP\\CustomGPT\\scraper_env\\Lib\\site-packages\\sklearn\\utils\\validation.py:2749: UserWarning: X does not have valid feature names, but LGBMClassifier was fitted with feature names\n",
      "  warnings.warn(\n",
      "c:\\Users\\Yann\\Desktop\\DEV\\School\\ml_m1\\NLP\\CustomGPT\\scraper_env\\Lib\\site-packages\\sklearn\\utils\\validation.py:2749: UserWarning: X does not have valid feature names, but LGBMClassifier was fitted with feature names\n",
      "  warnings.warn(\n",
      "c:\\Users\\Yann\\Desktop\\DEV\\School\\ml_m1\\NLP\\CustomGPT\\scraper_env\\Lib\\site-packages\\sklearn\\utils\\validation.py:2749: UserWarning: X does not have valid feature names, but LGBMClassifier was fitted with feature names\n",
      "  warnings.warn(\n",
      "c:\\Users\\Yann\\Desktop\\DEV\\School\\ml_m1\\NLP\\CustomGPT\\scraper_env\\Lib\\site-packages\\sklearn\\utils\\validation.py:2749: UserWarning: X does not have valid feature names, but LGBMClassifier was fitted with feature names\n",
      "  warnings.warn(\n",
      "c:\\Users\\Yann\\Desktop\\DEV\\School\\ml_m1\\NLP\\CustomGPT\\scraper_env\\Lib\\site-packages\\sklearn\\utils\\validation.py:2749: UserWarning: X does not have valid feature names, but LGBMClassifier was fitted with feature names\n",
      "  warnings.warn(\n",
      "c:\\Users\\Yann\\Desktop\\DEV\\School\\ml_m1\\NLP\\CustomGPT\\scraper_env\\Lib\\site-packages\\sklearn\\utils\\validation.py:2749: UserWarning: X does not have valid feature names, but LGBMClassifier was fitted with feature names\n",
      "  warnings.warn(\n",
      "c:\\Users\\Yann\\Desktop\\DEV\\School\\ml_m1\\NLP\\CustomGPT\\scraper_env\\Lib\\site-packages\\sklearn\\utils\\validation.py:2749: UserWarning: X does not have valid feature names, but LGBMClassifier was fitted with feature names\n",
      "  warnings.warn(\n",
      "c:\\Users\\Yann\\Desktop\\DEV\\School\\ml_m1\\NLP\\CustomGPT\\scraper_env\\Lib\\site-packages\\sklearn\\utils\\validation.py:2749: UserWarning: X does not have valid feature names, but LGBMClassifier was fitted with feature names\n",
      "  warnings.warn(\n",
      "c:\\Users\\Yann\\Desktop\\DEV\\School\\ml_m1\\NLP\\CustomGPT\\scraper_env\\Lib\\site-packages\\sklearn\\utils\\validation.py:2749: UserWarning: X does not have valid feature names, but LGBMClassifier was fitted with feature names\n",
      "  warnings.warn(\n",
      "c:\\Users\\Yann\\Desktop\\DEV\\School\\ml_m1\\NLP\\CustomGPT\\scraper_env\\Lib\\site-packages\\sklearn\\utils\\validation.py:2749: UserWarning: X does not have valid feature names, but LGBMClassifier was fitted with feature names\n",
      "  warnings.warn(\n",
      "c:\\Users\\Yann\\Desktop\\DEV\\School\\ml_m1\\NLP\\CustomGPT\\scraper_env\\Lib\\site-packages\\sklearn\\utils\\validation.py:2749: UserWarning: X does not have valid feature names, but LGBMClassifier was fitted with feature names\n",
      "  warnings.warn(\n",
      "c:\\Users\\Yann\\Desktop\\DEV\\School\\ml_m1\\NLP\\CustomGPT\\scraper_env\\Lib\\site-packages\\sklearn\\utils\\validation.py:2749: UserWarning: X does not have valid feature names, but LGBMClassifier was fitted with feature names\n",
      "  warnings.warn(\n",
      "c:\\Users\\Yann\\Desktop\\DEV\\School\\ml_m1\\NLP\\CustomGPT\\scraper_env\\Lib\\site-packages\\sklearn\\utils\\validation.py:2749: UserWarning: X does not have valid feature names, but LGBMClassifier was fitted with feature names\n",
      "  warnings.warn(\n",
      "c:\\Users\\Yann\\Desktop\\DEV\\School\\ml_m1\\NLP\\CustomGPT\\scraper_env\\Lib\\site-packages\\sklearn\\utils\\validation.py:2749: UserWarning: X does not have valid feature names, but LGBMClassifier was fitted with feature names\n",
      "  warnings.warn(\n",
      "c:\\Users\\Yann\\Desktop\\DEV\\School\\ml_m1\\NLP\\CustomGPT\\scraper_env\\Lib\\site-packages\\sklearn\\utils\\validation.py:2749: UserWarning: X does not have valid feature names, but LGBMClassifier was fitted with feature names\n",
      "  warnings.warn(\n",
      "c:\\Users\\Yann\\Desktop\\DEV\\School\\ml_m1\\NLP\\CustomGPT\\scraper_env\\Lib\\site-packages\\sklearn\\utils\\validation.py:2749: UserWarning: X does not have valid feature names, but LGBMClassifier was fitted with feature names\n",
      "  warnings.warn(\n",
      "c:\\Users\\Yann\\Desktop\\DEV\\School\\ml_m1\\NLP\\CustomGPT\\scraper_env\\Lib\\site-packages\\sklearn\\utils\\validation.py:2749: UserWarning: X does not have valid feature names, but LGBMClassifier was fitted with feature names\n",
      "  warnings.warn(\n",
      "c:\\Users\\Yann\\Desktop\\DEV\\School\\ml_m1\\NLP\\CustomGPT\\scraper_env\\Lib\\site-packages\\sklearn\\utils\\validation.py:2749: UserWarning: X does not have valid feature names, but LGBMClassifier was fitted with feature names\n",
      "  warnings.warn(\n",
      "c:\\Users\\Yann\\Desktop\\DEV\\School\\ml_m1\\NLP\\CustomGPT\\scraper_env\\Lib\\site-packages\\sklearn\\utils\\validation.py:2749: UserWarning: X does not have valid feature names, but LGBMClassifier was fitted with feature names\n",
      "  warnings.warn(\n",
      "c:\\Users\\Yann\\Desktop\\DEV\\School\\ml_m1\\NLP\\CustomGPT\\scraper_env\\Lib\\site-packages\\sklearn\\utils\\validation.py:2749: UserWarning: X does not have valid feature names, but LGBMClassifier was fitted with feature names\n",
      "  warnings.warn(\n"
     ]
    }
   ],
   "source": [
    "import lightgbm as lgb\n",
    "from sklearn.multioutput import MultiOutputClassifier\n",
    "\n",
    "lgbm = lgb.LGBMClassifier(objective='binary', n_estimators=100, random_state=42)\n",
    "clf_lgbm = MultiOutputClassifier(lgbm)\n",
    "\n",
    "clf_lgbm.fit(X_train_sbert, y_train)\n",
    "y_val_pred_lgbm = clf_lgbm.predict(X_val_sbert)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "id": "f909e1ba",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "LightGBM\n",
      "F1 micro : 0.18525210513755838\n",
      "F1 macro : 0.16807864535555164\n",
      "Hamming loss : 0.041074865942527156\n"
     ]
    }
   ],
   "source": [
    "print(\"LightGBM\")\n",
    "print(\"F1 micro :\", f1_score(y_val, y_val_pred_lgbm, average='micro'))\n",
    "print(\"F1 macro :\", f1_score(y_val, y_val_pred_lgbm, average='macro'))\n",
    "print(\"Hamming loss :\", hamming_loss(y_val, y_val_pred_lgbm))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8fd34d1a",
   "metadata": {},
   "source": [
    "## USE + MLPClassifier"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "40f82f35",
   "metadata": {},
   "source": [
    "### Encodage avec Universal Sentence Encoder"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "522a3086",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting tensorflow-hub\n",
      "  Using cached tensorflow_hub-0.16.1-py2.py3-none-any.whl.metadata (1.3 kB)\n",
      "Requirement already satisfied: numpy>=1.12.0 in c:\\users\\yann\\anaconda3\\envs\\nlp_gpu_env\\lib\\site-packages (from tensorflow-hub) (2.0.2)\n",
      "Collecting protobuf>=3.19.6 (from tensorflow-hub)\n",
      "  Downloading protobuf-6.31.1-cp39-cp39-win_amd64.whl.metadata (593 bytes)\n",
      "Collecting tf-keras>=2.14.1 (from tensorflow-hub)\n",
      "  Using cached tf_keras-2.19.0-py3-none-any.whl.metadata (1.8 kB)\n",
      "Collecting tensorflow<2.20,>=2.19 (from tf-keras>=2.14.1->tensorflow-hub)\n",
      "  Downloading tensorflow-2.19.0-cp39-cp39-win_amd64.whl.metadata (4.1 kB)\n",
      "Collecting absl-py>=1.0.0 (from tensorflow<2.20,>=2.19->tf-keras>=2.14.1->tensorflow-hub)\n",
      "  Downloading absl_py-2.3.0-py3-none-any.whl.metadata (2.4 kB)\n",
      "Collecting astunparse>=1.6.0 (from tensorflow<2.20,>=2.19->tf-keras>=2.14.1->tensorflow-hub)\n",
      "  Downloading astunparse-1.6.3-py2.py3-none-any.whl.metadata (4.4 kB)\n",
      "Collecting flatbuffers>=24.3.25 (from tensorflow<2.20,>=2.19->tf-keras>=2.14.1->tensorflow-hub)\n",
      "  Downloading flatbuffers-25.2.10-py2.py3-none-any.whl.metadata (875 bytes)\n",
      "Collecting gast!=0.5.0,!=0.5.1,!=0.5.2,>=0.2.1 (from tensorflow<2.20,>=2.19->tf-keras>=2.14.1->tensorflow-hub)\n",
      "  Downloading gast-0.6.0-py3-none-any.whl.metadata (1.3 kB)\n",
      "Collecting google-pasta>=0.1.1 (from tensorflow<2.20,>=2.19->tf-keras>=2.14.1->tensorflow-hub)\n",
      "  Downloading google_pasta-0.2.0-py3-none-any.whl.metadata (814 bytes)\n",
      "Collecting libclang>=13.0.0 (from tensorflow<2.20,>=2.19->tf-keras>=2.14.1->tensorflow-hub)\n",
      "  Downloading libclang-18.1.1-py2.py3-none-win_amd64.whl.metadata (5.3 kB)\n",
      "Collecting opt-einsum>=2.3.2 (from tensorflow<2.20,>=2.19->tf-keras>=2.14.1->tensorflow-hub)\n",
      "  Downloading opt_einsum-3.4.0-py3-none-any.whl.metadata (6.3 kB)\n",
      "Requirement already satisfied: packaging in c:\\users\\yann\\anaconda3\\envs\\nlp_gpu_env\\lib\\site-packages (from tensorflow<2.20,>=2.19->tf-keras>=2.14.1->tensorflow-hub) (25.0)\n",
      "Collecting protobuf>=3.19.6 (from tensorflow-hub)\n",
      "  Downloading protobuf-5.29.5-cp39-cp39-win_amd64.whl.metadata (592 bytes)\n",
      "Requirement already satisfied: requests<3,>=2.21.0 in c:\\users\\yann\\anaconda3\\envs\\nlp_gpu_env\\lib\\site-packages (from tensorflow<2.20,>=2.19->tf-keras>=2.14.1->tensorflow-hub) (2.32.4)\n",
      "Requirement already satisfied: setuptools in c:\\users\\yann\\anaconda3\\envs\\nlp_gpu_env\\lib\\site-packages (from tensorflow<2.20,>=2.19->tf-keras>=2.14.1->tensorflow-hub) (78.1.1)\n",
      "Requirement already satisfied: six>=1.12.0 in c:\\users\\yann\\anaconda3\\envs\\nlp_gpu_env\\lib\\site-packages (from tensorflow<2.20,>=2.19->tf-keras>=2.14.1->tensorflow-hub) (1.17.0)\n",
      "Collecting termcolor>=1.1.0 (from tensorflow<2.20,>=2.19->tf-keras>=2.14.1->tensorflow-hub)\n",
      "  Downloading termcolor-3.1.0-py3-none-any.whl.metadata (6.4 kB)\n",
      "Requirement already satisfied: typing-extensions>=3.6.6 in c:\\users\\yann\\anaconda3\\envs\\nlp_gpu_env\\lib\\site-packages (from tensorflow<2.20,>=2.19->tf-keras>=2.14.1->tensorflow-hub) (4.14.0)\n",
      "Collecting wrapt>=1.11.0 (from tensorflow<2.20,>=2.19->tf-keras>=2.14.1->tensorflow-hub)\n",
      "  Downloading wrapt-1.17.2-cp39-cp39-win_amd64.whl.metadata (6.5 kB)\n",
      "Collecting grpcio<2.0,>=1.24.3 (from tensorflow<2.20,>=2.19->tf-keras>=2.14.1->tensorflow-hub)\n",
      "  Downloading grpcio-1.73.1-cp39-cp39-win_amd64.whl.metadata (4.0 kB)\n",
      "Collecting tensorboard~=2.19.0 (from tensorflow<2.20,>=2.19->tf-keras>=2.14.1->tensorflow-hub)\n",
      "  Downloading tensorboard-2.19.0-py3-none-any.whl.metadata (1.8 kB)\n",
      "Collecting keras>=3.5.0 (from tensorflow<2.20,>=2.19->tf-keras>=2.14.1->tensorflow-hub)\n",
      "  Downloading keras-3.10.0-py3-none-any.whl.metadata (6.0 kB)\n",
      "Collecting h5py>=3.11.0 (from tensorflow<2.20,>=2.19->tf-keras>=2.14.1->tensorflow-hub)\n",
      "  Downloading h5py-3.14.0-cp39-cp39-win_amd64.whl.metadata (2.7 kB)\n",
      "Collecting ml-dtypes<1.0.0,>=0.5.1 (from tensorflow<2.20,>=2.19->tf-keras>=2.14.1->tensorflow-hub)\n",
      "  Downloading ml_dtypes-0.5.1-cp39-cp39-win_amd64.whl.metadata (22 kB)\n",
      "Collecting tensorflow-io-gcs-filesystem>=0.23.1 (from tensorflow<2.20,>=2.19->tf-keras>=2.14.1->tensorflow-hub)\n",
      "  Downloading tensorflow_io_gcs_filesystem-0.31.0-cp39-cp39-win_amd64.whl.metadata (14 kB)\n",
      "Requirement already satisfied: charset_normalizer<4,>=2 in c:\\users\\yann\\anaconda3\\envs\\nlp_gpu_env\\lib\\site-packages (from requests<3,>=2.21.0->tensorflow<2.20,>=2.19->tf-keras>=2.14.1->tensorflow-hub) (3.4.2)\n",
      "Requirement already satisfied: idna<4,>=2.5 in c:\\users\\yann\\anaconda3\\envs\\nlp_gpu_env\\lib\\site-packages (from requests<3,>=2.21.0->tensorflow<2.20,>=2.19->tf-keras>=2.14.1->tensorflow-hub) (3.10)\n",
      "Requirement already satisfied: urllib3<3,>=1.21.1 in c:\\users\\yann\\anaconda3\\envs\\nlp_gpu_env\\lib\\site-packages (from requests<3,>=2.21.0->tensorflow<2.20,>=2.19->tf-keras>=2.14.1->tensorflow-hub) (2.5.0)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in c:\\users\\yann\\anaconda3\\envs\\nlp_gpu_env\\lib\\site-packages (from requests<3,>=2.21.0->tensorflow<2.20,>=2.19->tf-keras>=2.14.1->tensorflow-hub) (2025.6.15)\n",
      "Collecting markdown>=2.6.8 (from tensorboard~=2.19.0->tensorflow<2.20,>=2.19->tf-keras>=2.14.1->tensorflow-hub)\n",
      "  Downloading markdown-3.8.2-py3-none-any.whl.metadata (5.1 kB)\n",
      "Collecting tensorboard-data-server<0.8.0,>=0.7.0 (from tensorboard~=2.19.0->tensorflow<2.20,>=2.19->tf-keras>=2.14.1->tensorflow-hub)\n",
      "  Downloading tensorboard_data_server-0.7.2-py3-none-any.whl.metadata (1.1 kB)\n",
      "Collecting werkzeug>=1.0.1 (from tensorboard~=2.19.0->tensorflow<2.20,>=2.19->tf-keras>=2.14.1->tensorflow-hub)\n",
      "  Downloading werkzeug-3.1.3-py3-none-any.whl.metadata (3.7 kB)\n",
      "Requirement already satisfied: wheel<1.0,>=0.23.0 in c:\\users\\yann\\anaconda3\\envs\\nlp_gpu_env\\lib\\site-packages (from astunparse>=1.6.0->tensorflow<2.20,>=2.19->tf-keras>=2.14.1->tensorflow-hub) (0.45.1)\n",
      "Collecting rich (from keras>=3.5.0->tensorflow<2.20,>=2.19->tf-keras>=2.14.1->tensorflow-hub)\n",
      "  Using cached rich-14.0.0-py3-none-any.whl.metadata (18 kB)\n",
      "Collecting namex (from keras>=3.5.0->tensorflow<2.20,>=2.19->tf-keras>=2.14.1->tensorflow-hub)\n",
      "  Downloading namex-0.1.0-py3-none-any.whl.metadata (322 bytes)\n",
      "Collecting optree (from keras>=3.5.0->tensorflow<2.20,>=2.19->tf-keras>=2.14.1->tensorflow-hub)\n",
      "  Downloading optree-0.16.0-cp39-cp39-win_amd64.whl.metadata (31 kB)\n",
      "Requirement already satisfied: importlib-metadata>=4.4 in c:\\users\\yann\\anaconda3\\envs\\nlp_gpu_env\\lib\\site-packages (from markdown>=2.6.8->tensorboard~=2.19.0->tensorflow<2.20,>=2.19->tf-keras>=2.14.1->tensorflow-hub) (8.7.0)\n",
      "Requirement already satisfied: zipp>=3.20 in c:\\users\\yann\\anaconda3\\envs\\nlp_gpu_env\\lib\\site-packages (from importlib-metadata>=4.4->markdown>=2.6.8->tensorboard~=2.19.0->tensorflow<2.20,>=2.19->tf-keras>=2.14.1->tensorflow-hub) (3.23.0)\n",
      "Requirement already satisfied: MarkupSafe>=2.1.1 in c:\\users\\yann\\anaconda3\\envs\\nlp_gpu_env\\lib\\site-packages (from werkzeug>=1.0.1->tensorboard~=2.19.0->tensorflow<2.20,>=2.19->tf-keras>=2.14.1->tensorflow-hub) (2.1.5)\n",
      "Collecting markdown-it-py>=2.2.0 (from rich->keras>=3.5.0->tensorflow<2.20,>=2.19->tf-keras>=2.14.1->tensorflow-hub)\n",
      "  Using cached markdown_it_py-3.0.0-py3-none-any.whl.metadata (6.9 kB)\n",
      "Requirement already satisfied: pygments<3.0.0,>=2.13.0 in c:\\users\\yann\\anaconda3\\envs\\nlp_gpu_env\\lib\\site-packages (from rich->keras>=3.5.0->tensorflow<2.20,>=2.19->tf-keras>=2.14.1->tensorflow-hub) (2.19.2)\n",
      "Collecting mdurl~=0.1 (from markdown-it-py>=2.2.0->rich->keras>=3.5.0->tensorflow<2.20,>=2.19->tf-keras>=2.14.1->tensorflow-hub)\n",
      "  Using cached mdurl-0.1.2-py3-none-any.whl.metadata (1.6 kB)\n",
      "Using cached tensorflow_hub-0.16.1-py2.py3-none-any.whl (30 kB)\n",
      "Downloading tf_keras-2.19.0-py3-none-any.whl (1.7 MB)\n",
      "   ---------------------------------------- 0.0/1.7 MB ? eta -:--:--\n",
      "   ------------------------ --------------- 1.0/1.7 MB 5.6 MB/s eta 0:00:01\n",
      "   ---------------------------------------- 1.7/1.7 MB 4.9 MB/s eta 0:00:00\n",
      "Downloading tensorflow-2.19.0-cp39-cp39-win_amd64.whl (375.7 MB)\n",
      "   ---------------------------------------- 0.0/375.7 MB ? eta -:--:--\n",
      "   ---------------------------------------- 1.3/375.7 MB 6.7 MB/s eta 0:00:56\n",
      "   ---------------------------------------- 2.6/375.7 MB 6.6 MB/s eta 0:00:57\n",
      "   ---------------------------------------- 4.2/375.7 MB 6.6 MB/s eta 0:00:57\n",
      "    --------------------------------------- 5.5/375.7 MB 6.7 MB/s eta 0:00:56\n",
      "    --------------------------------------- 7.1/375.7 MB 6.7 MB/s eta 0:00:55\n",
      "    --------------------------------------- 8.4/375.7 MB 6.7 MB/s eta 0:00:56\n",
      "   - -------------------------------------- 9.7/375.7 MB 6.6 MB/s eta 0:00:56\n",
      "   - -------------------------------------- 11.3/375.7 MB 6.6 MB/s eta 0:00:56\n",
      "   - -------------------------------------- 12.6/375.7 MB 6.6 MB/s eta 0:00:56\n",
      "   - -------------------------------------- 13.9/375.7 MB 6.5 MB/s eta 0:00:56\n",
      "   - -------------------------------------- 15.2/375.7 MB 6.5 MB/s eta 0:00:56\n",
      "   - -------------------------------------- 16.5/375.7 MB 6.5 MB/s eta 0:00:56\n",
      "   - -------------------------------------- 17.8/375.7 MB 6.5 MB/s eta 0:00:56\n",
      "   -- ------------------------------------- 19.4/375.7 MB 6.5 MB/s eta 0:00:55\n",
      "   -- ------------------------------------- 20.7/375.7 MB 6.5 MB/s eta 0:00:55\n",
      "   -- ------------------------------------- 22.0/375.7 MB 6.4 MB/s eta 0:00:55\n",
      "   -- ------------------------------------- 23.3/375.7 MB 6.4 MB/s eta 0:00:55\n",
      "   -- ------------------------------------- 24.6/375.7 MB 6.4 MB/s eta 0:00:55\n",
      "   -- ------------------------------------- 26.0/375.7 MB 6.4 MB/s eta 0:00:55\n",
      "   -- ------------------------------------- 27.5/375.7 MB 6.4 MB/s eta 0:00:55\n",
      "   --- ------------------------------------ 28.8/375.7 MB 6.4 MB/s eta 0:00:54\n",
      "   --- ------------------------------------ 30.1/375.7 MB 6.4 MB/s eta 0:00:54\n",
      "   --- ------------------------------------ 31.5/375.7 MB 6.4 MB/s eta 0:00:54\n",
      "   --- ------------------------------------ 32.8/375.7 MB 6.4 MB/s eta 0:00:54\n",
      "   --- ------------------------------------ 34.1/375.7 MB 6.4 MB/s eta 0:00:54\n",
      "   --- ------------------------------------ 35.7/375.7 MB 6.4 MB/s eta 0:00:53\n",
      "   --- ------------------------------------ 37.0/375.7 MB 6.4 MB/s eta 0:00:53\n",
      "   ---- ----------------------------------- 38.3/375.7 MB 6.4 MB/s eta 0:00:53\n",
      "   ---- ----------------------------------- 39.8/375.7 MB 6.4 MB/s eta 0:00:53\n",
      "   ---- ----------------------------------- 41.2/375.7 MB 6.4 MB/s eta 0:00:53\n",
      "   ---- ----------------------------------- 42.5/375.7 MB 6.4 MB/s eta 0:00:52\n",
      "   ---- ----------------------------------- 43.8/375.7 MB 6.4 MB/s eta 0:00:52\n",
      "   ---- ----------------------------------- 45.1/375.7 MB 6.4 MB/s eta 0:00:52\n",
      "   ---- ----------------------------------- 46.4/375.7 MB 6.4 MB/s eta 0:00:52\n",
      "   ----- ---------------------------------- 47.7/375.7 MB 6.4 MB/s eta 0:00:52\n",
      "   ----- ---------------------------------- 49.0/375.7 MB 6.4 MB/s eta 0:00:52\n",
      "   ----- ---------------------------------- 50.3/375.7 MB 6.4 MB/s eta 0:00:51\n",
      "   ----- ---------------------------------- 51.9/375.7 MB 6.4 MB/s eta 0:00:51\n",
      "   ----- ---------------------------------- 53.2/375.7 MB 6.4 MB/s eta 0:00:51\n",
      "   ----- ---------------------------------- 54.5/375.7 MB 6.4 MB/s eta 0:00:51\n",
      "   ----- ---------------------------------- 56.1/375.7 MB 6.4 MB/s eta 0:00:50\n",
      "   ------ --------------------------------- 57.4/375.7 MB 6.4 MB/s eta 0:00:50\n",
      "   ------ --------------------------------- 58.7/375.7 MB 6.4 MB/s eta 0:00:50\n",
      "   ------ --------------------------------- 60.0/375.7 MB 6.4 MB/s eta 0:00:50\n",
      "   ------ --------------------------------- 61.6/375.7 MB 6.4 MB/s eta 0:00:50\n",
      "   ------ --------------------------------- 62.9/375.7 MB 6.4 MB/s eta 0:00:49\n",
      "   ------ --------------------------------- 64.2/375.7 MB 6.4 MB/s eta 0:00:49\n",
      "   ------ --------------------------------- 65.5/375.7 MB 6.4 MB/s eta 0:00:49\n",
      "   ------- -------------------------------- 66.8/375.7 MB 6.4 MB/s eta 0:00:49\n",
      "   ------- -------------------------------- 68.4/375.7 MB 6.4 MB/s eta 0:00:49\n",
      "   ------- -------------------------------- 69.7/375.7 MB 6.4 MB/s eta 0:00:48\n",
      "   ------- -------------------------------- 71.0/375.7 MB 6.4 MB/s eta 0:00:48\n",
      "   ------- -------------------------------- 72.4/375.7 MB 6.4 MB/s eta 0:00:48\n",
      "   ------- -------------------------------- 73.9/375.7 MB 6.4 MB/s eta 0:00:48\n",
      "   -------- ------------------------------- 75.2/375.7 MB 6.4 MB/s eta 0:00:48\n",
      "   -------- ------------------------------- 76.5/375.7 MB 6.4 MB/s eta 0:00:47\n",
      "   -------- ------------------------------- 77.9/375.7 MB 6.4 MB/s eta 0:00:47\n",
      "   -------- ------------------------------- 79.2/375.7 MB 6.4 MB/s eta 0:00:47\n",
      "   -------- ------------------------------- 80.7/375.7 MB 6.4 MB/s eta 0:00:47\n",
      "   -------- ------------------------------- 81.8/375.7 MB 6.4 MB/s eta 0:00:47\n",
      "   -------- ------------------------------- 83.1/375.7 MB 6.4 MB/s eta 0:00:47\n",
      "   -------- ------------------------------- 84.4/375.7 MB 6.4 MB/s eta 0:00:46\n",
      "   --------- ------------------------------ 85.7/375.7 MB 6.4 MB/s eta 0:00:46\n",
      "   --------- ------------------------------ 87.3/375.7 MB 6.4 MB/s eta 0:00:46\n",
      "   --------- ------------------------------ 88.6/375.7 MB 6.4 MB/s eta 0:00:46\n",
      "   --------- ------------------------------ 89.9/375.7 MB 6.4 MB/s eta 0:00:45\n",
      "   --------- ------------------------------ 91.2/375.7 MB 6.4 MB/s eta 0:00:45\n",
      "   --------- ------------------------------ 92.5/375.7 MB 6.4 MB/s eta 0:00:45\n",
      "   --------- ------------------------------ 93.8/375.7 MB 6.3 MB/s eta 0:00:45\n",
      "   ---------- ----------------------------- 95.2/375.7 MB 6.4 MB/s eta 0:00:45\n",
      "   ---------- ----------------------------- 96.7/375.7 MB 6.4 MB/s eta 0:00:44\n",
      "   ---------- ----------------------------- 98.0/375.7 MB 6.3 MB/s eta 0:00:44\n",
      "   ---------- ----------------------------- 99.4/375.7 MB 6.3 MB/s eta 0:00:44\n",
      "   ---------- ----------------------------- 100.7/375.7 MB 6.3 MB/s eta 0:00:44\n",
      "   ---------- ----------------------------- 102.0/375.7 MB 6.3 MB/s eta 0:00:44\n",
      "   ---------- ----------------------------- 103.3/375.7 MB 6.3 MB/s eta 0:00:43\n",
      "   ----------- ---------------------------- 104.9/375.7 MB 6.3 MB/s eta 0:00:43\n",
      "   ----------- ---------------------------- 106.2/375.7 MB 6.3 MB/s eta 0:00:43\n",
      "   ----------- ---------------------------- 107.5/375.7 MB 6.3 MB/s eta 0:00:43\n",
      "   ----------- ---------------------------- 108.8/375.7 MB 6.3 MB/s eta 0:00:43\n",
      "   ----------- ---------------------------- 110.1/375.7 MB 6.3 MB/s eta 0:00:42\n",
      "   ----------- ---------------------------- 111.4/375.7 MB 6.3 MB/s eta 0:00:42\n",
      "   ------------ --------------------------- 112.7/375.7 MB 6.3 MB/s eta 0:00:42\n",
      "   ------------ --------------------------- 114.0/375.7 MB 6.3 MB/s eta 0:00:42\n",
      "   ------------ --------------------------- 115.3/375.7 MB 6.3 MB/s eta 0:00:42\n",
      "   ------------ --------------------------- 116.7/375.7 MB 6.3 MB/s eta 0:00:41\n",
      "   ------------ --------------------------- 118.0/375.7 MB 6.3 MB/s eta 0:00:41\n",
      "   ------------ --------------------------- 119.5/375.7 MB 6.3 MB/s eta 0:00:41\n",
      "   ------------ --------------------------- 120.8/375.7 MB 6.3 MB/s eta 0:00:41\n",
      "   ------------- -------------------------- 122.2/375.7 MB 6.3 MB/s eta 0:00:41\n",
      "   ------------- -------------------------- 123.5/375.7 MB 6.3 MB/s eta 0:00:40\n",
      "   ------------- -------------------------- 124.8/375.7 MB 6.3 MB/s eta 0:00:40\n",
      "   ------------- -------------------------- 126.4/375.7 MB 6.3 MB/s eta 0:00:40\n",
      "   ------------- -------------------------- 127.4/375.7 MB 6.3 MB/s eta 0:00:40\n",
      "   ------------- -------------------------- 128.7/375.7 MB 6.3 MB/s eta 0:00:40\n",
      "   ------------- -------------------------- 130.0/375.7 MB 6.3 MB/s eta 0:00:39\n",
      "   -------------- ------------------------- 131.6/375.7 MB 6.3 MB/s eta 0:00:39\n",
      "   -------------- ------------------------- 132.9/375.7 MB 6.3 MB/s eta 0:00:39\n",
      "   -------------- ------------------------- 134.2/375.7 MB 6.3 MB/s eta 0:00:39\n",
      "   -------------- ------------------------- 135.3/375.7 MB 6.3 MB/s eta 0:00:39\n",
      "   -------------- ------------------------- 136.6/375.7 MB 6.3 MB/s eta 0:00:38\n",
      "   -------------- ------------------------- 137.9/375.7 MB 6.3 MB/s eta 0:00:38\n",
      "   -------------- ------------------------- 139.2/375.7 MB 6.3 MB/s eta 0:00:38\n",
      "   -------------- ------------------------- 140.5/375.7 MB 6.3 MB/s eta 0:00:38\n",
      "   --------------- ------------------------ 141.8/375.7 MB 6.3 MB/s eta 0:00:38\n",
      "   --------------- ------------------------ 143.1/375.7 MB 6.3 MB/s eta 0:00:37\n",
      "   --------------- ------------------------ 144.4/375.7 MB 6.3 MB/s eta 0:00:37\n",
      "   --------------- ------------------------ 145.8/375.7 MB 6.3 MB/s eta 0:00:37\n",
      "   --------------- ------------------------ 147.3/375.7 MB 6.3 MB/s eta 0:00:37\n",
      "   --------------- ------------------------ 148.6/375.7 MB 6.3 MB/s eta 0:00:37\n",
      "   --------------- ------------------------ 149.9/375.7 MB 6.3 MB/s eta 0:00:36\n",
      "   ---------------- ----------------------- 151.3/375.7 MB 6.3 MB/s eta 0:00:36\n",
      "   ---------------- ----------------------- 152.6/375.7 MB 6.3 MB/s eta 0:00:36\n",
      "   ---------------- ----------------------- 153.9/375.7 MB 6.3 MB/s eta 0:00:36\n",
      "   ---------------- ----------------------- 155.2/375.7 MB 6.3 MB/s eta 0:00:36\n",
      "   ---------------- ----------------------- 156.5/375.7 MB 6.3 MB/s eta 0:00:35\n",
      "   ---------------- ----------------------- 157.8/375.7 MB 6.3 MB/s eta 0:00:35\n",
      "   ---------------- ----------------------- 159.1/375.7 MB 6.3 MB/s eta 0:00:35\n",
      "   ----------------- ---------------------- 160.4/375.7 MB 6.3 MB/s eta 0:00:35\n",
      "   ----------------- ---------------------- 161.7/375.7 MB 6.3 MB/s eta 0:00:35\n",
      "   ----------------- ---------------------- 163.1/375.7 MB 6.3 MB/s eta 0:00:34\n",
      "   ----------------- ---------------------- 164.4/375.7 MB 6.3 MB/s eta 0:00:34\n",
      "   ----------------- ---------------------- 165.7/375.7 MB 6.3 MB/s eta 0:00:34\n",
      "   ----------------- ---------------------- 167.2/375.7 MB 6.3 MB/s eta 0:00:34\n",
      "   ----------------- ---------------------- 168.6/375.7 MB 6.3 MB/s eta 0:00:33\n",
      "   ------------------ --------------------- 169.9/375.7 MB 6.3 MB/s eta 0:00:33\n",
      "   ------------------ --------------------- 171.2/375.7 MB 6.3 MB/s eta 0:00:33\n",
      "   ------------------ --------------------- 172.5/375.7 MB 6.3 MB/s eta 0:00:33\n",
      "   ------------------ --------------------- 173.8/375.7 MB 6.3 MB/s eta 0:00:33\n",
      "   ------------------ --------------------- 175.1/375.7 MB 6.3 MB/s eta 0:00:32\n",
      "   ------------------ --------------------- 176.7/375.7 MB 6.3 MB/s eta 0:00:32\n",
      "   ------------------ --------------------- 178.0/375.7 MB 6.3 MB/s eta 0:00:32\n",
      "   ------------------- -------------------- 179.0/375.7 MB 6.3 MB/s eta 0:00:32\n",
      "   ------------------- -------------------- 180.4/375.7 MB 6.3 MB/s eta 0:00:32\n",
      "   ------------------- -------------------- 181.4/375.7 MB 6.3 MB/s eta 0:00:31\n",
      "   ------------------- -------------------- 182.7/375.7 MB 6.3 MB/s eta 0:00:31\n",
      "   ------------------- -------------------- 184.0/375.7 MB 6.3 MB/s eta 0:00:31\n",
      "   ------------------- -------------------- 185.1/375.7 MB 6.3 MB/s eta 0:00:31\n",
      "   ------------------- -------------------- 186.4/375.7 MB 6.2 MB/s eta 0:00:31\n",
      "   ------------------- -------------------- 187.4/375.7 MB 6.2 MB/s eta 0:00:31\n",
      "   -------------------- ------------------- 188.7/375.7 MB 6.2 MB/s eta 0:00:30\n",
      "   -------------------- ------------------- 190.3/375.7 MB 6.2 MB/s eta 0:00:30\n",
      "   -------------------- ------------------- 191.9/375.7 MB 6.2 MB/s eta 0:00:30\n",
      "   -------------------- ------------------- 193.2/375.7 MB 6.2 MB/s eta 0:00:30\n",
      "   -------------------- ------------------- 194.8/375.7 MB 6.2 MB/s eta 0:00:29\n",
      "   -------------------- ------------------- 196.3/375.7 MB 6.3 MB/s eta 0:00:29\n",
      "   --------------------- ------------------ 197.7/375.7 MB 6.3 MB/s eta 0:00:29\n",
      "   --------------------- ------------------ 199.2/375.7 MB 6.3 MB/s eta 0:00:29\n",
      "   --------------------- ------------------ 200.8/375.7 MB 6.3 MB/s eta 0:00:28\n",
      "   --------------------- ------------------ 202.1/375.7 MB 6.3 MB/s eta 0:00:28\n",
      "   --------------------- ------------------ 203.7/375.7 MB 6.3 MB/s eta 0:00:28\n",
      "   --------------------- ------------------ 205.3/375.7 MB 6.3 MB/s eta 0:00:28\n",
      "   ---------------------- ----------------- 206.8/375.7 MB 6.3 MB/s eta 0:00:27\n",
      "   ---------------------- ----------------- 208.1/375.7 MB 6.3 MB/s eta 0:00:27\n",
      "   ---------------------- ----------------- 209.7/375.7 MB 6.3 MB/s eta 0:00:27\n",
      "   ---------------------- ----------------- 211.3/375.7 MB 6.3 MB/s eta 0:00:27\n",
      "   ---------------------- ----------------- 212.6/375.7 MB 6.3 MB/s eta 0:00:26\n",
      "   ---------------------- ----------------- 214.2/375.7 MB 6.3 MB/s eta 0:00:26\n",
      "   ---------------------- ----------------- 215.7/375.7 MB 6.3 MB/s eta 0:00:26\n",
      "   ----------------------- ---------------- 217.1/375.7 MB 6.3 MB/s eta 0:00:26\n",
      "   ----------------------- ---------------- 218.6/375.7 MB 6.3 MB/s eta 0:00:25\n",
      "   ----------------------- ---------------- 219.9/375.7 MB 6.3 MB/s eta 0:00:25\n",
      "   ----------------------- ---------------- 221.5/375.7 MB 6.3 MB/s eta 0:00:25\n",
      "   ----------------------- ---------------- 223.1/375.7 MB 6.3 MB/s eta 0:00:25\n",
      "   ----------------------- ---------------- 224.4/375.7 MB 6.3 MB/s eta 0:00:24\n",
      "   ------------------------ --------------- 226.0/375.7 MB 6.3 MB/s eta 0:00:24\n",
      "   ------------------------ --------------- 227.5/375.7 MB 6.3 MB/s eta 0:00:24\n",
      "   ------------------------ --------------- 228.9/375.7 MB 6.3 MB/s eta 0:00:24\n",
      "   ------------------------ --------------- 230.4/375.7 MB 6.3 MB/s eta 0:00:23\n",
      "   ------------------------ --------------- 231.7/375.7 MB 6.3 MB/s eta 0:00:23\n",
      "   ------------------------ --------------- 233.3/375.7 MB 6.3 MB/s eta 0:00:23\n",
      "   ------------------------- -------------- 234.9/375.7 MB 6.4 MB/s eta 0:00:23\n",
      "   ------------------------- -------------- 236.2/375.7 MB 6.4 MB/s eta 0:00:22\n",
      "   ------------------------- -------------- 237.8/375.7 MB 6.4 MB/s eta 0:00:22\n",
      "   ------------------------- -------------- 239.3/375.7 MB 6.4 MB/s eta 0:00:22\n",
      "   ------------------------- -------------- 240.6/375.7 MB 6.4 MB/s eta 0:00:22\n",
      "   ------------------------- -------------- 242.2/375.7 MB 6.4 MB/s eta 0:00:21\n",
      "   ------------------------- -------------- 243.8/375.7 MB 6.4 MB/s eta 0:00:21\n",
      "   -------------------------- ------------- 245.4/375.7 MB 6.4 MB/s eta 0:00:21\n",
      "   -------------------------- ------------- 246.9/375.7 MB 6.4 MB/s eta 0:00:21\n",
      "   -------------------------- ------------- 248.3/375.7 MB 6.4 MB/s eta 0:00:20\n",
      "   -------------------------- ------------- 249.8/375.7 MB 6.4 MB/s eta 0:00:20\n",
      "   -------------------------- ------------- 251.4/375.7 MB 6.4 MB/s eta 0:00:20\n",
      "   -------------------------- ------------- 253.0/375.7 MB 6.4 MB/s eta 0:00:20\n",
      "   --------------------------- ------------ 254.3/375.7 MB 6.4 MB/s eta 0:00:19\n",
      "   --------------------------- ------------ 255.9/375.7 MB 6.4 MB/s eta 0:00:19\n",
      "   --------------------------- ------------ 257.4/375.7 MB 6.4 MB/s eta 0:00:19\n",
      "   --------------------------- ------------ 258.7/375.7 MB 6.4 MB/s eta 0:00:19\n",
      "   --------------------------- ------------ 260.3/375.7 MB 6.4 MB/s eta 0:00:18\n",
      "   --------------------------- ------------ 261.9/375.7 MB 6.4 MB/s eta 0:00:18\n",
      "   ---------------------------- ----------- 263.2/375.7 MB 6.4 MB/s eta 0:00:18\n",
      "   ---------------------------- ----------- 264.8/375.7 MB 6.4 MB/s eta 0:00:18\n",
      "   ---------------------------- ----------- 266.3/375.7 MB 6.4 MB/s eta 0:00:17\n",
      "   ---------------------------- ----------- 267.9/375.7 MB 6.5 MB/s eta 0:00:17\n",
      "   ---------------------------- ----------- 269.2/375.7 MB 6.5 MB/s eta 0:00:17\n",
      "   ---------------------------- ----------- 270.8/375.7 MB 6.5 MB/s eta 0:00:17\n",
      "   ---------------------------- ----------- 272.4/375.7 MB 6.5 MB/s eta 0:00:16\n",
      "   ----------------------------- ---------- 273.7/375.7 MB 6.5 MB/s eta 0:00:16\n",
      "   ----------------------------- ---------- 275.3/375.7 MB 6.5 MB/s eta 0:00:16\n",
      "   ----------------------------- ---------- 276.8/375.7 MB 6.5 MB/s eta 0:00:16\n",
      "   ----------------------------- ---------- 278.4/375.7 MB 6.5 MB/s eta 0:00:15\n",
      "   ----------------------------- ---------- 279.7/375.7 MB 6.5 MB/s eta 0:00:15\n",
      "   ----------------------------- ---------- 281.3/375.7 MB 6.5 MB/s eta 0:00:15\n",
      "   ------------------------------ --------- 282.9/375.7 MB 6.5 MB/s eta 0:00:15\n",
      "   ------------------------------ --------- 284.2/375.7 MB 6.5 MB/s eta 0:00:15\n",
      "   ------------------------------ --------- 285.7/375.7 MB 6.5 MB/s eta 0:00:14\n",
      "   ------------------------------ --------- 287.3/375.7 MB 6.5 MB/s eta 0:00:14\n",
      "   ------------------------------ --------- 288.9/375.7 MB 6.5 MB/s eta 0:00:14\n",
      "   ------------------------------ --------- 290.2/375.7 MB 6.5 MB/s eta 0:00:14\n",
      "   ------------------------------- -------- 291.8/375.7 MB 6.5 MB/s eta 0:00:13\n",
      "   ------------------------------- -------- 293.3/375.7 MB 6.5 MB/s eta 0:00:13\n",
      "   ------------------------------- -------- 294.6/375.7 MB 6.5 MB/s eta 0:00:13\n",
      "   ------------------------------- -------- 296.2/375.7 MB 6.6 MB/s eta 0:00:13\n",
      "   ------------------------------- -------- 297.8/375.7 MB 6.6 MB/s eta 0:00:12\n",
      "   ------------------------------- -------- 299.1/375.7 MB 6.6 MB/s eta 0:00:12\n",
      "   -------------------------------- ------- 300.7/375.7 MB 6.6 MB/s eta 0:00:12\n",
      "   -------------------------------- ------- 302.3/375.7 MB 6.6 MB/s eta 0:00:12\n",
      "   -------------------------------- ------- 303.6/375.7 MB 6.6 MB/s eta 0:00:11\n",
      "   -------------------------------- ------- 305.1/375.7 MB 6.6 MB/s eta 0:00:11\n",
      "   -------------------------------- ------- 306.7/375.7 MB 6.6 MB/s eta 0:00:11\n",
      "   -------------------------------- ------- 308.0/375.7 MB 6.6 MB/s eta 0:00:11\n",
      "   -------------------------------- ------- 309.6/375.7 MB 6.6 MB/s eta 0:00:11\n",
      "   --------------------------------- ------ 311.2/375.7 MB 6.6 MB/s eta 0:00:10\n",
      "   --------------------------------- ------ 312.7/375.7 MB 6.6 MB/s eta 0:00:10\n",
      "   --------------------------------- ------ 314.0/375.7 MB 6.6 MB/s eta 0:00:10\n",
      "   --------------------------------- ------ 315.6/375.7 MB 6.6 MB/s eta 0:00:10\n",
      "   --------------------------------- ------ 316.9/375.7 MB 6.6 MB/s eta 0:00:09\n",
      "   --------------------------------- ------ 318.5/375.7 MB 6.6 MB/s eta 0:00:09\n",
      "   ---------------------------------- ----- 320.1/375.7 MB 6.6 MB/s eta 0:00:09\n",
      "   ---------------------------------- ----- 321.4/375.7 MB 6.6 MB/s eta 0:00:09\n",
      "   ---------------------------------- ----- 323.0/375.7 MB 6.6 MB/s eta 0:00:08\n",
      "   ---------------------------------- ----- 324.5/375.7 MB 6.6 MB/s eta 0:00:08\n",
      "   ---------------------------------- ----- 325.8/375.7 MB 6.6 MB/s eta 0:00:08\n",
      "   ---------------------------------- ----- 327.4/375.7 MB 6.7 MB/s eta 0:00:08\n",
      "   ----------------------------------- ---- 329.0/375.7 MB 6.7 MB/s eta 0:00:08\n",
      "   ----------------------------------- ---- 330.3/375.7 MB 6.7 MB/s eta 0:00:07\n",
      "   ----------------------------------- ---- 331.9/375.7 MB 6.7 MB/s eta 0:00:07\n",
      "   ----------------------------------- ---- 333.4/375.7 MB 6.7 MB/s eta 0:00:07\n",
      "   ----------------------------------- ---- 334.8/375.7 MB 6.7 MB/s eta 0:00:07\n",
      "   ----------------------------------- ---- 336.3/375.7 MB 6.7 MB/s eta 0:00:06\n",
      "   ----------------------------------- ---- 337.6/375.7 MB 6.7 MB/s eta 0:00:06\n",
      "   ------------------------------------ --- 339.2/375.7 MB 6.7 MB/s eta 0:00:06\n",
      "   ------------------------------------ --- 340.8/375.7 MB 6.7 MB/s eta 0:00:06\n",
      "   ------------------------------------ --- 342.1/375.7 MB 6.7 MB/s eta 0:00:06\n",
      "   ------------------------------------ --- 343.7/375.7 MB 6.7 MB/s eta 0:00:05\n",
      "   ------------------------------------ --- 345.2/375.7 MB 6.7 MB/s eta 0:00:05\n",
      "   ------------------------------------ --- 346.6/375.7 MB 6.7 MB/s eta 0:00:05\n",
      "   ------------------------------------- -- 348.1/375.7 MB 6.7 MB/s eta 0:00:05\n",
      "   ------------------------------------- -- 349.7/375.7 MB 6.7 MB/s eta 0:00:04\n",
      "   ------------------------------------- -- 351.3/375.7 MB 6.7 MB/s eta 0:00:04\n",
      "   ------------------------------------- -- 352.8/375.7 MB 6.8 MB/s eta 0:00:04\n",
      "   ------------------------------------- -- 354.2/375.7 MB 6.8 MB/s eta 0:00:04\n",
      "   ------------------------------------- -- 355.7/375.7 MB 6.8 MB/s eta 0:00:03\n",
      "   -------------------------------------- - 357.3/375.7 MB 6.8 MB/s eta 0:00:03\n",
      "   -------------------------------------- - 358.6/375.7 MB 6.8 MB/s eta 0:00:03\n",
      "   -------------------------------------- - 360.2/375.7 MB 6.8 MB/s eta 0:00:03\n",
      "   -------------------------------------- - 361.8/375.7 MB 6.8 MB/s eta 0:00:03\n",
      "   -------------------------------------- - 363.1/375.7 MB 6.8 MB/s eta 0:00:02\n",
      "   -------------------------------------- - 364.6/375.7 MB 6.8 MB/s eta 0:00:02\n",
      "   -------------------------------------- - 366.0/375.7 MB 6.8 MB/s eta 0:00:02\n",
      "   ---------------------------------------  367.5/375.7 MB 6.8 MB/s eta 0:00:02\n",
      "   ---------------------------------------  369.1/375.7 MB 6.8 MB/s eta 0:00:01\n",
      "   ---------------------------------------  370.4/375.7 MB 6.8 MB/s eta 0:00:01\n",
      "   ---------------------------------------  372.0/375.7 MB 6.8 MB/s eta 0:00:01\n",
      "   ---------------------------------------  373.6/375.7 MB 6.8 MB/s eta 0:00:01\n",
      "   ---------------------------------------  374.9/375.7 MB 6.8 MB/s eta 0:00:01\n",
      "   ---------------------------------------  375.7/375.7 MB 6.8 MB/s eta 0:00:01\n",
      "   ---------------------------------------  375.7/375.7 MB 6.8 MB/s eta 0:00:01\n",
      "   ---------------------------------------  375.7/375.7 MB 6.8 MB/s eta 0:00:01\n",
      "   ---------------------------------------  375.7/375.7 MB 6.8 MB/s eta 0:00:01\n",
      "   ---------------------------------------  375.7/375.7 MB 6.8 MB/s eta 0:00:01\n",
      "   ---------------------------------------  375.7/375.7 MB 6.8 MB/s eta 0:00:01\n",
      "   ---------------------------------------  375.7/375.7 MB 6.8 MB/s eta 0:00:01\n",
      "   ---------------------------------------  375.7/375.7 MB 6.8 MB/s eta 0:00:01\n",
      "   ---------------------------------------  375.7/375.7 MB 6.8 MB/s eta 0:00:01\n",
      "   ---------------------------------------  375.7/375.7 MB 6.8 MB/s eta 0:00:01\n",
      "   ---------------------------------------  375.7/375.7 MB 6.8 MB/s eta 0:00:01\n",
      "   ---------------------------------------  375.7/375.7 MB 6.8 MB/s eta 0:00:01\n",
      "   ---------------------------------------- 375.7/375.7 MB 6.3 MB/s eta 0:00:00\n",
      "Downloading grpcio-1.73.1-cp39-cp39-win_amd64.whl (4.3 MB)\n",
      "   ---------------------------------------- 0.0/4.3 MB ? eta -:--:--\n",
      "   ------------ --------------------------- 1.3/4.3 MB 6.7 MB/s eta 0:00:01\n",
      "   -------------------------- ------------- 2.9/4.3 MB 7.0 MB/s eta 0:00:01\n",
      "   -------------------------------------- - 4.2/4.3 MB 6.8 MB/s eta 0:00:01\n",
      "   -------------------------------------- - 4.2/4.3 MB 6.8 MB/s eta 0:00:01\n",
      "   ---------------------------------------- 4.3/4.3 MB 4.7 MB/s eta 0:00:00\n",
      "Downloading ml_dtypes-0.5.1-cp39-cp39-win_amd64.whl (209 kB)\n",
      "Downloading protobuf-5.29.5-cp39-cp39-win_amd64.whl (434 kB)\n",
      "Downloading tensorboard-2.19.0-py3-none-any.whl (5.5 MB)\n",
      "   ---------------------------------------- 0.0/5.5 MB ? eta -:--:--\n",
      "   --------- ------------------------------ 1.3/5.5 MB 7.4 MB/s eta 0:00:01\n",
      "   -------------------- ------------------- 2.9/5.5 MB 7.0 MB/s eta 0:00:01\n",
      "   -------------------------------- ------- 4.5/5.5 MB 6.9 MB/s eta 0:00:01\n",
      "   -------------------------------------- - 5.2/5.5 MB 6.9 MB/s eta 0:00:01\n",
      "   ---------------------------------------- 5.5/5.5 MB 5.7 MB/s eta 0:00:00\n",
      "Downloading tensorboard_data_server-0.7.2-py3-none-any.whl (2.4 kB)\n",
      "Downloading absl_py-2.3.0-py3-none-any.whl (135 kB)\n",
      "Downloading astunparse-1.6.3-py2.py3-none-any.whl (12 kB)\n",
      "Downloading flatbuffers-25.2.10-py2.py3-none-any.whl (30 kB)\n",
      "Downloading gast-0.6.0-py3-none-any.whl (21 kB)\n",
      "Downloading google_pasta-0.2.0-py3-none-any.whl (57 kB)\n",
      "Downloading h5py-3.14.0-cp39-cp39-win_amd64.whl (2.9 MB)\n",
      "   ---------------------------------------- 0.0/2.9 MB ? eta -:--:--\n",
      "   ------------------ --------------------- 1.3/2.9 MB 6.7 MB/s eta 0:00:01\n",
      "   ------------------------------------ --- 2.6/2.9 MB 6.9 MB/s eta 0:00:01\n",
      "   ---------------------------------------- 2.9/2.9 MB 4.8 MB/s eta 0:00:00\n",
      "Downloading keras-3.10.0-py3-none-any.whl (1.4 MB)\n",
      "   ---------------------------------------- 0.0/1.4 MB ? eta -:--:--\n",
      "   ------------------------------------- -- 1.3/1.4 MB 6.7 MB/s eta 0:00:01\n",
      "   ---------------------------------------- 1.4/1.4 MB 4.0 MB/s eta 0:00:00\n",
      "Downloading libclang-18.1.1-py2.py3-none-win_amd64.whl (26.4 MB)\n",
      "   ---------------------------------------- 0.0/26.4 MB ? eta -:--:--\n",
      "   - -------------------------------------- 1.3/26.4 MB 6.7 MB/s eta 0:00:04\n",
      "   ---- ----------------------------------- 2.9/26.4 MB 6.7 MB/s eta 0:00:04\n",
      "   ------ --------------------------------- 4.2/26.4 MB 6.8 MB/s eta 0:00:04\n",
      "   -------- ------------------------------- 5.8/26.4 MB 6.8 MB/s eta 0:00:04\n",
      "   ---------- ----------------------------- 7.1/26.4 MB 6.8 MB/s eta 0:00:03\n",
      "   ------------- -------------------------- 8.7/26.4 MB 6.8 MB/s eta 0:00:03\n",
      "   --------------- ------------------------ 10.0/26.4 MB 6.7 MB/s eta 0:00:03\n",
      "   ----------------- ---------------------- 11.5/26.4 MB 6.8 MB/s eta 0:00:03\n",
      "   ------------------- -------------------- 12.8/26.4 MB 6.8 MB/s eta 0:00:02\n",
      "   --------------------- ------------------ 14.4/26.4 MB 6.8 MB/s eta 0:00:02\n",
      "   ----------------------- ---------------- 15.7/26.4 MB 6.8 MB/s eta 0:00:02\n",
      "   -------------------------- ------------- 17.3/26.4 MB 6.8 MB/s eta 0:00:02\n",
      "   ---------------------------- ----------- 18.6/26.4 MB 6.8 MB/s eta 0:00:02\n",
      "   ------------------------------ --------- 20.2/26.4 MB 6.8 MB/s eta 0:00:01\n",
      "   -------------------------------- ------- 21.5/26.4 MB 6.8 MB/s eta 0:00:01\n",
      "   ---------------------------------- ----- 23.1/26.4 MB 6.8 MB/s eta 0:00:01\n",
      "   ------------------------------------ --- 24.4/26.4 MB 6.8 MB/s eta 0:00:01\n",
      "   ---------------------------------------  26.0/26.4 MB 6.8 MB/s eta 0:00:01\n",
      "   ---------------------------------------  26.2/26.4 MB 6.8 MB/s eta 0:00:01\n",
      "   ---------------------------------------- 26.4/26.4 MB 6.4 MB/s eta 0:00:00\n",
      "Downloading markdown-3.8.2-py3-none-any.whl (106 kB)\n",
      "Downloading opt_einsum-3.4.0-py3-none-any.whl (71 kB)\n",
      "Downloading tensorflow_io_gcs_filesystem-0.31.0-cp39-cp39-win_amd64.whl (1.5 MB)\n",
      "   ---------------------------------------- 0.0/1.5 MB ? eta -:--:--\n",
      "   ----------------------------------- ---- 1.3/1.5 MB 6.7 MB/s eta 0:00:01\n",
      "   ---------------------------------------- 1.5/1.5 MB 4.4 MB/s eta 0:00:00\n",
      "Downloading termcolor-3.1.0-py3-none-any.whl (7.7 kB)\n",
      "Downloading werkzeug-3.1.3-py3-none-any.whl (224 kB)\n",
      "Downloading wrapt-1.17.2-cp39-cp39-win_amd64.whl (38 kB)\n",
      "Downloading namex-0.1.0-py3-none-any.whl (5.9 kB)\n",
      "Downloading optree-0.16.0-cp39-cp39-win_amd64.whl (300 kB)\n",
      "Using cached rich-14.0.0-py3-none-any.whl (243 kB)\n",
      "Using cached markdown_it_py-3.0.0-py3-none-any.whl (87 kB)\n",
      "Using cached mdurl-0.1.2-py3-none-any.whl (10.0 kB)\n",
      "Installing collected packages: namex, libclang, flatbuffers, wrapt, werkzeug, termcolor, tensorflow-io-gcs-filesystem, tensorboard-data-server, protobuf, optree, opt-einsum, ml-dtypes, mdurl, h5py, grpcio, google-pasta, gast, astunparse, absl-py, markdown-it-py, markdown, tensorboard, rich, keras, tensorflow, tf-keras, tensorflow-hub\n",
      "\n",
      "   ----------------------------------------  0/27 [namex]\n",
      "   - --------------------------------------  1/27 [libclang]\n",
      "   - --------------------------------------  1/27 [libclang]\n",
      "   -- -------------------------------------  2/27 [flatbuffers]\n",
      "   ---- -----------------------------------  3/27 [wrapt]\n",
      "   ----- ----------------------------------  4/27 [werkzeug]\n",
      "   ----- ----------------------------------  4/27 [werkzeug]\n",
      "   ----- ----------------------------------  4/27 [werkzeug]\n",
      "   ----- ----------------------------------  4/27 [werkzeug]\n",
      "   -------- ------------------------------  6/27 [tensorflow-io-gcs-filesystem]\n",
      "   ---------- -----------------------------  7/27 [tensorboard-data-server]\n",
      "   ----------- ----------------------------  8/27 [protobuf]\n",
      "   ----------- ----------------------------  8/27 [protobuf]\n",
      "   ------------- --------------------------  9/27 [optree]\n",
      "   ------------- --------------------------  9/27 [optree]\n",
      "   -------------- ------------------------- 10/27 [opt-einsum]\n",
      "   ---------------- ----------------------- 11/27 [ml-dtypes]\n",
      "   ----------------- ---------------------- 12/27 [mdurl]\n",
      "   ------------------- -------------------- 13/27 [h5py]\n",
      "   ------------------- -------------------- 13/27 [h5py]\n",
      "   ------------------- -------------------- 13/27 [h5py]\n",
      "   -------------------- ------------------- 14/27 [grpcio]\n",
      "   -------------------- ------------------- 14/27 [grpcio]\n",
      "   -------------------- ------------------- 14/27 [grpcio]\n",
      "   -------------------- ------------------- 14/27 [grpcio]\n",
      "   ---------------------- ----------------- 15/27 [google-pasta]\n",
      "   ---------------------- ----------------- 15/27 [google-pasta]\n",
      "   ----------------------- ---------------- 16/27 [gast]\n",
      "   ------------------------- -------------- 17/27 [astunparse]\n",
      "   -------------------------- ------------- 18/27 [absl-py]\n",
      "   ---------------------------- ----------- 19/27 [markdown-it-py]\n",
      "   ---------------------------- ----------- 19/27 [markdown-it-py]\n",
      "   ---------------------------- ----------- 19/27 [markdown-it-py]\n",
      "   ---------------------------- ----------- 19/27 [markdown-it-py]\n",
      "   ----------------------------- ---------- 20/27 [markdown]\n",
      "   ------------------------------- -------- 21/27 [tensorboard]\n",
      "   ------------------------------- -------- 21/27 [tensorboard]\n",
      "   ------------------------------- -------- 21/27 [tensorboard]\n",
      "   ------------------------------- -------- 21/27 [tensorboard]\n",
      "   ------------------------------- -------- 21/27 [tensorboard]\n",
      "   ------------------------------- -------- 21/27 [tensorboard]\n",
      "   ------------------------------- -------- 21/27 [tensorboard]\n",
      "   ------------------------------- -------- 21/27 [tensorboard]\n",
      "   ------------------------------- -------- 21/27 [tensorboard]\n",
      "   ------------------------------- -------- 21/27 [tensorboard]\n",
      "   ------------------------------- -------- 21/27 [tensorboard]\n",
      "   ------------------------------- -------- 21/27 [tensorboard]\n",
      "   ------------------------------- -------- 21/27 [tensorboard]\n",
      "   ------------------------------- -------- 21/27 [tensorboard]\n",
      "   ------------------------------- -------- 21/27 [tensorboard]\n",
      "   ------------------------------- -------- 21/27 [tensorboard]\n",
      "   ------------------------------- -------- 21/27 [tensorboard]\n",
      "   ------------------------------- -------- 21/27 [tensorboard]\n",
      "   ------------------------------- -------- 21/27 [tensorboard]\n",
      "   ------------------------------- -------- 21/27 [tensorboard]\n",
      "   ------------------------------- -------- 21/27 [tensorboard]\n",
      "   ------------------------------- -------- 21/27 [tensorboard]\n",
      "   ------------------------------- -------- 21/27 [tensorboard]\n",
      "   ------------------------------- -------- 21/27 [tensorboard]\n",
      "   -------------------------------- ------- 22/27 [rich]\n",
      "   -------------------------------- ------- 22/27 [rich]\n",
      "   -------------------------------- ------- 22/27 [rich]\n",
      "   -------------------------------- ------- 22/27 [rich]\n",
      "   -------------------------------- ------- 22/27 [rich]\n",
      "   ---------------------------------- ----- 23/27 [keras]\n",
      "   ---------------------------------- ----- 23/27 [keras]\n",
      "   ---------------------------------- ----- 23/27 [keras]\n",
      "   ---------------------------------- ----- 23/27 [keras]\n",
      "   ---------------------------------- ----- 23/27 [keras]\n",
      "   ---------------------------------- ----- 23/27 [keras]\n",
      "   ---------------------------------- ----- 23/27 [keras]\n",
      "   ---------------------------------- ----- 23/27 [keras]\n",
      "   ---------------------------------- ----- 23/27 [keras]\n",
      "   ---------------------------------- ----- 23/27 [keras]\n",
      "   ---------------------------------- ----- 23/27 [keras]\n",
      "   ---------------------------------- ----- 23/27 [keras]\n",
      "   ---------------------------------- ----- 23/27 [keras]\n",
      "   ---------------------------------- ----- 23/27 [keras]\n",
      "   ---------------------------------- ----- 23/27 [keras]\n",
      "   ---------------------------------- ----- 23/27 [keras]\n",
      "   ---------------------------------- ----- 23/27 [keras]\n",
      "   ---------------------------------- ----- 23/27 [keras]\n",
      "   ---------------------------------- ----- 23/27 [keras]\n",
      "   ---------------------------------- ----- 23/27 [keras]\n",
      "   ---------------------------------- ----- 23/27 [keras]\n",
      "   ---------------------------------- ----- 23/27 [keras]\n",
      "   ----------------------------------- ---- 24/27 [tensorflow]\n",
      "   ----------------------------------- ---- 24/27 [tensorflow]\n",
      "   ----------------------------------- ---- 24/27 [tensorflow]\n",
      "   ----------------------------------- ---- 24/27 [tensorflow]\n",
      "   ----------------------------------- ---- 24/27 [tensorflow]\n",
      "   ----------------------------------- ---- 24/27 [tensorflow]\n",
      "   ----------------------------------- ---- 24/27 [tensorflow]\n",
      "   ----------------------------------- ---- 24/27 [tensorflow]\n",
      "   ----------------------------------- ---- 24/27 [tensorflow]\n",
      "   ----------------------------------- ---- 24/27 [tensorflow]\n",
      "   ----------------------------------- ---- 24/27 [tensorflow]\n",
      "   ----------------------------------- ---- 24/27 [tensorflow]\n",
      "   ----------------------------------- ---- 24/27 [tensorflow]\n",
      "   ----------------------------------- ---- 24/27 [tensorflow]\n",
      "   ----------------------------------- ---- 24/27 [tensorflow]\n",
      "   ----------------------------------- ---- 24/27 [tensorflow]\n",
      "   ----------------------------------- ---- 24/27 [tensorflow]\n",
      "   ----------------------------------- ---- 24/27 [tensorflow]\n",
      "   ----------------------------------- ---- 24/27 [tensorflow]\n",
      "   ----------------------------------- ---- 24/27 [tensorflow]\n",
      "   ----------------------------------- ---- 24/27 [tensorflow]\n",
      "   ----------------------------------- ---- 24/27 [tensorflow]\n",
      "   ----------------------------------- ---- 24/27 [tensorflow]\n",
      "   ----------------------------------- ---- 24/27 [tensorflow]\n",
      "   ----------------------------------- ---- 24/27 [tensorflow]\n",
      "   ----------------------------------- ---- 24/27 [tensorflow]\n",
      "   ----------------------------------- ---- 24/27 [tensorflow]\n",
      "   ----------------------------------- ---- 24/27 [tensorflow]\n",
      "   ----------------------------------- ---- 24/27 [tensorflow]\n",
      "   ----------------------------------- ---- 24/27 [tensorflow]\n",
      "   ----------------------------------- ---- 24/27 [tensorflow]\n",
      "   ----------------------------------- ---- 24/27 [tensorflow]\n",
      "   ----------------------------------- ---- 24/27 [tensorflow]\n",
      "   ----------------------------------- ---- 24/27 [tensorflow]\n",
      "   ----------------------------------- ---- 24/27 [tensorflow]\n",
      "   ----------------------------------- ---- 24/27 [tensorflow]\n",
      "   ----------------------------------- ---- 24/27 [tensorflow]\n",
      "   ----------------------------------- ---- 24/27 [tensorflow]\n",
      "   ----------------------------------- ---- 24/27 [tensorflow]\n",
      "   ----------------------------------- ---- 24/27 [tensorflow]\n",
      "   ----------------------------------- ---- 24/27 [tensorflow]\n",
      "   ----------------------------------- ---- 24/27 [tensorflow]\n",
      "   ----------------------------------- ---- 24/27 [tensorflow]\n",
      "   ----------------------------------- ---- 24/27 [tensorflow]\n",
      "   ----------------------------------- ---- 24/27 [tensorflow]\n",
      "   ----------------------------------- ---- 24/27 [tensorflow]\n",
      "   ----------------------------------- ---- 24/27 [tensorflow]\n",
      "   ----------------------------------- ---- 24/27 [tensorflow]\n",
      "   ----------------------------------- ---- 24/27 [tensorflow]\n",
      "   ----------------------------------- ---- 24/27 [tensorflow]\n",
      "   ----------------------------------- ---- 24/27 [tensorflow]\n",
      "   ----------------------------------- ---- 24/27 [tensorflow]\n",
      "   ----------------------------------- ---- 24/27 [tensorflow]\n",
      "   ----------------------------------- ---- 24/27 [tensorflow]\n",
      "   ----------------------------------- ---- 24/27 [tensorflow]\n",
      "   ----------------------------------- ---- 24/27 [tensorflow]\n",
      "   ----------------------------------- ---- 24/27 [tensorflow]\n",
      "   ----------------------------------- ---- 24/27 [tensorflow]\n",
      "   ----------------------------------- ---- 24/27 [tensorflow]\n",
      "   ----------------------------------- ---- 24/27 [tensorflow]\n",
      "   ----------------------------------- ---- 24/27 [tensorflow]\n",
      "   ----------------------------------- ---- 24/27 [tensorflow]\n",
      "   ----------------------------------- ---- 24/27 [tensorflow]\n",
      "   ----------------------------------- ---- 24/27 [tensorflow]\n",
      "   ----------------------------------- ---- 24/27 [tensorflow]\n",
      "   ----------------------------------- ---- 24/27 [tensorflow]\n",
      "   ----------------------------------- ---- 24/27 [tensorflow]\n",
      "   ----------------------------------- ---- 24/27 [tensorflow]\n",
      "   ----------------------------------- ---- 24/27 [tensorflow]\n",
      "   ----------------------------------- ---- 24/27 [tensorflow]\n",
      "   ----------------------------------- ---- 24/27 [tensorflow]\n",
      "   ----------------------------------- ---- 24/27 [tensorflow]\n",
      "   ----------------------------------- ---- 24/27 [tensorflow]\n",
      "   ----------------------------------- ---- 24/27 [tensorflow]\n",
      "   ----------------------------------- ---- 24/27 [tensorflow]\n",
      "   ----------------------------------- ---- 24/27 [tensorflow]\n",
      "   ----------------------------------- ---- 24/27 [tensorflow]\n",
      "   ----------------------------------- ---- 24/27 [tensorflow]\n",
      "   ----------------------------------- ---- 24/27 [tensorflow]\n",
      "   ----------------------------------- ---- 24/27 [tensorflow]\n",
      "   ----------------------------------- ---- 24/27 [tensorflow]\n",
      "   ----------------------------------- ---- 24/27 [tensorflow]\n",
      "   ----------------------------------- ---- 24/27 [tensorflow]\n",
      "   ----------------------------------- ---- 24/27 [tensorflow]\n",
      "   ----------------------------------- ---- 24/27 [tensorflow]\n",
      "   ----------------------------------- ---- 24/27 [tensorflow]\n",
      "   ----------------------------------- ---- 24/27 [tensorflow]\n",
      "   ----------------------------------- ---- 24/27 [tensorflow]\n",
      "   ----------------------------------- ---- 24/27 [tensorflow]\n",
      "   ----------------------------------- ---- 24/27 [tensorflow]\n",
      "   ----------------------------------- ---- 24/27 [tensorflow]\n",
      "   ----------------------------------- ---- 24/27 [tensorflow]\n",
      "   ----------------------------------- ---- 24/27 [tensorflow]\n",
      "   ----------------------------------- ---- 24/27 [tensorflow]\n",
      "   ----------------------------------- ---- 24/27 [tensorflow]\n",
      "   ----------------------------------- ---- 24/27 [tensorflow]\n",
      "   ----------------------------------- ---- 24/27 [tensorflow]\n",
      "   ----------------------------------- ---- 24/27 [tensorflow]\n",
      "   ----------------------------------- ---- 24/27 [tensorflow]\n",
      "   ----------------------------------- ---- 24/27 [tensorflow]\n",
      "   ----------------------------------- ---- 24/27 [tensorflow]\n",
      "   ----------------------------------- ---- 24/27 [tensorflow]\n",
      "   ----------------------------------- ---- 24/27 [tensorflow]\n",
      "   ----------------------------------- ---- 24/27 [tensorflow]\n",
      "   ----------------------------------- ---- 24/27 [tensorflow]\n",
      "   ----------------------------------- ---- 24/27 [tensorflow]\n",
      "   ----------------------------------- ---- 24/27 [tensorflow]\n",
      "   ----------------------------------- ---- 24/27 [tensorflow]\n",
      "   ----------------------------------- ---- 24/27 [tensorflow]\n",
      "   ----------------------------------- ---- 24/27 [tensorflow]\n",
      "   ----------------------------------- ---- 24/27 [tensorflow]\n",
      "   ----------------------------------- ---- 24/27 [tensorflow]\n",
      "   ----------------------------------- ---- 24/27 [tensorflow]\n",
      "   ----------------------------------- ---- 24/27 [tensorflow]\n",
      "   ----------------------------------- ---- 24/27 [tensorflow]\n",
      "   ----------------------------------- ---- 24/27 [tensorflow]\n",
      "   ----------------------------------- ---- 24/27 [tensorflow]\n",
      "   ----------------------------------- ---- 24/27 [tensorflow]\n",
      "   ----------------------------------- ---- 24/27 [tensorflow]\n",
      "   ----------------------------------- ---- 24/27 [tensorflow]\n",
      "   ----------------------------------- ---- 24/27 [tensorflow]\n",
      "   ----------------------------------- ---- 24/27 [tensorflow]\n",
      "   ----------------------------------- ---- 24/27 [tensorflow]\n",
      "   ----------------------------------- ---- 24/27 [tensorflow]\n",
      "   ----------------------------------- ---- 24/27 [tensorflow]\n",
      "   ----------------------------------- ---- 24/27 [tensorflow]\n",
      "   ----------------------------------- ---- 24/27 [tensorflow]\n",
      "   ----------------------------------- ---- 24/27 [tensorflow]\n",
      "   ----------------------------------- ---- 24/27 [tensorflow]\n",
      "   ----------------------------------- ---- 24/27 [tensorflow]\n",
      "   ----------------------------------- ---- 24/27 [tensorflow]\n",
      "   ----------------------------------- ---- 24/27 [tensorflow]\n",
      "   ----------------------------------- ---- 24/27 [tensorflow]\n",
      "   ----------------------------------- ---- 24/27 [tensorflow]\n",
      "   ----------------------------------- ---- 24/27 [tensorflow]\n",
      "   ----------------------------------- ---- 24/27 [tensorflow]\n",
      "   ----------------------------------- ---- 24/27 [tensorflow]\n",
      "   ----------------------------------- ---- 24/27 [tensorflow]\n",
      "   ----------------------------------- ---- 24/27 [tensorflow]\n",
      "   ----------------------------------- ---- 24/27 [tensorflow]\n",
      "   ----------------------------------- ---- 24/27 [tensorflow]\n",
      "   ----------------------------------- ---- 24/27 [tensorflow]\n",
      "   ----------------------------------- ---- 24/27 [tensorflow]\n",
      "   ----------------------------------- ---- 24/27 [tensorflow]\n",
      "   ----------------------------------- ---- 24/27 [tensorflow]\n",
      "   ----------------------------------- ---- 24/27 [tensorflow]\n",
      "   ----------------------------------- ---- 24/27 [tensorflow]\n",
      "   ----------------------------------- ---- 24/27 [tensorflow]\n",
      "   ----------------------------------- ---- 24/27 [tensorflow]\n",
      "   ----------------------------------- ---- 24/27 [tensorflow]\n",
      "   ----------------------------------- ---- 24/27 [tensorflow]\n",
      "   ----------------------------------- ---- 24/27 [tensorflow]\n",
      "   ----------------------------------- ---- 24/27 [tensorflow]\n",
      "   ----------------------------------- ---- 24/27 [tensorflow]\n",
      "   ----------------------------------- ---- 24/27 [tensorflow]\n",
      "   ----------------------------------- ---- 24/27 [tensorflow]\n",
      "   ----------------------------------- ---- 24/27 [tensorflow]\n",
      "   ----------------------------------- ---- 24/27 [tensorflow]\n",
      "   ----------------------------------- ---- 24/27 [tensorflow]\n",
      "   ----------------------------------- ---- 24/27 [tensorflow]\n",
      "   ----------------------------------- ---- 24/27 [tensorflow]\n",
      "   ----------------------------------- ---- 24/27 [tensorflow]\n",
      "   ----------------------------------- ---- 24/27 [tensorflow]\n",
      "   ----------------------------------- ---- 24/27 [tensorflow]\n",
      "   ----------------------------------- ---- 24/27 [tensorflow]\n",
      "   ----------------------------------- ---- 24/27 [tensorflow]\n",
      "   ----------------------------------- ---- 24/27 [tensorflow]\n",
      "   ----------------------------------- ---- 24/27 [tensorflow]\n",
      "   ----------------------------------- ---- 24/27 [tensorflow]\n",
      "   ----------------------------------- ---- 24/27 [tensorflow]\n",
      "   ----------------------------------- ---- 24/27 [tensorflow]\n",
      "   ----------------------------------- ---- 24/27 [tensorflow]\n",
      "   ----------------------------------- ---- 24/27 [tensorflow]\n",
      "   ----------------------------------- ---- 24/27 [tensorflow]\n",
      "   ----------------------------------- ---- 24/27 [tensorflow]\n",
      "   ----------------------------------- ---- 24/27 [tensorflow]\n",
      "   ----------------------------------- ---- 24/27 [tensorflow]\n",
      "   ----------------------------------- ---- 24/27 [tensorflow]\n",
      "   ----------------------------------- ---- 24/27 [tensorflow]\n",
      "   ----------------------------------- ---- 24/27 [tensorflow]\n",
      "   ----------------------------------- ---- 24/27 [tensorflow]\n",
      "   ----------------------------------- ---- 24/27 [tensorflow]\n",
      "   ----------------------------------- ---- 24/27 [tensorflow]\n",
      "   ----------------------------------- ---- 24/27 [tensorflow]\n",
      "   ----------------------------------- ---- 24/27 [tensorflow]\n",
      "   ----------------------------------- ---- 24/27 [tensorflow]\n",
      "   ----------------------------------- ---- 24/27 [tensorflow]\n",
      "   ----------------------------------- ---- 24/27 [tensorflow]\n",
      "   ----------------------------------- ---- 24/27 [tensorflow]\n",
      "   ----------------------------------- ---- 24/27 [tensorflow]\n",
      "   ----------------------------------- ---- 24/27 [tensorflow]\n",
      "   ----------------------------------- ---- 24/27 [tensorflow]\n",
      "   ----------------------------------- ---- 24/27 [tensorflow]\n",
      "   ----------------------------------- ---- 24/27 [tensorflow]\n",
      "   ----------------------------------- ---- 24/27 [tensorflow]\n",
      "   ----------------------------------- ---- 24/27 [tensorflow]\n",
      "   ----------------------------------- ---- 24/27 [tensorflow]\n",
      "   ----------------------------------- ---- 24/27 [tensorflow]\n",
      "   ----------------------------------- ---- 24/27 [tensorflow]\n",
      "   ----------------------------------- ---- 24/27 [tensorflow]\n",
      "   ----------------------------------- ---- 24/27 [tensorflow]\n",
      "   ----------------------------------- ---- 24/27 [tensorflow]\n",
      "   ----------------------------------- ---- 24/27 [tensorflow]\n",
      "   ----------------------------------- ---- 24/27 [tensorflow]\n",
      "   ----------------------------------- ---- 24/27 [tensorflow]\n",
      "   ----------------------------------- ---- 24/27 [tensorflow]\n",
      "   ----------------------------------- ---- 24/27 [tensorflow]\n",
      "   ----------------------------------- ---- 24/27 [tensorflow]\n",
      "   ----------------------------------- ---- 24/27 [tensorflow]\n",
      "   ----------------------------------- ---- 24/27 [tensorflow]\n",
      "   ----------------------------------- ---- 24/27 [tensorflow]\n",
      "   ----------------------------------- ---- 24/27 [tensorflow]\n",
      "   ----------------------------------- ---- 24/27 [tensorflow]\n",
      "   ----------------------------------- ---- 24/27 [tensorflow]\n",
      "   ----------------------------------- ---- 24/27 [tensorflow]\n",
      "   ----------------------------------- ---- 24/27 [tensorflow]\n",
      "   ----------------------------------- ---- 24/27 [tensorflow]\n",
      "   ----------------------------------- ---- 24/27 [tensorflow]\n",
      "   ----------------------------------- ---- 24/27 [tensorflow]\n",
      "   ----------------------------------- ---- 24/27 [tensorflow]\n",
      "   ----------------------------------- ---- 24/27 [tensorflow]\n",
      "   ----------------------------------- ---- 24/27 [tensorflow]\n",
      "   ----------------------------------- ---- 24/27 [tensorflow]\n",
      "   ----------------------------------- ---- 24/27 [tensorflow]\n",
      "   ----------------------------------- ---- 24/27 [tensorflow]\n",
      "   ----------------------------------- ---- 24/27 [tensorflow]\n",
      "   ----------------------------------- ---- 24/27 [tensorflow]\n",
      "   ----------------------------------- ---- 24/27 [tensorflow]\n",
      "   ----------------------------------- ---- 24/27 [tensorflow]\n",
      "   ----------------------------------- ---- 24/27 [tensorflow]\n",
      "   ----------------------------------- ---- 24/27 [tensorflow]\n",
      "   ----------------------------------- ---- 24/27 [tensorflow]\n",
      "   ----------------------------------- ---- 24/27 [tensorflow]\n",
      "   ----------------------------------- ---- 24/27 [tensorflow]\n",
      "   ----------------------------------- ---- 24/27 [tensorflow]\n",
      "   ----------------------------------- ---- 24/27 [tensorflow]\n",
      "   ----------------------------------- ---- 24/27 [tensorflow]\n",
      "   ----------------------------------- ---- 24/27 [tensorflow]\n",
      "   ----------------------------------- ---- 24/27 [tensorflow]\n",
      "   ----------------------------------- ---- 24/27 [tensorflow]\n",
      "   ----------------------------------- ---- 24/27 [tensorflow]\n",
      "   ----------------------------------- ---- 24/27 [tensorflow]\n",
      "   ----------------------------------- ---- 24/27 [tensorflow]\n",
      "   ----------------------------------- ---- 24/27 [tensorflow]\n",
      "   ----------------------------------- ---- 24/27 [tensorflow]\n",
      "   ----------------------------------- ---- 24/27 [tensorflow]\n",
      "   ----------------------------------- ---- 24/27 [tensorflow]\n",
      "   ----------------------------------- ---- 24/27 [tensorflow]\n",
      "   ----------------------------------- ---- 24/27 [tensorflow]\n",
      "   ----------------------------------- ---- 24/27 [tensorflow]\n",
      "   ----------------------------------- ---- 24/27 [tensorflow]\n",
      "   ----------------------------------- ---- 24/27 [tensorflow]\n",
      "   ----------------------------------- ---- 24/27 [tensorflow]\n",
      "   ----------------------------------- ---- 24/27 [tensorflow]\n",
      "   ----------------------------------- ---- 24/27 [tensorflow]\n",
      "   ----------------------------------- ---- 24/27 [tensorflow]\n",
      "   ----------------------------------- ---- 24/27 [tensorflow]\n",
      "   ----------------------------------- ---- 24/27 [tensorflow]\n",
      "   ----------------------------------- ---- 24/27 [tensorflow]\n",
      "   ----------------------------------- ---- 24/27 [tensorflow]\n",
      "   ----------------------------------- ---- 24/27 [tensorflow]\n",
      "   ----------------------------------- ---- 24/27 [tensorflow]\n",
      "   ----------------------------------- ---- 24/27 [tensorflow]\n",
      "   ----------------------------------- ---- 24/27 [tensorflow]\n",
      "   ----------------------------------- ---- 24/27 [tensorflow]\n",
      "   ------------------------------------- -- 25/27 [tf-keras]\n",
      "   ------------------------------------- -- 25/27 [tf-keras]\n",
      "   ------------------------------------- -- 25/27 [tf-keras]\n",
      "   ------------------------------------- -- 25/27 [tf-keras]\n",
      "   ------------------------------------- -- 25/27 [tf-keras]\n",
      "   ------------------------------------- -- 25/27 [tf-keras]\n",
      "   ------------------------------------- -- 25/27 [tf-keras]\n",
      "   ------------------------------------- -- 25/27 [tf-keras]\n",
      "   ------------------------------------- -- 25/27 [tf-keras]\n",
      "   ------------------------------------- -- 25/27 [tf-keras]\n",
      "   ------------------------------------- -- 25/27 [tf-keras]\n",
      "   ------------------------------------- -- 25/27 [tf-keras]\n",
      "   ------------------------------------- -- 25/27 [tf-keras]\n",
      "   ------------------------------------- -- 25/27 [tf-keras]\n",
      "   ------------------------------------- -- 25/27 [tf-keras]\n",
      "   ------------------------------------- -- 25/27 [tf-keras]\n",
      "   ------------------------------------- -- 25/27 [tf-keras]\n",
      "   ------------------------------------- -- 25/27 [tf-keras]\n",
      "   ------------------------------------- -- 25/27 [tf-keras]\n",
      "   ------------------------------------- -- 25/27 [tf-keras]\n",
      "   ------------------------------------- -- 25/27 [tf-keras]\n",
      "   ------------------------------------- -- 25/27 [tf-keras]\n",
      "   ------------------------------------- -- 25/27 [tf-keras]\n",
      "   ------------------------------------- -- 25/27 [tf-keras]\n",
      "   ------------------------------------- -- 25/27 [tf-keras]\n",
      "   ------------------------------------- -- 25/27 [tf-keras]\n",
      "   ------------------------------------- -- 25/27 [tf-keras]\n",
      "   ------------------------------------- -- 25/27 [tf-keras]\n",
      "   ------------------------------------- -- 25/27 [tf-keras]\n",
      "   -------------------------------------- - 26/27 [tensorflow-hub]\n",
      "   ---------------------------------------- 27/27 [tensorflow-hub]\n",
      "\n",
      "Successfully installed absl-py-2.3.0 astunparse-1.6.3 flatbuffers-25.2.10 gast-0.6.0 google-pasta-0.2.0 grpcio-1.73.1 h5py-3.14.0 keras-3.10.0 libclang-18.1.1 markdown-3.8.2 markdown-it-py-3.0.0 mdurl-0.1.2 ml-dtypes-0.5.1 namex-0.1.0 opt-einsum-3.4.0 optree-0.16.0 protobuf-5.29.5 rich-14.0.0 tensorboard-2.19.0 tensorboard-data-server-0.7.2 tensorflow-2.19.0 tensorflow-hub-0.16.1 tensorflow-io-gcs-filesystem-0.31.0 termcolor-3.1.0 tf-keras-2.19.0 werkzeug-3.1.3 wrapt-1.17.2\n",
      "Collecting tensorflow-text\n",
      "  Downloading tensorflow_text-2.10.0-cp39-cp39-win_amd64.whl.metadata (2.1 kB)\n",
      "Requirement already satisfied: tensorflow-hub>=0.8.0 in c:\\users\\yann\\anaconda3\\envs\\nlp_gpu_env\\lib\\site-packages (from tensorflow-text) (0.16.1)\n",
      "Collecting tensorflow<2.11,>=2.10.0 (from tensorflow-text)\n",
      "  Downloading tensorflow-2.10.1-cp39-cp39-win_amd64.whl.metadata (3.1 kB)\n",
      "Requirement already satisfied: absl-py>=1.0.0 in c:\\users\\yann\\anaconda3\\envs\\nlp_gpu_env\\lib\\site-packages (from tensorflow<2.11,>=2.10.0->tensorflow-text) (2.3.0)\n",
      "Requirement already satisfied: astunparse>=1.6.0 in c:\\users\\yann\\anaconda3\\envs\\nlp_gpu_env\\lib\\site-packages (from tensorflow<2.11,>=2.10.0->tensorflow-text) (1.6.3)\n",
      "Requirement already satisfied: flatbuffers>=2.0 in c:\\users\\yann\\anaconda3\\envs\\nlp_gpu_env\\lib\\site-packages (from tensorflow<2.11,>=2.10.0->tensorflow-text) (25.2.10)\n",
      "Collecting gast<=0.4.0,>=0.2.1 (from tensorflow<2.11,>=2.10.0->tensorflow-text)\n",
      "  Downloading gast-0.4.0-py3-none-any.whl.metadata (1.1 kB)\n",
      "Requirement already satisfied: google-pasta>=0.1.1 in c:\\users\\yann\\anaconda3\\envs\\nlp_gpu_env\\lib\\site-packages (from tensorflow<2.11,>=2.10.0->tensorflow-text) (0.2.0)\n",
      "Requirement already satisfied: h5py>=2.9.0 in c:\\users\\yann\\anaconda3\\envs\\nlp_gpu_env\\lib\\site-packages (from tensorflow<2.11,>=2.10.0->tensorflow-text) (3.14.0)\n",
      "Collecting keras-preprocessing>=1.1.1 (from tensorflow<2.11,>=2.10.0->tensorflow-text)\n",
      "  Downloading Keras_Preprocessing-1.1.2-py2.py3-none-any.whl.metadata (1.9 kB)\n",
      "Requirement already satisfied: libclang>=13.0.0 in c:\\users\\yann\\anaconda3\\envs\\nlp_gpu_env\\lib\\site-packages (from tensorflow<2.11,>=2.10.0->tensorflow-text) (18.1.1)\n",
      "Requirement already satisfied: numpy>=1.20 in c:\\users\\yann\\anaconda3\\envs\\nlp_gpu_env\\lib\\site-packages (from tensorflow<2.11,>=2.10.0->tensorflow-text) (2.0.2)\n",
      "Requirement already satisfied: opt-einsum>=2.3.2 in c:\\users\\yann\\anaconda3\\envs\\nlp_gpu_env\\lib\\site-packages (from tensorflow<2.11,>=2.10.0->tensorflow-text) (3.4.0)\n",
      "Requirement already satisfied: packaging in c:\\users\\yann\\anaconda3\\envs\\nlp_gpu_env\\lib\\site-packages (from tensorflow<2.11,>=2.10.0->tensorflow-text) (25.0)\n",
      "Collecting protobuf<3.20,>=3.9.2 (from tensorflow<2.11,>=2.10.0->tensorflow-text)\n",
      "  Downloading protobuf-3.19.6-cp39-cp39-win_amd64.whl.metadata (807 bytes)\n",
      "Requirement already satisfied: setuptools in c:\\users\\yann\\anaconda3\\envs\\nlp_gpu_env\\lib\\site-packages (from tensorflow<2.11,>=2.10.0->tensorflow-text) (78.1.1)\n",
      "Requirement already satisfied: six>=1.12.0 in c:\\users\\yann\\anaconda3\\envs\\nlp_gpu_env\\lib\\site-packages (from tensorflow<2.11,>=2.10.0->tensorflow-text) (1.17.0)\n",
      "Requirement already satisfied: termcolor>=1.1.0 in c:\\users\\yann\\anaconda3\\envs\\nlp_gpu_env\\lib\\site-packages (from tensorflow<2.11,>=2.10.0->tensorflow-text) (3.1.0)\n",
      "Requirement already satisfied: typing-extensions>=3.6.6 in c:\\users\\yann\\anaconda3\\envs\\nlp_gpu_env\\lib\\site-packages (from tensorflow<2.11,>=2.10.0->tensorflow-text) (4.14.0)\n",
      "Requirement already satisfied: wrapt>=1.11.0 in c:\\users\\yann\\anaconda3\\envs\\nlp_gpu_env\\lib\\site-packages (from tensorflow<2.11,>=2.10.0->tensorflow-text) (1.17.2)\n",
      "Requirement already satisfied: tensorflow-io-gcs-filesystem>=0.23.1 in c:\\users\\yann\\anaconda3\\envs\\nlp_gpu_env\\lib\\site-packages (from tensorflow<2.11,>=2.10.0->tensorflow-text) (0.31.0)\n",
      "Requirement already satisfied: grpcio<2.0,>=1.24.3 in c:\\users\\yann\\anaconda3\\envs\\nlp_gpu_env\\lib\\site-packages (from tensorflow<2.11,>=2.10.0->tensorflow-text) (1.73.1)\n",
      "Collecting tensorboard<2.11,>=2.10 (from tensorflow<2.11,>=2.10.0->tensorflow-text)\n",
      "  Downloading tensorboard-2.10.1-py3-none-any.whl.metadata (1.9 kB)\n",
      "Collecting tensorflow-estimator<2.11,>=2.10.0 (from tensorflow<2.11,>=2.10.0->tensorflow-text)\n",
      "  Downloading tensorflow_estimator-2.10.0-py2.py3-none-any.whl.metadata (1.3 kB)\n",
      "Collecting keras<2.11,>=2.10.0 (from tensorflow<2.11,>=2.10.0->tensorflow-text)\n",
      "  Downloading keras-2.10.0-py2.py3-none-any.whl.metadata (1.3 kB)\n",
      "Collecting google-auth<3,>=1.6.3 (from tensorboard<2.11,>=2.10->tensorflow<2.11,>=2.10.0->tensorflow-text)\n",
      "  Downloading google_auth-2.40.3-py2.py3-none-any.whl.metadata (6.2 kB)\n",
      "Collecting google-auth-oauthlib<0.5,>=0.4.1 (from tensorboard<2.11,>=2.10->tensorflow<2.11,>=2.10.0->tensorflow-text)\n",
      "  Downloading google_auth_oauthlib-0.4.6-py2.py3-none-any.whl.metadata (2.7 kB)\n",
      "Requirement already satisfied: markdown>=2.6.8 in c:\\users\\yann\\anaconda3\\envs\\nlp_gpu_env\\lib\\site-packages (from tensorboard<2.11,>=2.10->tensorflow<2.11,>=2.10.0->tensorflow-text) (3.8.2)\n",
      "Requirement already satisfied: requests<3,>=2.21.0 in c:\\users\\yann\\anaconda3\\envs\\nlp_gpu_env\\lib\\site-packages (from tensorboard<2.11,>=2.10->tensorflow<2.11,>=2.10.0->tensorflow-text) (2.32.4)\n",
      "Collecting tensorboard-data-server<0.7.0,>=0.6.0 (from tensorboard<2.11,>=2.10->tensorflow<2.11,>=2.10.0->tensorflow-text)\n",
      "  Downloading tensorboard_data_server-0.6.1-py3-none-any.whl.metadata (1.1 kB)\n",
      "Collecting tensorboard-plugin-wit>=1.6.0 (from tensorboard<2.11,>=2.10->tensorflow<2.11,>=2.10.0->tensorflow-text)\n",
      "  Downloading tensorboard_plugin_wit-1.8.1-py3-none-any.whl.metadata (873 bytes)\n",
      "Requirement already satisfied: werkzeug>=1.0.1 in c:\\users\\yann\\anaconda3\\envs\\nlp_gpu_env\\lib\\site-packages (from tensorboard<2.11,>=2.10->tensorflow<2.11,>=2.10.0->tensorflow-text) (3.1.3)\n",
      "Requirement already satisfied: wheel>=0.26 in c:\\users\\yann\\anaconda3\\envs\\nlp_gpu_env\\lib\\site-packages (from tensorboard<2.11,>=2.10->tensorflow<2.11,>=2.10.0->tensorflow-text) (0.45.1)\n",
      "Collecting cachetools<6.0,>=2.0.0 (from google-auth<3,>=1.6.3->tensorboard<2.11,>=2.10->tensorflow<2.11,>=2.10.0->tensorflow-text)\n",
      "  Downloading cachetools-5.5.2-py3-none-any.whl.metadata (5.4 kB)\n",
      "Collecting pyasn1-modules>=0.2.1 (from google-auth<3,>=1.6.3->tensorboard<2.11,>=2.10->tensorflow<2.11,>=2.10.0->tensorflow-text)\n",
      "  Downloading pyasn1_modules-0.4.2-py3-none-any.whl.metadata (3.5 kB)\n",
      "Collecting rsa<5,>=3.1.4 (from google-auth<3,>=1.6.3->tensorboard<2.11,>=2.10->tensorflow<2.11,>=2.10.0->tensorflow-text)\n",
      "  Downloading rsa-4.9.1-py3-none-any.whl.metadata (5.6 kB)\n",
      "Collecting requests-oauthlib>=0.7.0 (from google-auth-oauthlib<0.5,>=0.4.1->tensorboard<2.11,>=2.10->tensorflow<2.11,>=2.10.0->tensorflow-text)\n",
      "  Downloading requests_oauthlib-2.0.0-py2.py3-none-any.whl.metadata (11 kB)\n",
      "Requirement already satisfied: charset_normalizer<4,>=2 in c:\\users\\yann\\anaconda3\\envs\\nlp_gpu_env\\lib\\site-packages (from requests<3,>=2.21.0->tensorboard<2.11,>=2.10->tensorflow<2.11,>=2.10.0->tensorflow-text) (3.4.2)\n",
      "Requirement already satisfied: idna<4,>=2.5 in c:\\users\\yann\\anaconda3\\envs\\nlp_gpu_env\\lib\\site-packages (from requests<3,>=2.21.0->tensorboard<2.11,>=2.10->tensorflow<2.11,>=2.10.0->tensorflow-text) (3.10)\n",
      "Requirement already satisfied: urllib3<3,>=1.21.1 in c:\\users\\yann\\anaconda3\\envs\\nlp_gpu_env\\lib\\site-packages (from requests<3,>=2.21.0->tensorboard<2.11,>=2.10->tensorflow<2.11,>=2.10.0->tensorflow-text) (2.5.0)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in c:\\users\\yann\\anaconda3\\envs\\nlp_gpu_env\\lib\\site-packages (from requests<3,>=2.21.0->tensorboard<2.11,>=2.10->tensorflow<2.11,>=2.10.0->tensorflow-text) (2025.6.15)\n",
      "Collecting pyasn1>=0.1.3 (from rsa<5,>=3.1.4->google-auth<3,>=1.6.3->tensorboard<2.11,>=2.10->tensorflow<2.11,>=2.10.0->tensorflow-text)\n",
      "  Downloading pyasn1-0.6.1-py3-none-any.whl.metadata (8.4 kB)\n",
      "Requirement already satisfied: importlib-metadata>=4.4 in c:\\users\\yann\\anaconda3\\envs\\nlp_gpu_env\\lib\\site-packages (from markdown>=2.6.8->tensorboard<2.11,>=2.10->tensorflow<2.11,>=2.10.0->tensorflow-text) (8.7.0)\n",
      "Requirement already satisfied: zipp>=3.20 in c:\\users\\yann\\anaconda3\\envs\\nlp_gpu_env\\lib\\site-packages (from importlib-metadata>=4.4->markdown>=2.6.8->tensorboard<2.11,>=2.10->tensorflow<2.11,>=2.10.0->tensorflow-text) (3.23.0)\n",
      "Collecting oauthlib>=3.0.0 (from requests-oauthlib>=0.7.0->google-auth-oauthlib<0.5,>=0.4.1->tensorboard<2.11,>=2.10->tensorflow<2.11,>=2.10.0->tensorflow-text)\n",
      "  Downloading oauthlib-3.3.1-py3-none-any.whl.metadata (7.9 kB)\n",
      "Requirement already satisfied: tf-keras>=2.14.1 in c:\\users\\yann\\anaconda3\\envs\\nlp_gpu_env\\lib\\site-packages (from tensorflow-hub>=0.8.0->tensorflow-text) (2.19.0)\n",
      "INFO: pip is looking at multiple versions of tf-keras to determine which version is compatible with other requirements. This could take a while.\n",
      "Collecting tf-keras>=2.14.1 (from tensorflow-hub>=0.8.0->tensorflow-text)\n",
      "  Using cached tf_keras-2.18.0-py3-none-any.whl.metadata (1.6 kB)\n",
      "  Using cached tf_keras-2.17.0-py3-none-any.whl.metadata (1.6 kB)\n",
      "  Using cached tf_keras-2.16.0-py3-none-any.whl.metadata (1.6 kB)\n",
      "  Using cached tf_keras-2.15.1-py3-none-any.whl.metadata (1.7 kB)\n",
      "  Using cached tf_keras-2.15.0-py3-none-any.whl.metadata (1.6 kB)\n",
      "Requirement already satisfied: MarkupSafe>=2.1.1 in c:\\users\\yann\\anaconda3\\envs\\nlp_gpu_env\\lib\\site-packages (from werkzeug>=1.0.1->tensorboard<2.11,>=2.10->tensorflow<2.11,>=2.10.0->tensorflow-text) (2.1.5)\n",
      "Downloading tensorflow_text-2.10.0-cp39-cp39-win_amd64.whl (5.0 MB)\n",
      "   ---------------------------------------- 0.0/5.0 MB ? eta -:--:--\n",
      "   -- ------------------------------------- 0.3/5.0 MB ? eta -:--:--\n",
      "   -------- ------------------------------- 1.0/5.0 MB 3.3 MB/s eta 0:00:02\n",
      "   ---------------- ----------------------- 2.1/5.0 MB 3.9 MB/s eta 0:00:01\n",
      "   ------------------------- -------------- 3.1/5.0 MB 4.2 MB/s eta 0:00:01\n",
      "   --------------------------------- ------ 4.2/5.0 MB 4.5 MB/s eta 0:00:01\n",
      "   ---------------------------------------  5.0/5.0 MB 4.8 MB/s eta 0:00:01\n",
      "   ---------------------------------------- 5.0/5.0 MB 4.2 MB/s eta 0:00:00\n",
      "Downloading tensorflow-2.10.1-cp39-cp39-win_amd64.whl (455.9 MB)\n",
      "   ---------------------------------------- 0.0/455.9 MB ? eta -:--:--\n",
      "   ---------------------------------------- 1.3/455.9 MB 6.7 MB/s eta 0:01:08\n",
      "   ---------------------------------------- 2.9/455.9 MB 6.7 MB/s eta 0:01:08\n",
      "   ---------------------------------------- 4.2/455.9 MB 6.8 MB/s eta 0:01:07\n",
      "    --------------------------------------- 5.8/455.9 MB 6.8 MB/s eta 0:01:07\n",
      "    --------------------------------------- 7.3/455.9 MB 6.9 MB/s eta 0:01:06\n",
      "    --------------------------------------- 8.7/455.9 MB 6.9 MB/s eta 0:01:05\n",
      "    --------------------------------------- 10.2/455.9 MB 6.9 MB/s eta 0:01:05\n",
      "   - -------------------------------------- 11.8/455.9 MB 6.9 MB/s eta 0:01:05\n",
      "   - -------------------------------------- 13.1/455.9 MB 6.9 MB/s eta 0:01:05\n",
      "   - -------------------------------------- 14.7/455.9 MB 6.8 MB/s eta 0:01:05\n",
      "   - -------------------------------------- 16.0/455.9 MB 6.8 MB/s eta 0:01:05\n",
      "   - -------------------------------------- 17.6/455.9 MB 6.8 MB/s eta 0:01:05\n",
      "   - -------------------------------------- 18.9/455.9 MB 6.8 MB/s eta 0:01:05\n",
      "   - -------------------------------------- 20.4/455.9 MB 6.8 MB/s eta 0:01:05\n",
      "   - -------------------------------------- 21.8/455.9 MB 6.8 MB/s eta 0:01:04\n",
      "   -- ------------------------------------- 23.3/455.9 MB 6.8 MB/s eta 0:01:04\n",
      "   -- ------------------------------------- 24.9/455.9 MB 6.8 MB/s eta 0:01:04\n",
      "   -- ------------------------------------- 26.2/455.9 MB 6.8 MB/s eta 0:01:03\n",
      "   -- ------------------------------------- 27.8/455.9 MB 6.9 MB/s eta 0:01:03\n",
      "   -- ------------------------------------- 29.1/455.9 MB 6.8 MB/s eta 0:01:03\n",
      "   -- ------------------------------------- 30.7/455.9 MB 6.8 MB/s eta 0:01:03\n",
      "   -- ------------------------------------- 32.0/455.9 MB 6.8 MB/s eta 0:01:03\n",
      "   -- ------------------------------------- 33.6/455.9 MB 6.8 MB/s eta 0:01:02\n",
      "   --- ------------------------------------ 35.1/455.9 MB 6.8 MB/s eta 0:01:02\n",
      "   --- ------------------------------------ 36.4/455.9 MB 6.8 MB/s eta 0:01:02\n",
      "   --- ------------------------------------ 38.0/455.9 MB 6.8 MB/s eta 0:01:02\n",
      "   --- ------------------------------------ 39.6/455.9 MB 6.9 MB/s eta 0:01:01\n",
      "   --- ------------------------------------ 40.9/455.9 MB 6.8 MB/s eta 0:01:01\n",
      "   --- ------------------------------------ 42.2/455.9 MB 6.8 MB/s eta 0:01:01\n",
      "   --- ------------------------------------ 43.5/455.9 MB 6.8 MB/s eta 0:01:01\n",
      "   --- ------------------------------------ 44.8/455.9 MB 6.8 MB/s eta 0:01:01\n",
      "   ---- ----------------------------------- 46.4/455.9 MB 6.8 MB/s eta 0:01:01\n",
      "   ---- ----------------------------------- 47.7/455.9 MB 6.8 MB/s eta 0:01:01\n",
      "   ---- ----------------------------------- 49.3/455.9 MB 6.8 MB/s eta 0:01:00\n",
      "   ---- ----------------------------------- 50.6/455.9 MB 6.8 MB/s eta 0:01:00\n",
      "   ---- ----------------------------------- 51.9/455.9 MB 6.8 MB/s eta 0:01:00\n",
      "   ---- ----------------------------------- 53.5/455.9 MB 6.8 MB/s eta 0:01:00\n",
      "   ---- ----------------------------------- 54.8/455.9 MB 6.8 MB/s eta 0:01:00\n",
      "   ---- ----------------------------------- 56.4/455.9 MB 6.8 MB/s eta 0:01:00\n",
      "   ----- ---------------------------------- 57.7/455.9 MB 6.8 MB/s eta 0:00:59\n",
      "   ----- ---------------------------------- 59.2/455.9 MB 6.8 MB/s eta 0:00:59\n",
      "   ----- ---------------------------------- 60.6/455.9 MB 6.8 MB/s eta 0:00:59\n",
      "   ----- ---------------------------------- 62.1/455.9 MB 6.8 MB/s eta 0:00:59\n",
      "   ----- ---------------------------------- 63.4/455.9 MB 6.8 MB/s eta 0:00:58\n",
      "   ----- ---------------------------------- 65.0/455.9 MB 6.8 MB/s eta 0:00:58\n",
      "   ----- ---------------------------------- 66.6/455.9 MB 6.8 MB/s eta 0:00:58\n",
      "   ----- ---------------------------------- 67.9/455.9 MB 6.8 MB/s eta 0:00:58\n",
      "   ------ --------------------------------- 69.5/455.9 MB 6.8 MB/s eta 0:00:57\n",
      "   ------ --------------------------------- 70.8/455.9 MB 6.8 MB/s eta 0:00:57\n",
      "   ------ --------------------------------- 72.4/455.9 MB 6.8 MB/s eta 0:00:57\n",
      "   ------ --------------------------------- 73.4/455.9 MB 6.7 MB/s eta 0:00:57\n",
      "   ------ --------------------------------- 75.0/455.9 MB 6.8 MB/s eta 0:00:57\n",
      "   ------ --------------------------------- 76.5/455.9 MB 6.8 MB/s eta 0:00:57\n",
      "   ------ --------------------------------- 77.9/455.9 MB 6.8 MB/s eta 0:00:56\n",
      "   ------ --------------------------------- 79.4/455.9 MB 6.8 MB/s eta 0:00:56\n",
      "   ------- -------------------------------- 80.7/455.9 MB 6.8 MB/s eta 0:00:56\n",
      "   ------- -------------------------------- 82.3/455.9 MB 6.8 MB/s eta 0:00:56\n",
      "   ------- -------------------------------- 83.9/455.9 MB 6.8 MB/s eta 0:00:55\n",
      "   ------- -------------------------------- 85.2/455.9 MB 6.8 MB/s eta 0:00:55\n",
      "   ------- -------------------------------- 86.8/455.9 MB 6.8 MB/s eta 0:00:55\n",
      "   ------- -------------------------------- 88.3/455.9 MB 6.8 MB/s eta 0:00:55\n",
      "   ------- -------------------------------- 89.7/455.9 MB 6.8 MB/s eta 0:00:55\n",
      "   -------- ------------------------------- 91.2/455.9 MB 6.8 MB/s eta 0:00:54\n",
      "   -------- ------------------------------- 92.5/455.9 MB 6.8 MB/s eta 0:00:54\n",
      "   -------- ------------------------------- 94.1/455.9 MB 6.8 MB/s eta 0:00:54\n",
      "   -------- ------------------------------- 95.7/455.9 MB 6.8 MB/s eta 0:00:54\n",
      "   -------- ------------------------------- 97.0/455.9 MB 6.8 MB/s eta 0:00:53\n",
      "   -------- ------------------------------- 98.6/455.9 MB 6.8 MB/s eta 0:00:53\n",
      "   -------- ------------------------------- 100.1/455.9 MB 6.8 MB/s eta 0:00:53\n",
      "   -------- ------------------------------- 101.7/455.9 MB 6.8 MB/s eta 0:00:53\n",
      "   --------- ------------------------------ 103.0/455.9 MB 6.8 MB/s eta 0:00:52\n",
      "   --------- ------------------------------ 104.6/455.9 MB 6.8 MB/s eta 0:00:52\n",
      "   --------- ------------------------------ 105.9/455.9 MB 6.8 MB/s eta 0:00:52\n",
      "   --------- ------------------------------ 107.5/455.9 MB 6.8 MB/s eta 0:00:52\n",
      "   --------- ------------------------------ 109.1/455.9 MB 6.8 MB/s eta 0:00:52\n",
      "   --------- ------------------------------ 110.4/455.9 MB 6.8 MB/s eta 0:00:51\n",
      "   --------- ------------------------------ 111.9/455.9 MB 6.8 MB/s eta 0:00:51\n",
      "   --------- ------------------------------ 113.5/455.9 MB 6.8 MB/s eta 0:00:51\n",
      "   ---------- ----------------------------- 114.8/455.9 MB 6.8 MB/s eta 0:00:51\n",
      "   ---------- ----------------------------- 116.4/455.9 MB 6.8 MB/s eta 0:00:50\n",
      "   ---------- ----------------------------- 118.0/455.9 MB 6.8 MB/s eta 0:00:50\n",
      "   ---------- ----------------------------- 119.3/455.9 MB 6.8 MB/s eta 0:00:50\n",
      "   ---------- ----------------------------- 120.8/455.9 MB 6.8 MB/s eta 0:00:50\n",
      "   ---------- ----------------------------- 122.4/455.9 MB 6.8 MB/s eta 0:00:49\n",
      "   ---------- ----------------------------- 123.7/455.9 MB 6.8 MB/s eta 0:00:49\n",
      "   ---------- ----------------------------- 125.3/455.9 MB 6.8 MB/s eta 0:00:49\n",
      "   ----------- ---------------------------- 126.6/455.9 MB 6.8 MB/s eta 0:00:49\n",
      "   ----------- ---------------------------- 128.2/455.9 MB 6.8 MB/s eta 0:00:49\n",
      "   ----------- ---------------------------- 129.5/455.9 MB 6.8 MB/s eta 0:00:48\n",
      "   ----------- ---------------------------- 131.1/455.9 MB 6.8 MB/s eta 0:00:48\n",
      "   ----------- ---------------------------- 132.6/455.9 MB 6.8 MB/s eta 0:00:48\n",
      "   ----------- ---------------------------- 134.0/455.9 MB 6.8 MB/s eta 0:00:48\n",
      "   ----------- ---------------------------- 135.5/455.9 MB 6.8 MB/s eta 0:00:47\n",
      "   ------------ --------------------------- 137.1/455.9 MB 6.8 MB/s eta 0:00:47\n",
      "   ------------ --------------------------- 138.7/455.9 MB 6.8 MB/s eta 0:00:47\n",
      "   ------------ --------------------------- 140.0/455.9 MB 6.8 MB/s eta 0:00:47\n",
      "   ------------ --------------------------- 141.6/455.9 MB 6.8 MB/s eta 0:00:47\n",
      "   ------------ --------------------------- 142.9/455.9 MB 6.8 MB/s eta 0:00:46\n",
      "   ------------ --------------------------- 144.4/455.9 MB 6.8 MB/s eta 0:00:46\n",
      "   ------------ --------------------------- 145.8/455.9 MB 6.8 MB/s eta 0:00:46\n",
      "   ------------ --------------------------- 147.3/455.9 MB 6.8 MB/s eta 0:00:46\n",
      "   ------------- -------------------------- 148.9/455.9 MB 6.8 MB/s eta 0:00:45\n",
      "   ------------- -------------------------- 150.2/455.9 MB 6.8 MB/s eta 0:00:45\n",
      "   ------------- -------------------------- 151.8/455.9 MB 6.8 MB/s eta 0:00:45\n",
      "   ------------- -------------------------- 153.4/455.9 MB 6.8 MB/s eta 0:00:45\n",
      "   ------------- -------------------------- 154.7/455.9 MB 6.8 MB/s eta 0:00:45\n",
      "   ------------- -------------------------- 156.2/455.9 MB 6.8 MB/s eta 0:00:44\n",
      "   ------------- -------------------------- 157.5/455.9 MB 6.8 MB/s eta 0:00:44\n",
      "   ------------- -------------------------- 159.1/455.9 MB 6.8 MB/s eta 0:00:44\n",
      "   -------------- ------------------------- 160.4/455.9 MB 6.8 MB/s eta 0:00:44\n",
      "   -------------- ------------------------- 162.0/455.9 MB 6.8 MB/s eta 0:00:44\n",
      "   -------------- ------------------------- 163.3/455.9 MB 6.8 MB/s eta 0:00:43\n",
      "   -------------- ------------------------- 164.9/455.9 MB 6.8 MB/s eta 0:00:43\n",
      "   -------------- ------------------------- 166.5/455.9 MB 6.8 MB/s eta 0:00:43\n",
      "   -------------- ------------------------- 167.8/455.9 MB 6.8 MB/s eta 0:00:43\n",
      "   -------------- ------------------------- 169.3/455.9 MB 6.8 MB/s eta 0:00:42\n",
      "   -------------- ------------------------- 170.7/455.9 MB 6.8 MB/s eta 0:00:42\n",
      "   --------------- ------------------------ 172.2/455.9 MB 6.8 MB/s eta 0:00:42\n",
      "   --------------- ------------------------ 173.8/455.9 MB 6.8 MB/s eta 0:00:42\n",
      "   --------------- ------------------------ 175.1/455.9 MB 6.8 MB/s eta 0:00:42\n",
      "   --------------- ------------------------ 176.7/455.9 MB 6.8 MB/s eta 0:00:41\n",
      "   --------------- ------------------------ 178.0/455.9 MB 6.8 MB/s eta 0:00:41\n",
      "   --------------- ------------------------ 179.6/455.9 MB 6.8 MB/s eta 0:00:41\n",
      "   --------------- ------------------------ 180.9/455.9 MB 6.8 MB/s eta 0:00:41\n",
      "   ---------------- ----------------------- 182.5/455.9 MB 6.8 MB/s eta 0:00:41\n",
      "   ---------------- ----------------------- 184.0/455.9 MB 6.8 MB/s eta 0:00:40\n",
      "   ---------------- ----------------------- 185.3/455.9 MB 6.8 MB/s eta 0:00:40\n",
      "   ---------------- ----------------------- 186.9/455.9 MB 6.8 MB/s eta 0:00:40\n",
      "   ---------------- ----------------------- 188.2/455.9 MB 6.8 MB/s eta 0:00:40\n",
      "   ---------------- ----------------------- 189.8/455.9 MB 6.8 MB/s eta 0:00:39\n",
      "   ---------------- ----------------------- 191.4/455.9 MB 6.8 MB/s eta 0:00:39\n",
      "   ---------------- ----------------------- 192.7/455.9 MB 6.8 MB/s eta 0:00:39\n",
      "   ----------------- ---------------------- 194.2/455.9 MB 6.8 MB/s eta 0:00:39\n",
      "   ----------------- ---------------------- 195.8/455.9 MB 6.8 MB/s eta 0:00:39\n",
      "   ----------------- ---------------------- 197.1/455.9 MB 6.8 MB/s eta 0:00:38\n",
      "   ----------------- ---------------------- 198.4/455.9 MB 6.8 MB/s eta 0:00:38\n",
      "   ----------------- ---------------------- 199.8/455.9 MB 6.8 MB/s eta 0:00:38\n",
      "   ----------------- ---------------------- 201.3/455.9 MB 6.8 MB/s eta 0:00:38\n",
      "   ----------------- ---------------------- 202.6/455.9 MB 6.8 MB/s eta 0:00:38\n",
      "   ----------------- ---------------------- 204.2/455.9 MB 6.8 MB/s eta 0:00:37\n",
      "   ------------------ --------------------- 205.8/455.9 MB 6.8 MB/s eta 0:00:37\n",
      "   ------------------ --------------------- 207.1/455.9 MB 6.8 MB/s eta 0:00:37\n",
      "   ------------------ --------------------- 208.7/455.9 MB 6.8 MB/s eta 0:00:37\n",
      "   ------------------ --------------------- 210.2/455.9 MB 6.8 MB/s eta 0:00:36\n",
      "   ------------------ --------------------- 211.6/455.9 MB 6.8 MB/s eta 0:00:36\n",
      "   ------------------ --------------------- 213.1/455.9 MB 6.8 MB/s eta 0:00:36\n",
      "   ------------------ --------------------- 214.7/455.9 MB 6.8 MB/s eta 0:00:36\n",
      "   ------------------ --------------------- 216.0/455.9 MB 6.8 MB/s eta 0:00:36\n",
      "   ------------------- -------------------- 217.6/455.9 MB 6.8 MB/s eta 0:00:35\n",
      "   ------------------- -------------------- 219.2/455.9 MB 6.8 MB/s eta 0:00:35\n",
      "   ------------------- -------------------- 220.5/455.9 MB 6.8 MB/s eta 0:00:35\n",
      "   ------------------- -------------------- 222.0/455.9 MB 6.8 MB/s eta 0:00:35\n",
      "   ------------------- -------------------- 223.6/455.9 MB 6.8 MB/s eta 0:00:34\n",
      "   ------------------- -------------------- 224.9/455.9 MB 6.8 MB/s eta 0:00:34\n",
      "   ------------------- -------------------- 226.5/455.9 MB 6.8 MB/s eta 0:00:34\n",
      "   -------------------- ------------------- 228.1/455.9 MB 6.8 MB/s eta 0:00:34\n",
      "   -------------------- ------------------- 229.4/455.9 MB 6.8 MB/s eta 0:00:34\n",
      "   -------------------- ------------------- 230.9/455.9 MB 6.8 MB/s eta 0:00:33\n",
      "   -------------------- ------------------- 232.3/455.9 MB 6.8 MB/s eta 0:00:33\n",
      "   -------------------- ------------------- 233.8/455.9 MB 6.8 MB/s eta 0:00:33\n",
      "   -------------------- ------------------- 235.4/455.9 MB 6.8 MB/s eta 0:00:33\n",
      "   -------------------- ------------------- 236.7/455.9 MB 6.8 MB/s eta 0:00:33\n",
      "   -------------------- ------------------- 238.3/455.9 MB 6.8 MB/s eta 0:00:32\n",
      "   --------------------- ------------------ 239.9/455.9 MB 6.8 MB/s eta 0:00:32\n",
      "   --------------------- ------------------ 241.2/455.9 MB 6.8 MB/s eta 0:00:32\n",
      "   --------------------- ------------------ 242.7/455.9 MB 6.8 MB/s eta 0:00:32\n",
      "   --------------------- ------------------ 244.1/455.9 MB 6.8 MB/s eta 0:00:31\n",
      "   --------------------- ------------------ 245.6/455.9 MB 6.8 MB/s eta 0:00:31\n",
      "   --------------------- ------------------ 246.9/455.9 MB 6.8 MB/s eta 0:00:31\n",
      "   --------------------- ------------------ 248.5/455.9 MB 6.9 MB/s eta 0:00:31\n",
      "   --------------------- ------------------ 250.1/455.9 MB 6.9 MB/s eta 0:00:31\n",
      "   ---------------------- ----------------- 251.4/455.9 MB 6.9 MB/s eta 0:00:30\n",
      "   ---------------------- ----------------- 253.0/455.9 MB 6.9 MB/s eta 0:00:30\n",
      "   ---------------------- ----------------- 254.5/455.9 MB 6.9 MB/s eta 0:00:30\n",
      "   ---------------------- ----------------- 255.9/455.9 MB 6.9 MB/s eta 0:00:30\n",
      "   ---------------------- ----------------- 257.4/455.9 MB 6.9 MB/s eta 0:00:29\n",
      "   ---------------------- ----------------- 258.7/455.9 MB 6.9 MB/s eta 0:00:29\n",
      "   ---------------------- ----------------- 260.3/455.9 MB 6.9 MB/s eta 0:00:29\n",
      "   ---------------------- ----------------- 261.6/455.9 MB 6.9 MB/s eta 0:00:29\n",
      "   ----------------------- ---------------- 263.2/455.9 MB 6.9 MB/s eta 0:00:29\n",
      "   ----------------------- ---------------- 264.8/455.9 MB 6.9 MB/s eta 0:00:28\n",
      "   ----------------------- ---------------- 266.3/455.9 MB 6.9 MB/s eta 0:00:28\n",
      "   ----------------------- ---------------- 267.6/455.9 MB 6.9 MB/s eta 0:00:28\n",
      "   ----------------------- ---------------- 269.2/455.9 MB 6.9 MB/s eta 0:00:28\n",
      "   ----------------------- ---------------- 270.8/455.9 MB 6.9 MB/s eta 0:00:27\n",
      "   ----------------------- ---------------- 272.1/455.9 MB 6.9 MB/s eta 0:00:27\n",
      "   ------------------------ --------------- 273.7/455.9 MB 6.9 MB/s eta 0:00:27\n",
      "   ------------------------ --------------- 275.3/455.9 MB 6.9 MB/s eta 0:00:27\n",
      "   ------------------------ --------------- 276.6/455.9 MB 6.9 MB/s eta 0:00:27\n",
      "   ------------------------ --------------- 278.1/455.9 MB 6.9 MB/s eta 0:00:26\n",
      "   ------------------------ --------------- 279.7/455.9 MB 6.9 MB/s eta 0:00:26\n",
      "   ------------------------ --------------- 281.0/455.9 MB 6.9 MB/s eta 0:00:26\n",
      "   ------------------------ --------------- 282.6/455.9 MB 6.9 MB/s eta 0:00:26\n",
      "   ------------------------ --------------- 284.2/455.9 MB 6.9 MB/s eta 0:00:25\n",
      "   ------------------------- -------------- 285.5/455.9 MB 6.9 MB/s eta 0:00:25\n",
      "   ------------------------- -------------- 287.0/455.9 MB 6.9 MB/s eta 0:00:25\n",
      "   ------------------------- -------------- 288.4/455.9 MB 6.9 MB/s eta 0:00:25\n",
      "   ------------------------- -------------- 289.9/455.9 MB 6.9 MB/s eta 0:00:25\n",
      "   ------------------------- -------------- 291.5/455.9 MB 6.9 MB/s eta 0:00:24\n",
      "   ------------------------- -------------- 292.8/455.9 MB 6.9 MB/s eta 0:00:24\n",
      "   ------------------------- -------------- 294.4/455.9 MB 6.9 MB/s eta 0:00:24\n",
      "   ------------------------- -------------- 296.0/455.9 MB 6.9 MB/s eta 0:00:24\n",
      "   -------------------------- ------------- 297.3/455.9 MB 6.9 MB/s eta 0:00:24\n",
      "   -------------------------- ------------- 298.8/455.9 MB 6.9 MB/s eta 0:00:23\n",
      "   -------------------------- ------------- 300.4/455.9 MB 6.9 MB/s eta 0:00:23\n",
      "   -------------------------- ------------- 301.7/455.9 MB 6.9 MB/s eta 0:00:23\n",
      "   -------------------------- ------------- 303.3/455.9 MB 6.9 MB/s eta 0:00:23\n",
      "   -------------------------- ------------- 304.9/455.9 MB 6.9 MB/s eta 0:00:22\n",
      "   -------------------------- ------------- 306.2/455.9 MB 6.9 MB/s eta 0:00:22\n",
      "   --------------------------- ------------ 307.8/455.9 MB 6.9 MB/s eta 0:00:22\n",
      "   --------------------------- ------------ 309.3/455.9 MB 6.9 MB/s eta 0:00:22\n",
      "   --------------------------- ------------ 310.6/455.9 MB 6.9 MB/s eta 0:00:22\n",
      "   --------------------------- ------------ 312.2/455.9 MB 6.9 MB/s eta 0:00:21\n",
      "   --------------------------- ------------ 313.8/455.9 MB 6.9 MB/s eta 0:00:21\n",
      "   --------------------------- ------------ 315.1/455.9 MB 6.9 MB/s eta 0:00:21\n",
      "   --------------------------- ------------ 316.7/455.9 MB 6.9 MB/s eta 0:00:21\n",
      "   --------------------------- ------------ 318.2/455.9 MB 6.9 MB/s eta 0:00:20\n",
      "   ---------------------------- ----------- 319.6/455.9 MB 6.9 MB/s eta 0:00:20\n",
      "   ---------------------------- ----------- 321.1/455.9 MB 6.9 MB/s eta 0:00:20\n",
      "   ---------------------------- ----------- 322.7/455.9 MB 6.9 MB/s eta 0:00:20\n",
      "   ---------------------------- ----------- 324.0/455.9 MB 6.9 MB/s eta 0:00:20\n",
      "   ---------------------------- ----------- 325.6/455.9 MB 6.9 MB/s eta 0:00:19\n",
      "   ---------------------------- ----------- 327.2/455.9 MB 6.9 MB/s eta 0:00:19\n",
      "   ---------------------------- ----------- 328.5/455.9 MB 6.9 MB/s eta 0:00:19\n",
      "   ---------------------------- ----------- 330.0/455.9 MB 6.9 MB/s eta 0:00:19\n",
      "   ----------------------------- ---------- 331.6/455.9 MB 6.9 MB/s eta 0:00:19\n",
      "   ----------------------------- ---------- 333.2/455.9 MB 6.9 MB/s eta 0:00:18\n",
      "   ----------------------------- ---------- 334.5/455.9 MB 6.9 MB/s eta 0:00:18\n",
      "   ----------------------------- ---------- 336.1/455.9 MB 6.9 MB/s eta 0:00:18\n",
      "   ----------------------------- ---------- 337.6/455.9 MB 6.9 MB/s eta 0:00:18\n",
      "   ----------------------------- ---------- 339.0/455.9 MB 6.9 MB/s eta 0:00:17\n",
      "   ----------------------------- ---------- 340.5/455.9 MB 6.9 MB/s eta 0:00:17\n",
      "   ------------------------------ --------- 342.1/455.9 MB 6.9 MB/s eta 0:00:17\n",
      "   ------------------------------ --------- 343.4/455.9 MB 6.9 MB/s eta 0:00:17\n",
      "   ------------------------------ --------- 345.0/455.9 MB 6.9 MB/s eta 0:00:17\n",
      "   ------------------------------ --------- 346.3/455.9 MB 6.9 MB/s eta 0:00:16\n",
      "   ------------------------------ --------- 347.9/455.9 MB 6.9 MB/s eta 0:00:16\n",
      "   ------------------------------ --------- 349.4/455.9 MB 6.9 MB/s eta 0:00:16\n",
      "   ------------------------------ --------- 350.7/455.9 MB 6.9 MB/s eta 0:00:16\n",
      "   ------------------------------ --------- 352.3/455.9 MB 6.9 MB/s eta 0:00:16\n",
      "   ------------------------------- -------- 353.9/455.9 MB 6.9 MB/s eta 0:00:15\n",
      "   ------------------------------- -------- 355.2/455.9 MB 6.9 MB/s eta 0:00:15\n",
      "   ------------------------------- -------- 356.8/455.9 MB 6.9 MB/s eta 0:00:15\n",
      "   ------------------------------- -------- 358.4/455.9 MB 6.9 MB/s eta 0:00:15\n",
      "   ------------------------------- -------- 359.9/455.9 MB 6.9 MB/s eta 0:00:14\n",
      "   ------------------------------- -------- 361.5/455.9 MB 6.9 MB/s eta 0:00:14\n",
      "   ------------------------------- -------- 362.8/455.9 MB 6.9 MB/s eta 0:00:14\n",
      "   ------------------------------- -------- 364.4/455.9 MB 6.9 MB/s eta 0:00:14\n",
      "   -------------------------------- ------- 365.7/455.9 MB 6.9 MB/s eta 0:00:14\n",
      "   -------------------------------- ------- 367.3/455.9 MB 6.9 MB/s eta 0:00:13\n",
      "   -------------------------------- ------- 368.6/455.9 MB 6.9 MB/s eta 0:00:13\n",
      "   -------------------------------- ------- 370.1/455.9 MB 6.9 MB/s eta 0:00:13\n",
      "   -------------------------------- ------- 371.7/455.9 MB 6.9 MB/s eta 0:00:13\n",
      "   -------------------------------- ------- 373.0/455.9 MB 6.9 MB/s eta 0:00:13\n",
      "   -------------------------------- ------- 374.6/455.9 MB 6.9 MB/s eta 0:00:12\n",
      "   -------------------------------- ------- 375.9/455.9 MB 6.9 MB/s eta 0:00:12\n",
      "   --------------------------------- ------ 377.5/455.9 MB 6.9 MB/s eta 0:00:12\n",
      "   --------------------------------- ------ 379.1/455.9 MB 6.9 MB/s eta 0:00:12\n",
      "   --------------------------------- ------ 380.6/455.9 MB 6.9 MB/s eta 0:00:11\n",
      "   --------------------------------- ------ 381.9/455.9 MB 6.9 MB/s eta 0:00:11\n",
      "   --------------------------------- ------ 383.5/455.9 MB 6.9 MB/s eta 0:00:11\n",
      "   --------------------------------- ------ 385.1/455.9 MB 6.9 MB/s eta 0:00:11\n",
      "   --------------------------------- ------ 386.4/455.9 MB 6.9 MB/s eta 0:00:11\n",
      "   ---------------------------------- ----- 388.0/455.9 MB 6.9 MB/s eta 0:00:10\n",
      "   ---------------------------------- ----- 389.5/455.9 MB 6.9 MB/s eta 0:00:10\n",
      "   ---------------------------------- ----- 390.9/455.9 MB 6.9 MB/s eta 0:00:10\n",
      "   ---------------------------------- ----- 392.4/455.9 MB 6.9 MB/s eta 0:00:10\n",
      "   ---------------------------------- ----- 393.7/455.9 MB 6.9 MB/s eta 0:00:10\n",
      "   ---------------------------------- ----- 395.3/455.9 MB 6.9 MB/s eta 0:00:09\n",
      "   ---------------------------------- ----- 396.6/455.9 MB 6.9 MB/s eta 0:00:09\n",
      "   ---------------------------------- ----- 398.2/455.9 MB 6.9 MB/s eta 0:00:09\n",
      "   ----------------------------------- ---- 399.8/455.9 MB 6.9 MB/s eta 0:00:09\n",
      "   ----------------------------------- ---- 401.3/455.9 MB 6.9 MB/s eta 0:00:08\n",
      "   ----------------------------------- ---- 402.7/455.9 MB 6.9 MB/s eta 0:00:08\n",
      "   ----------------------------------- ---- 404.2/455.9 MB 6.9 MB/s eta 0:00:08\n",
      "   ----------------------------------- ---- 405.8/455.9 MB 6.9 MB/s eta 0:00:08\n",
      "   ----------------------------------- ---- 407.1/455.9 MB 6.9 MB/s eta 0:00:08\n",
      "   ----------------------------------- ---- 408.7/455.9 MB 6.9 MB/s eta 0:00:07\n",
      "   ----------------------------------- ---- 410.3/455.9 MB 6.9 MB/s eta 0:00:07\n",
      "   ------------------------------------ --- 411.8/455.9 MB 6.9 MB/s eta 0:00:07\n",
      "   ------------------------------------ --- 413.1/455.9 MB 6.9 MB/s eta 0:00:07\n",
      "   ------------------------------------ --- 414.2/455.9 MB 6.9 MB/s eta 0:00:07\n",
      "   ------------------------------------ --- 415.8/455.9 MB 6.9 MB/s eta 0:00:06\n",
      "   ------------------------------------ --- 417.3/455.9 MB 6.9 MB/s eta 0:00:06\n",
      "   ------------------------------------ --- 418.6/455.9 MB 6.9 MB/s eta 0:00:06\n",
      "   ------------------------------------ --- 420.2/455.9 MB 6.9 MB/s eta 0:00:06\n",
      "   ------------------------------------- -- 421.8/455.9 MB 6.9 MB/s eta 0:00:05\n",
      "   ------------------------------------- -- 423.4/455.9 MB 6.9 MB/s eta 0:00:05\n",
      "   ------------------------------------- -- 424.7/455.9 MB 6.9 MB/s eta 0:00:05\n",
      "   ------------------------------------- -- 426.0/455.9 MB 6.9 MB/s eta 0:00:05\n",
      "   ------------------------------------- -- 427.6/455.9 MB 6.9 MB/s eta 0:00:05\n",
      "   ------------------------------------- -- 429.1/455.9 MB 6.9 MB/s eta 0:00:04\n",
      "   ------------------------------------- -- 430.4/455.9 MB 6.9 MB/s eta 0:00:04\n",
      "   ------------------------------------- -- 432.0/455.9 MB 6.9 MB/s eta 0:00:04\n",
      "   -------------------------------------- - 433.6/455.9 MB 6.9 MB/s eta 0:00:04\n",
      "   -------------------------------------- - 434.9/455.9 MB 6.9 MB/s eta 0:00:04\n",
      "   -------------------------------------- - 436.5/455.9 MB 6.9 MB/s eta 0:00:03\n",
      "   -------------------------------------- - 437.8/455.9 MB 6.9 MB/s eta 0:00:03\n",
      "   -------------------------------------- - 439.4/455.9 MB 6.9 MB/s eta 0:00:03\n",
      "   -------------------------------------- - 440.9/455.9 MB 6.9 MB/s eta 0:00:03\n",
      "   -------------------------------------- - 442.5/455.9 MB 6.9 MB/s eta 0:00:02\n",
      "   -------------------------------------- - 443.8/455.9 MB 6.9 MB/s eta 0:00:02\n",
      "   ---------------------------------------  445.4/455.9 MB 6.9 MB/s eta 0:00:02\n",
      "   ---------------------------------------  447.0/455.9 MB 6.9 MB/s eta 0:00:02\n",
      "   ---------------------------------------  448.3/455.9 MB 6.9 MB/s eta 0:00:02\n",
      "   ---------------------------------------  449.8/455.9 MB 6.9 MB/s eta 0:00:01\n",
      "   ---------------------------------------  451.4/455.9 MB 6.9 MB/s eta 0:00:01\n",
      "   ---------------------------------------  452.7/455.9 MB 6.9 MB/s eta 0:00:01\n",
      "   ---------------------------------------  454.3/455.9 MB 6.9 MB/s eta 0:00:01\n",
      "   ---------------------------------------  455.9/455.9 MB 6.9 MB/s eta 0:00:01\n",
      "   ---------------------------------------  455.9/455.9 MB 6.9 MB/s eta 0:00:01\n",
      "   ---------------------------------------  455.9/455.9 MB 6.9 MB/s eta 0:00:01\n",
      "   ---------------------------------------  455.9/455.9 MB 6.9 MB/s eta 0:00:01\n",
      "   ---------------------------------------  455.9/455.9 MB 6.9 MB/s eta 0:00:01\n",
      "   ---------------------------------------  455.9/455.9 MB 6.9 MB/s eta 0:00:01\n",
      "   ---------------------------------------  455.9/455.9 MB 6.9 MB/s eta 0:00:01\n",
      "   ---------------------------------------  455.9/455.9 MB 6.9 MB/s eta 0:00:01\n",
      "   ---------------------------------------  455.9/455.9 MB 6.9 MB/s eta 0:00:01\n",
      "   ---------------------------------------  455.9/455.9 MB 6.9 MB/s eta 0:00:01\n",
      "   ---------------------------------------  455.9/455.9 MB 6.9 MB/s eta 0:00:01\n",
      "   ---------------------------------------  455.9/455.9 MB 6.9 MB/s eta 0:00:01\n",
      "   ---------------------------------------- 455.9/455.9 MB 6.4 MB/s eta 0:00:00\n",
      "Downloading gast-0.4.0-py3-none-any.whl (9.8 kB)\n",
      "Downloading keras-2.10.0-py2.py3-none-any.whl (1.7 MB)\n",
      "   ---------------------------------------- 0.0/1.7 MB ? eta -:--:--\n",
      "   ------------------ --------------------- 0.8/1.7 MB 4.2 MB/s eta 0:00:01\n",
      "   ---------------------------------------- 1.7/1.7 MB 4.3 MB/s eta 0:00:00\n",
      "Downloading protobuf-3.19.6-cp39-cp39-win_amd64.whl (895 kB)\n",
      "   ---------------------------------------- 0.0/895.9 kB ? eta -:--:--\n",
      "   ---------------------------------------- 895.9/895.9 kB 4.5 MB/s eta 0:00:00\n",
      "Downloading tensorboard-2.10.1-py3-none-any.whl (5.9 MB)\n",
      "   ---------------------------------------- 0.0/5.9 MB ? eta -:--:--\n",
      "   -------- ------------------------------- 1.3/5.9 MB 6.1 MB/s eta 0:00:01\n",
      "   ----------------- ---------------------- 2.6/5.9 MB 6.6 MB/s eta 0:00:01\n",
      "   ---------------------------- ----------- 4.2/5.9 MB 6.8 MB/s eta 0:00:01\n",
      "   ---------------------------------------  5.8/5.9 MB 6.8 MB/s eta 0:00:01\n",
      "   ---------------------------------------- 5.9/5.9 MB 6.2 MB/s eta 0:00:00\n",
      "Downloading google_auth-2.40.3-py2.py3-none-any.whl (216 kB)\n",
      "Downloading cachetools-5.5.2-py3-none-any.whl (10 kB)\n",
      "Downloading google_auth_oauthlib-0.4.6-py2.py3-none-any.whl (18 kB)\n",
      "Downloading rsa-4.9.1-py3-none-any.whl (34 kB)\n",
      "Downloading tensorboard_data_server-0.6.1-py3-none-any.whl (2.4 kB)\n",
      "Downloading tensorflow_estimator-2.10.0-py2.py3-none-any.whl (438 kB)\n",
      "Downloading Keras_Preprocessing-1.1.2-py2.py3-none-any.whl (42 kB)\n",
      "Downloading pyasn1-0.6.1-py3-none-any.whl (83 kB)\n",
      "Downloading pyasn1_modules-0.4.2-py3-none-any.whl (181 kB)\n",
      "Downloading requests_oauthlib-2.0.0-py2.py3-none-any.whl (24 kB)\n",
      "Downloading oauthlib-3.3.1-py3-none-any.whl (160 kB)\n",
      "Downloading tensorboard_plugin_wit-1.8.1-py3-none-any.whl (781 kB)\n",
      "   ---------------------------------------- 0.0/781.3 kB ? eta -:--:--\n",
      "   ---------------------------------------- 781.3/781.3 kB 3.3 MB/s eta 0:00:00\n",
      "Using cached tf_keras-2.15.0-py3-none-any.whl (1.7 MB)\n",
      "Installing collected packages: tensorboard-plugin-wit, keras, tf-keras, tensorflow-estimator, tensorboard-data-server, pyasn1, protobuf, oauthlib, keras-preprocessing, gast, cachetools, rsa, requests-oauthlib, pyasn1-modules, google-auth, google-auth-oauthlib, tensorboard, tensorflow, tensorflow-text\n",
      "\n",
      "   ----------------------------------------  0/19 [tensorboard-plugin-wit]\n",
      "  Attempting uninstall: keras\n",
      "   ----------------------------------------  0/19 [tensorboard-plugin-wit]\n",
      "    Found existing installation: keras 3.10.0\n",
      "   ----------------------------------------  0/19 [tensorboard-plugin-wit]\n",
      "    Uninstalling keras-3.10.0:\n",
      "   ----------------------------------------  0/19 [tensorboard-plugin-wit]\n",
      "      Successfully uninstalled keras-3.10.0\n",
      "   ----------------------------------------  0/19 [tensorboard-plugin-wit]\n",
      "   -- -------------------------------------  1/19 [keras]\n",
      "   -- -------------------------------------  1/19 [keras]\n",
      "   -- -------------------------------------  1/19 [keras]\n",
      "   -- -------------------------------------  1/19 [keras]\n",
      "   -- -------------------------------------  1/19 [keras]\n",
      "   -- -------------------------------------  1/19 [keras]\n",
      "   -- -------------------------------------  1/19 [keras]\n",
      "   -- -------------------------------------  1/19 [keras]\n",
      "   -- -------------------------------------  1/19 [keras]\n",
      "   -- -------------------------------------  1/19 [keras]\n",
      "   -- -------------------------------------  1/19 [keras]\n",
      "   -- -------------------------------------  1/19 [keras]\n",
      "   -- -------------------------------------  1/19 [keras]\n",
      "   -- -------------------------------------  1/19 [keras]\n",
      "   -- -------------------------------------  1/19 [keras]\n",
      "   -- -------------------------------------  1/19 [keras]\n",
      "   -- -------------------------------------  1/19 [keras]\n",
      "   -- -------------------------------------  1/19 [keras]\n",
      "   -- -------------------------------------  1/19 [keras]\n",
      "   -- -------------------------------------  1/19 [keras]\n",
      "   -- -------------------------------------  1/19 [keras]\n",
      "   -- -------------------------------------  1/19 [keras]\n",
      "   -- -------------------------------------  1/19 [keras]\n",
      "   -- -------------------------------------  1/19 [keras]\n",
      "  Attempting uninstall: tf-keras\n",
      "   -- -------------------------------------  1/19 [keras]\n",
      "    Found existing installation: tf_keras 2.19.0\n",
      "   -- -------------------------------------  1/19 [keras]\n",
      "    Uninstalling tf_keras-2.19.0:\n",
      "   -- -------------------------------------  1/19 [keras]\n",
      "      Successfully uninstalled tf_keras-2.19.0\n",
      "   -- -------------------------------------  1/19 [keras]\n",
      "   ---- -----------------------------------  2/19 [tf-keras]\n",
      "   ---- -----------------------------------  2/19 [tf-keras]\n",
      "   ---- -----------------------------------  2/19 [tf-keras]\n",
      "   ---- -----------------------------------  2/19 [tf-keras]\n",
      "   ---- -----------------------------------  2/19 [tf-keras]\n",
      "   ---- -----------------------------------  2/19 [tf-keras]\n",
      "   ---- -----------------------------------  2/19 [tf-keras]\n",
      "   ---- -----------------------------------  2/19 [tf-keras]\n",
      "   ---- -----------------------------------  2/19 [tf-keras]\n",
      "   ---- -----------------------------------  2/19 [tf-keras]\n",
      "   ---- -----------------------------------  2/19 [tf-keras]\n",
      "   ---- -----------------------------------  2/19 [tf-keras]\n",
      "   ---- -----------------------------------  2/19 [tf-keras]\n",
      "   ---- -----------------------------------  2/19 [tf-keras]\n",
      "   ---- -----------------------------------  2/19 [tf-keras]\n",
      "   ---- -----------------------------------  2/19 [tf-keras]\n",
      "   ---- -----------------------------------  2/19 [tf-keras]\n",
      "   ---- -----------------------------------  2/19 [tf-keras]\n",
      "   ---- -----------------------------------  2/19 [tf-keras]\n",
      "   ---- -----------------------------------  2/19 [tf-keras]\n",
      "   ---- -----------------------------------  2/19 [tf-keras]\n",
      "   ---- -----------------------------------  2/19 [tf-keras]\n",
      "   ---- -----------------------------------  2/19 [tf-keras]\n",
      "   ---- -----------------------------------  2/19 [tf-keras]\n",
      "   ---- -----------------------------------  2/19 [tf-keras]\n",
      "   ------ ---------------------------------  3/19 [tensorflow-estimator]\n",
      "   ------ ---------------------------------  3/19 [tensorflow-estimator]\n",
      "   ------ ---------------------------------  3/19 [tensorflow-estimator]\n",
      "   ------ ---------------------------------  3/19 [tensorflow-estimator]\n",
      "  Attempting uninstall: tensorboard-data-server\n",
      "   ------ ---------------------------------  3/19 [tensorflow-estimator]\n",
      "    Found existing installation: tensorboard-data-server 0.7.2\n",
      "   ------ ---------------------------------  3/19 [tensorflow-estimator]\n",
      "    Uninstalling tensorboard-data-server-0.7.2:\n",
      "   ------ ---------------------------------  3/19 [tensorflow-estimator]\n",
      "      Successfully uninstalled tensorboard-data-server-0.7.2\n",
      "   ------ ---------------------------------  3/19 [tensorflow-estimator]\n",
      "   -------- -------------------------------  4/19 [tensorboard-data-server]\n",
      "   ---------- -----------------------------  5/19 [pyasn1]\n",
      "   ---------- -----------------------------  5/19 [pyasn1]\n",
      "  Attempting uninstall: protobuf\n",
      "   ---------- -----------------------------  5/19 [pyasn1]\n",
      "    Found existing installation: protobuf 5.29.5\n",
      "   ---------- -----------------------------  5/19 [pyasn1]\n",
      "    Uninstalling protobuf-5.29.5:\n",
      "   ---------- -----------------------------  5/19 [pyasn1]\n",
      "      Successfully uninstalled protobuf-5.29.5\n",
      "   ---------- -----------------------------  5/19 [pyasn1]\n",
      "   ------------ ---------------------------  6/19 [protobuf]\n",
      "   ------------ ---------------------------  6/19 [protobuf]\n",
      "   ------------ ---------------------------  6/19 [protobuf]\n",
      "   -------------- -------------------------  7/19 [oauthlib]\n",
      "   -------------- -------------------------  7/19 [oauthlib]\n",
      "   -------------- -------------------------  7/19 [oauthlib]\n",
      "   ---------------- -----------------------  8/19 [keras-preprocessing]\n",
      "  Attempting uninstall: gast\n",
      "   ---------------- -----------------------  8/19 [keras-preprocessing]\n",
      "    Found existing installation: gast 0.6.0\n",
      "   ---------------- -----------------------  8/19 [keras-preprocessing]\n",
      "    Uninstalling gast-0.6.0:\n",
      "   ---------------- -----------------------  8/19 [keras-preprocessing]\n",
      "      Successfully uninstalled gast-0.6.0\n",
      "   ---------------- -----------------------  8/19 [keras-preprocessing]\n",
      "   ------------------ ---------------------  9/19 [gast]\n",
      "   --------------------- ------------------ 10/19 [cachetools]\n",
      "   ----------------------- ---------------- 11/19 [rsa]\n",
      "   ----------------------- ---------------- 11/19 [rsa]\n",
      "   --------------------------- ------------ 13/19 [pyasn1-modules]\n",
      "   --------------------------- ------------ 13/19 [pyasn1-modules]\n",
      "   --------------------------- ------------ 13/19 [pyasn1-modules]\n",
      "   --------------------------- ------------ 13/19 [pyasn1-modules]\n",
      "   ----------------------------- ---------- 14/19 [google-auth]\n",
      "   ----------------------------- ---------- 14/19 [google-auth]\n",
      "   ----------------------------- ---------- 14/19 [google-auth]\n",
      "   ------------------------------- -------- 15/19 [google-auth-oauthlib]\n",
      "  Attempting uninstall: tensorboard\n",
      "   ------------------------------- -------- 15/19 [google-auth-oauthlib]\n",
      "    Found existing installation: tensorboard 2.19.0\n",
      "   ------------------------------- -------- 15/19 [google-auth-oauthlib]\n",
      "    Uninstalling tensorboard-2.19.0:\n",
      "   ------------------------------- -------- 15/19 [google-auth-oauthlib]\n",
      "      Successfully uninstalled tensorboard-2.19.0\n",
      "   ------------------------------- -------- 15/19 [google-auth-oauthlib]\n",
      "   --------------------------------- ------ 16/19 [tensorboard]\n",
      "   --------------------------------- ------ 16/19 [tensorboard]\n",
      "   --------------------------------- ------ 16/19 [tensorboard]\n",
      "   --------------------------------- ------ 16/19 [tensorboard]\n",
      "   --------------------------------- ------ 16/19 [tensorboard]\n",
      "   --------------------------------- ------ 16/19 [tensorboard]\n",
      "   --------------------------------- ------ 16/19 [tensorboard]\n",
      "   --------------------------------- ------ 16/19 [tensorboard]\n",
      "   --------------------------------- ------ 16/19 [tensorboard]\n",
      "   --------------------------------- ------ 16/19 [tensorboard]\n",
      "   --------------------------------- ------ 16/19 [tensorboard]\n",
      "   --------------------------------- ------ 16/19 [tensorboard]\n",
      "  Attempting uninstall: tensorflow\n",
      "   --------------------------------- ------ 16/19 [tensorboard]\n",
      "    Found existing installation: tensorflow 2.19.0\n",
      "   --------------------------------- ------ 16/19 [tensorboard]\n",
      "   ----------------------------------- ---- 17/19 [tensorflow]\n",
      "   ----------------------------------- ---- 17/19 [tensorflow]\n",
      "   ----------------------------------- ---- 17/19 [tensorflow]\n",
      "    Uninstalling tensorflow-2.19.0:\n",
      "   ----------------------------------- ---- 17/19 [tensorflow]\n",
      "   ----------------------------------- ---- 17/19 [tensorflow]\n",
      "      Successfully uninstalled tensorflow-2.19.0\n",
      "   ----------------------------------- ---- 17/19 [tensorflow]\n",
      "   ----------------------------------- ---- 17/19 [tensorflow]\n",
      "   ----------------------------------- ---- 17/19 [tensorflow]\n",
      "   ----------------------------------- ---- 17/19 [tensorflow]\n",
      "   ----------------------------------- ---- 17/19 [tensorflow]\n",
      "   ----------------------------------- ---- 17/19 [tensorflow]\n",
      "   ----------------------------------- ---- 17/19 [tensorflow]\n",
      "   ----------------------------------- ---- 17/19 [tensorflow]\n",
      "   ----------------------------------- ---- 17/19 [tensorflow]\n",
      "   ----------------------------------- ---- 17/19 [tensorflow]\n",
      "   ----------------------------------- ---- 17/19 [tensorflow]\n",
      "   ----------------------------------- ---- 17/19 [tensorflow]\n",
      "   ----------------------------------- ---- 17/19 [tensorflow]\n",
      "   ----------------------------------- ---- 17/19 [tensorflow]\n",
      "   ----------------------------------- ---- 17/19 [tensorflow]\n",
      "   ----------------------------------- ---- 17/19 [tensorflow]\n",
      "   ----------------------------------- ---- 17/19 [tensorflow]\n",
      "   ----------------------------------- ---- 17/19 [tensorflow]\n",
      "   ----------------------------------- ---- 17/19 [tensorflow]\n",
      "   ----------------------------------- ---- 17/19 [tensorflow]\n",
      "   ----------------------------------- ---- 17/19 [tensorflow]\n",
      "   ----------------------------------- ---- 17/19 [tensorflow]\n",
      "   ----------------------------------- ---- 17/19 [tensorflow]\n",
      "   ----------------------------------- ---- 17/19 [tensorflow]\n",
      "   ----------------------------------- ---- 17/19 [tensorflow]\n",
      "   ----------------------------------- ---- 17/19 [tensorflow]\n",
      "   ----------------------------------- ---- 17/19 [tensorflow]\n",
      "   ----------------------------------- ---- 17/19 [tensorflow]\n",
      "   ----------------------------------- ---- 17/19 [tensorflow]\n",
      "   ----------------------------------- ---- 17/19 [tensorflow]\n",
      "   ----------------------------------- ---- 17/19 [tensorflow]\n",
      "   ----------------------------------- ---- 17/19 [tensorflow]\n",
      "   ----------------------------------- ---- 17/19 [tensorflow]\n",
      "   ----------------------------------- ---- 17/19 [tensorflow]\n",
      "   ----------------------------------- ---- 17/19 [tensorflow]\n",
      "   ----------------------------------- ---- 17/19 [tensorflow]\n",
      "   ----------------------------------- ---- 17/19 [tensorflow]\n",
      "   ----------------------------------- ---- 17/19 [tensorflow]\n",
      "   ----------------------------------- ---- 17/19 [tensorflow]\n",
      "   ----------------------------------- ---- 17/19 [tensorflow]\n",
      "   ----------------------------------- ---- 17/19 [tensorflow]\n",
      "   ----------------------------------- ---- 17/19 [tensorflow]\n",
      "   ----------------------------------- ---- 17/19 [tensorflow]\n",
      "   ----------------------------------- ---- 17/19 [tensorflow]\n",
      "   ----------------------------------- ---- 17/19 [tensorflow]\n",
      "   ----------------------------------- ---- 17/19 [tensorflow]\n",
      "   ----------------------------------- ---- 17/19 [tensorflow]\n",
      "   ----------------------------------- ---- 17/19 [tensorflow]\n",
      "   ----------------------------------- ---- 17/19 [tensorflow]\n",
      "   ----------------------------------- ---- 17/19 [tensorflow]\n",
      "   ----------------------------------- ---- 17/19 [tensorflow]\n",
      "   ----------------------------------- ---- 17/19 [tensorflow]\n",
      "   ----------------------------------- ---- 17/19 [tensorflow]\n",
      "   ----------------------------------- ---- 17/19 [tensorflow]\n",
      "   ----------------------------------- ---- 17/19 [tensorflow]\n",
      "   ----------------------------------- ---- 17/19 [tensorflow]\n",
      "   ----------------------------------- ---- 17/19 [tensorflow]\n",
      "   ----------------------------------- ---- 17/19 [tensorflow]\n",
      "   ----------------------------------- ---- 17/19 [tensorflow]\n",
      "   ----------------------------------- ---- 17/19 [tensorflow]\n",
      "   ----------------------------------- ---- 17/19 [tensorflow]\n",
      "   ----------------------------------- ---- 17/19 [tensorflow]\n",
      "   ----------------------------------- ---- 17/19 [tensorflow]\n",
      "   ----------------------------------- ---- 17/19 [tensorflow]\n",
      "   ----------------------------------- ---- 17/19 [tensorflow]\n",
      "   ----------------------------------- ---- 17/19 [tensorflow]\n",
      "   ----------------------------------- ---- 17/19 [tensorflow]\n",
      "   ----------------------------------- ---- 17/19 [tensorflow]\n",
      "   ----------------------------------- ---- 17/19 [tensorflow]\n",
      "   ----------------------------------- ---- 17/19 [tensorflow]\n",
      "   ----------------------------------- ---- 17/19 [tensorflow]\n",
      "   ----------------------------------- ---- 17/19 [tensorflow]\n",
      "   ----------------------------------- ---- 17/19 [tensorflow]\n",
      "   ----------------------------------- ---- 17/19 [tensorflow]\n",
      "   ----------------------------------- ---- 17/19 [tensorflow]\n",
      "   ----------------------------------- ---- 17/19 [tensorflow]\n",
      "   ----------------------------------- ---- 17/19 [tensorflow]\n",
      "   ----------------------------------- ---- 17/19 [tensorflow]\n",
      "   ----------------------------------- ---- 17/19 [tensorflow]\n",
      "   ----------------------------------- ---- 17/19 [tensorflow]\n",
      "   ----------------------------------- ---- 17/19 [tensorflow]\n",
      "   ----------------------------------- ---- 17/19 [tensorflow]\n",
      "   ----------------------------------- ---- 17/19 [tensorflow]\n",
      "   ----------------------------------- ---- 17/19 [tensorflow]\n",
      "   ----------------------------------- ---- 17/19 [tensorflow]\n",
      "   ----------------------------------- ---- 17/19 [tensorflow]\n",
      "   ----------------------------------- ---- 17/19 [tensorflow]\n",
      "   ----------------------------------- ---- 17/19 [tensorflow]\n",
      "   ----------------------------------- ---- 17/19 [tensorflow]\n",
      "   ----------------------------------- ---- 17/19 [tensorflow]\n",
      "   ----------------------------------- ---- 17/19 [tensorflow]\n",
      "   ----------------------------------- ---- 17/19 [tensorflow]\n",
      "   ----------------------------------- ---- 17/19 [tensorflow]\n",
      "   ----------------------------------- ---- 17/19 [tensorflow]\n",
      "   ----------------------------------- ---- 17/19 [tensorflow]\n",
      "   ----------------------------------- ---- 17/19 [tensorflow]\n",
      "   ----------------------------------- ---- 17/19 [tensorflow]\n",
      "   ----------------------------------- ---- 17/19 [tensorflow]\n",
      "   ----------------------------------- ---- 17/19 [tensorflow]\n",
      "   ----------------------------------- ---- 17/19 [tensorflow]\n",
      "   ----------------------------------- ---- 17/19 [tensorflow]\n",
      "   ----------------------------------- ---- 17/19 [tensorflow]\n",
      "   ----------------------------------- ---- 17/19 [tensorflow]\n",
      "   ----------------------------------- ---- 17/19 [tensorflow]\n",
      "   ----------------------------------- ---- 17/19 [tensorflow]\n",
      "   ----------------------------------- ---- 17/19 [tensorflow]\n",
      "   ----------------------------------- ---- 17/19 [tensorflow]\n",
      "   ----------------------------------- ---- 17/19 [tensorflow]\n",
      "   ----------------------------------- ---- 17/19 [tensorflow]\n",
      "   ----------------------------------- ---- 17/19 [tensorflow]\n",
      "   ----------------------------------- ---- 17/19 [tensorflow]\n",
      "   ----------------------------------- ---- 17/19 [tensorflow]\n",
      "   ----------------------------------- ---- 17/19 [tensorflow]\n",
      "   ----------------------------------- ---- 17/19 [tensorflow]\n",
      "   ----------------------------------- ---- 17/19 [tensorflow]\n",
      "   ----------------------------------- ---- 17/19 [tensorflow]\n",
      "   ----------------------------------- ---- 17/19 [tensorflow]\n",
      "   ----------------------------------- ---- 17/19 [tensorflow]\n",
      "   ----------------------------------- ---- 17/19 [tensorflow]\n",
      "   ----------------------------------- ---- 17/19 [tensorflow]\n",
      "   ----------------------------------- ---- 17/19 [tensorflow]\n",
      "   ----------------------------------- ---- 17/19 [tensorflow]\n",
      "   ----------------------------------- ---- 17/19 [tensorflow]\n",
      "   ----------------------------------- ---- 17/19 [tensorflow]\n",
      "   ----------------------------------- ---- 17/19 [tensorflow]\n",
      "   ----------------------------------- ---- 17/19 [tensorflow]\n",
      "   ----------------------------------- ---- 17/19 [tensorflow]\n",
      "   ----------------------------------- ---- 17/19 [tensorflow]\n",
      "   ----------------------------------- ---- 17/19 [tensorflow]\n",
      "   ----------------------------------- ---- 17/19 [tensorflow]\n",
      "   ----------------------------------- ---- 17/19 [tensorflow]\n",
      "   ----------------------------------- ---- 17/19 [tensorflow]\n",
      "   ----------------------------------- ---- 17/19 [tensorflow]\n",
      "   ----------------------------------- ---- 17/19 [tensorflow]\n",
      "   ----------------------------------- ---- 17/19 [tensorflow]\n",
      "   ----------------------------------- ---- 17/19 [tensorflow]\n",
      "   ----------------------------------- ---- 17/19 [tensorflow]\n",
      "   ----------------------------------- ---- 17/19 [tensorflow]\n",
      "   ----------------------------------- ---- 17/19 [tensorflow]\n",
      "   ----------------------------------- ---- 17/19 [tensorflow]\n",
      "   ----------------------------------- ---- 17/19 [tensorflow]\n",
      "   ----------------------------------- ---- 17/19 [tensorflow]\n",
      "   ----------------------------------- ---- 17/19 [tensorflow]\n",
      "   ----------------------------------- ---- 17/19 [tensorflow]\n",
      "   ----------------------------------- ---- 17/19 [tensorflow]\n",
      "   ----------------------------------- ---- 17/19 [tensorflow]\n",
      "   ----------------------------------- ---- 17/19 [tensorflow]\n",
      "   ----------------------------------- ---- 17/19 [tensorflow]\n",
      "   ----------------------------------- ---- 17/19 [tensorflow]\n",
      "   ----------------------------------- ---- 17/19 [tensorflow]\n",
      "   ----------------------------------- ---- 17/19 [tensorflow]\n",
      "   ----------------------------------- ---- 17/19 [tensorflow]\n",
      "   ----------------------------------- ---- 17/19 [tensorflow]\n",
      "   ----------------------------------- ---- 17/19 [tensorflow]\n",
      "   ----------------------------------- ---- 17/19 [tensorflow]\n",
      "   ----------------------------------- ---- 17/19 [tensorflow]\n",
      "   ----------------------------------- ---- 17/19 [tensorflow]\n",
      "   ----------------------------------- ---- 17/19 [tensorflow]\n",
      "   ----------------------------------- ---- 17/19 [tensorflow]\n",
      "   ----------------------------------- ---- 17/19 [tensorflow]\n",
      "   ----------------------------------- ---- 17/19 [tensorflow]\n",
      "   ----------------------------------- ---- 17/19 [tensorflow]\n",
      "   ----------------------------------- ---- 17/19 [tensorflow]\n",
      "   ----------------------------------- ---- 17/19 [tensorflow]\n",
      "   ----------------------------------- ---- 17/19 [tensorflow]\n",
      "   ----------------------------------- ---- 17/19 [tensorflow]\n",
      "   ----------------------------------- ---- 17/19 [tensorflow]\n",
      "   ----------------------------------- ---- 17/19 [tensorflow]\n",
      "   ----------------------------------- ---- 17/19 [tensorflow]\n",
      "   ----------------------------------- ---- 17/19 [tensorflow]\n",
      "   ----------------------------------- ---- 17/19 [tensorflow]\n",
      "   ----------------------------------- ---- 17/19 [tensorflow]\n",
      "   ----------------------------------- ---- 17/19 [tensorflow]\n",
      "   ----------------------------------- ---- 17/19 [tensorflow]\n",
      "   ----------------------------------- ---- 17/19 [tensorflow]\n",
      "   ----------------------------------- ---- 17/19 [tensorflow]\n",
      "   ----------------------------------- ---- 17/19 [tensorflow]\n",
      "   ----------------------------------- ---- 17/19 [tensorflow]\n",
      "   ----------------------------------- ---- 17/19 [tensorflow]\n",
      "   ----------------------------------- ---- 17/19 [tensorflow]\n",
      "   ----------------------------------- ---- 17/19 [tensorflow]\n",
      "   ----------------------------------- ---- 17/19 [tensorflow]\n",
      "   ----------------------------------- ---- 17/19 [tensorflow]\n",
      "   ----------------------------------- ---- 17/19 [tensorflow]\n",
      "   ----------------------------------- ---- 17/19 [tensorflow]\n",
      "   ----------------------------------- ---- 17/19 [tensorflow]\n",
      "   ----------------------------------- ---- 17/19 [tensorflow]\n",
      "   ----------------------------------- ---- 17/19 [tensorflow]\n",
      "   ----------------------------------- ---- 17/19 [tensorflow]\n",
      "   ----------------------------------- ---- 17/19 [tensorflow]\n",
      "   ----------------------------------- ---- 17/19 [tensorflow]\n",
      "   ----------------------------------- ---- 17/19 [tensorflow]\n",
      "   ----------------------------------- ---- 17/19 [tensorflow]\n",
      "   ----------------------------------- ---- 17/19 [tensorflow]\n",
      "   ----------------------------------- ---- 17/19 [tensorflow]\n",
      "   ----------------------------------- ---- 17/19 [tensorflow]\n",
      "   ----------------------------------- ---- 17/19 [tensorflow]\n",
      "   ----------------------------------- ---- 17/19 [tensorflow]\n",
      "   ----------------------------------- ---- 17/19 [tensorflow]\n",
      "   ----------------------------------- ---- 17/19 [tensorflow]\n",
      "   ----------------------------------- ---- 17/19 [tensorflow]\n",
      "   ----------------------------------- ---- 17/19 [tensorflow]\n",
      "   ----------------------------------- ---- 17/19 [tensorflow]\n",
      "   ----------------------------------- ---- 17/19 [tensorflow]\n",
      "   ----------------------------------- ---- 17/19 [tensorflow]\n",
      "   ----------------------------------- ---- 17/19 [tensorflow]\n",
      "   ----------------------------------- ---- 17/19 [tensorflow]\n",
      "   ----------------------------------- ---- 17/19 [tensorflow]\n",
      "   ----------------------------------- ---- 17/19 [tensorflow]\n",
      "   ----------------------------------- ---- 17/19 [tensorflow]\n",
      "   ----------------------------------- ---- 17/19 [tensorflow]\n",
      "   ----------------------------------- ---- 17/19 [tensorflow]\n",
      "   ----------------------------------- ---- 17/19 [tensorflow]\n",
      "   ----------------------------------- ---- 17/19 [tensorflow]\n",
      "   ----------------------------------- ---- 17/19 [tensorflow]\n",
      "   ----------------------------------- ---- 17/19 [tensorflow]\n",
      "   ----------------------------------- ---- 17/19 [tensorflow]\n",
      "   ----------------------------------- ---- 17/19 [tensorflow]\n",
      "   ----------------------------------- ---- 17/19 [tensorflow]\n",
      "   ----------------------------------- ---- 17/19 [tensorflow]\n",
      "   ----------------------------------- ---- 17/19 [tensorflow]\n",
      "   ----------------------------------- ---- 17/19 [tensorflow]\n",
      "   ----------------------------------- ---- 17/19 [tensorflow]\n",
      "   ----------------------------------- ---- 17/19 [tensorflow]\n",
      "   ----------------------------------- ---- 17/19 [tensorflow]\n",
      "   ----------------------------------- ---- 17/19 [tensorflow]\n",
      "   ----------------------------------- ---- 17/19 [tensorflow]\n",
      "   ----------------------------------- ---- 17/19 [tensorflow]\n",
      "   ----------------------------------- ---- 17/19 [tensorflow]\n",
      "   ----------------------------------- ---- 17/19 [tensorflow]\n",
      "   ----------------------------------- ---- 17/19 [tensorflow]\n",
      "   ----------------------------------- ---- 17/19 [tensorflow]\n",
      "   ----------------------------------- ---- 17/19 [tensorflow]\n",
      "   ----------------------------------- ---- 17/19 [tensorflow]\n",
      "   ----------------------------------- ---- 17/19 [tensorflow]\n",
      "   ------------------------------------- -- 18/19 [tensorflow-text]\n",
      "   ------------------------------------- -- 18/19 [tensorflow-text]\n",
      "   ------------------------------------- -- 18/19 [tensorflow-text]\n",
      "   ------------------------------------- -- 18/19 [tensorflow-text]\n",
      "   ---------------------------------------- 19/19 [tensorflow-text]\n",
      "\n",
      "Successfully installed cachetools-5.5.2 gast-0.4.0 google-auth-2.40.3 google-auth-oauthlib-0.4.6 keras-2.10.0 keras-preprocessing-1.1.2 oauthlib-3.3.1 protobuf-3.19.6 pyasn1-0.6.1 pyasn1-modules-0.4.2 requests-oauthlib-2.0.0 rsa-4.9.1 tensorboard-2.10.1 tensorboard-data-server-0.6.1 tensorboard-plugin-wit-1.8.1 tensorflow-2.10.1 tensorflow-estimator-2.10.0 tensorflow-text-2.10.0 tf-keras-2.15.0\n"
     ]
    }
   ],
   "source": [
    "!pip install tensorflow-hub\n",
    "\n",
    "!pip install tensorflow-text"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "id": "fad2ab30",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "ERROR: Could not find a version that satisfies the requirement tensorflow<2.11 (from versions: none)\n",
      "ERROR: No matching distribution found for tensorflow<2.11\n"
     ]
    }
   ],
   "source": [
    "!python -m pip install \"tensorflow<2.11\"\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "id": "79a933dc",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "Failed to import tensorflow. Please note that tensorflow is not installed by default when you install tensorflow_hub. This is so that users can decide which tensorflow package to use. To use tensorflow_hub, please install a current version of tensorflow by following the instructions at https://tensorflow.org/install and https://tensorflow.org/hub/installation.\n",
      "\n",
      "\n"
     ]
    },
    {
     "ename": "ModuleNotFoundError",
     "evalue": "No module named 'tensorflow'",
     "output_type": "error",
     "traceback": [
      "\u001b[31m---------------------------------------------------------------------------\u001b[39m",
      "\u001b[31mModuleNotFoundError\u001b[39m                       Traceback (most recent call last)",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[41]\u001b[39m\u001b[32m, line 1\u001b[39m\n\u001b[32m----> \u001b[39m\u001b[32m1\u001b[39m \u001b[38;5;28;01mimport\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34;01mtensorflow_hub\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mas\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34;01mhub\u001b[39;00m\n\u001b[32m      3\u001b[39m \u001b[38;5;66;03m# Charger USE depuis TensorFlow Hub\u001b[39;00m\n\u001b[32m      4\u001b[39m use_model = hub.load(\u001b[33m\"\u001b[39m\u001b[33mhttps://tfhub.dev/google/universal-sentence-encoder/4\u001b[39m\u001b[33m\"\u001b[39m)\n",
      "\u001b[36mFile \u001b[39m\u001b[32mc:\\Users\\Yann\\Desktop\\DEV\\School\\ml_m1\\NLP\\CustomGPT\\scraper_env\\Lib\\site-packages\\tensorflow_hub\\__init__.py:85\u001b[39m\n\u001b[32m     74\u001b[39m   \u001b[38;5;28;01mif\u001b[39;00m (parse_version(tf.__version__) <\n\u001b[32m     75\u001b[39m       parse_version(required_tensorflow_version)):\n\u001b[32m     76\u001b[39m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mImportError\u001b[39;00m(\n\u001b[32m     77\u001b[39m         \u001b[33m\"\u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[33mThis version of tensorflow_hub requires tensorflow \u001b[39m\u001b[33m\"\u001b[39m\n\u001b[32m     78\u001b[39m         \u001b[33m\"\u001b[39m\u001b[33mversion >= \u001b[39m\u001b[38;5;132;01m{required}\u001b[39;00m\u001b[33m; Detected an installation of version \u001b[39m\u001b[38;5;132;01m{present}\u001b[39;00m\u001b[33m. \u001b[39m\u001b[33m\"\u001b[39m\n\u001b[32m   (...)\u001b[39m\u001b[32m     82\u001b[39m             required=required_tensorflow_version,\n\u001b[32m     83\u001b[39m             present=tf.__version__))\n\u001b[32m---> \u001b[39m\u001b[32m85\u001b[39m \u001b[43m_ensure_tf_install\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m     88\u001b[39m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34m_ensure_keras_2_importable\u001b[39m():\n\u001b[32m     89\u001b[39m \u001b[38;5;250m  \u001b[39m\u001b[33;03m\"\"\"Check that Keras 2 can be used by attempting to import tf_keras.\u001b[39;00m\n\u001b[32m     90\u001b[39m \n\u001b[32m     91\u001b[39m \u001b[33;03m  Raises:\u001b[39;00m\n\u001b[32m     92\u001b[39m \u001b[33;03m    ImportError: if using tf.keras would mean using Keras 3 and tf_keras is not\u001b[39;00m\n\u001b[32m     93\u001b[39m \u001b[33;03m      installed.\u001b[39;00m\n\u001b[32m     94\u001b[39m \u001b[33;03m  \"\"\"\u001b[39;00m\n",
      "\u001b[36mFile \u001b[39m\u001b[32mc:\\Users\\Yann\\Desktop\\DEV\\School\\ml_m1\\NLP\\CustomGPT\\scraper_env\\Lib\\site-packages\\tensorflow_hub\\__init__.py:49\u001b[39m, in \u001b[36m_ensure_tf_install\u001b[39m\u001b[34m()\u001b[39m\n\u001b[32m     42\u001b[39m \u001b[38;5;250m\u001b[39m\u001b[33;03m\"\"\"Attempt to import tensorflow, and ensure its version is sufficient.\u001b[39;00m\n\u001b[32m     43\u001b[39m \n\u001b[32m     44\u001b[39m \u001b[33;03mRaises:\u001b[39;00m\n\u001b[32m     45\u001b[39m \u001b[33;03m  ImportError: if either tensorflow is not importable or its version is\u001b[39;00m\n\u001b[32m     46\u001b[39m \u001b[33;03m  inadequate.\u001b[39;00m\n\u001b[32m     47\u001b[39m \u001b[33;03m\"\"\"\u001b[39;00m\n\u001b[32m     48\u001b[39m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[32m---> \u001b[39m\u001b[32m49\u001b[39m   \u001b[38;5;28;01mimport\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34;01mtensorflow\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mas\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34;01mtf\u001b[39;00m\n\u001b[32m     50\u001b[39m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mImportError\u001b[39;00m:\n\u001b[32m     51\u001b[39m   \u001b[38;5;66;03m# Print more informative error message, then reraise.\u001b[39;00m\n\u001b[32m     52\u001b[39m   \u001b[38;5;28mprint\u001b[39m(\n\u001b[32m     53\u001b[39m       \u001b[33m\"\u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[33mFailed to import tensorflow. Please note that tensorflow is not \u001b[39m\u001b[33m\"\u001b[39m\n\u001b[32m     54\u001b[39m       \u001b[33m\"\u001b[39m\u001b[33minstalled by default when you install tensorflow_hub. This is so that \u001b[39m\u001b[33m\"\u001b[39m\n\u001b[32m   (...)\u001b[39m\u001b[32m     57\u001b[39m       \u001b[33m\"\u001b[39m\u001b[33mby following the instructions at https://tensorflow.org/install and \u001b[39m\u001b[33m\"\u001b[39m\n\u001b[32m     58\u001b[39m       \u001b[33m\"\u001b[39m\u001b[33mhttps://tensorflow.org/hub/installation.\u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[33m\"\u001b[39m)\n",
      "\u001b[31mModuleNotFoundError\u001b[39m: No module named 'tensorflow'"
     ]
    }
   ],
   "source": [
    "import tensorflow_hub as hub\n",
    "\n",
    "# Charger USE depuis TensorFlow Hub\n",
    "use_model = hub.load(\"https://tfhub.dev/google/universal-sentence-encoder/4\")\n",
    "\n",
    "# Encodage (⚠️ long sur CPU)\n",
    "X_train_use = use_model(X_train).numpy()\n",
    "X_val_use = use_model(X_val).numpy()\n",
    "X_test_use = use_model(X_test).numpy()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ea6d2e60",
   "metadata": {},
   "source": [
    "### mlp classif avec use "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "id": "efc2255e",
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'X_train_use' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[31m---------------------------------------------------------------------------\u001b[39m",
      "\u001b[31mNameError\u001b[39m                                 Traceback (most recent call last)",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[46]\u001b[39m\u001b[32m, line 6\u001b[39m\n\u001b[32m      3\u001b[39m mlp = MLPClassifier(hidden_layer_sizes=(\u001b[32m256\u001b[39m, \u001b[32m128\u001b[39m), max_iter=\u001b[32m20\u001b[39m, random_state=\u001b[32m42\u001b[39m, verbose=\u001b[38;5;28;01mTrue\u001b[39;00m)\n\u001b[32m      4\u001b[39m clf_use_mlp = OneVsRestClassifier(mlp)\n\u001b[32m----> \u001b[39m\u001b[32m6\u001b[39m clf_use_mlp.fit(\u001b[43mX_train_use\u001b[49m, y_train)\n\u001b[32m      7\u001b[39m y_val_pred_use = clf_use_mlp.predict(X_val_use)\n",
      "\u001b[31mNameError\u001b[39m: name 'X_train_use' is not defined"
     ]
    }
   ],
   "source": [
    "from sklearn.neural_network import MLPClassifier\n",
    "\n",
    "mlp = MLPClassifier(hidden_layer_sizes=(256, 128), max_iter=20, random_state=42, verbose=True)\n",
    "clf_use_mlp = OneVsRestClassifier(mlp)\n",
    "\n",
    "clf_use_mlp.fit(X_train_use, y_train)\n",
    "y_val_pred_use = clf_use_mlp.predict(X_val_use)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "61f8958b",
   "metadata": {},
   "source": [
    "### Evaluation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "182daf00",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"USE + MLPClassifier\")\n",
    "print(\"F1 micro :\", f1_score(y_val, y_val_pred_use, average='micro'))\n",
    "print(\"F1 macro :\", f1_score(y_val, y_val_pred_use, average='macro'))\n",
    "print(\"Hamming loss :\", hamming_loss(y_val, y_val_pred_use))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f8dd6805",
   "metadata": {},
   "source": [
    "# Fine tuning Roberta "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8bd8eb38",
   "metadata": {},
   "source": [
    "fine tuning dun gros transformers pour les vecteurs les plus riches possible"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "42579bc3",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: transformers in c:\\users\\yann\\anaconda3\\envs\\hf_gpu_env\\lib\\site-packages (4.41.2)\n",
      "Requirement already satisfied: datasets in c:\\users\\yann\\anaconda3\\envs\\hf_gpu_env\\lib\\site-packages (3.6.0)\n",
      "Collecting evaluate\n",
      "  Using cached evaluate-0.4.4-py3-none-any.whl.metadata (9.5 kB)\n",
      "Requirement already satisfied: scikit-learn in c:\\users\\yann\\anaconda3\\envs\\hf_gpu_env\\lib\\site-packages (1.7.0)\n",
      "Requirement already satisfied: filelock in c:\\users\\yann\\anaconda3\\envs\\hf_gpu_env\\lib\\site-packages (from transformers) (3.13.1)\n",
      "Requirement already satisfied: huggingface-hub<1.0,>=0.23.0 in c:\\users\\yann\\anaconda3\\envs\\hf_gpu_env\\lib\\site-packages (from transformers) (0.33.2)\n",
      "Requirement already satisfied: numpy>=1.17 in c:\\users\\yann\\anaconda3\\envs\\hf_gpu_env\\lib\\site-packages (from transformers) (2.1.2)\n",
      "Requirement already satisfied: packaging>=20.0 in c:\\users\\yann\\anaconda3\\envs\\hf_gpu_env\\lib\\site-packages (from transformers) (25.0)\n",
      "Requirement already satisfied: pyyaml>=5.1 in c:\\users\\yann\\anaconda3\\envs\\hf_gpu_env\\lib\\site-packages (from transformers) (6.0.2)\n",
      "Requirement already satisfied: regex!=2019.12.17 in c:\\users\\yann\\anaconda3\\envs\\hf_gpu_env\\lib\\site-packages (from transformers) (2024.11.6)\n",
      "Requirement already satisfied: requests in c:\\users\\yann\\anaconda3\\envs\\hf_gpu_env\\lib\\site-packages (from transformers) (2.32.4)\n",
      "Requirement already satisfied: tokenizers<0.20,>=0.19 in c:\\users\\yann\\anaconda3\\envs\\hf_gpu_env\\lib\\site-packages (from transformers) (0.19.1)\n",
      "Requirement already satisfied: safetensors>=0.4.1 in c:\\users\\yann\\anaconda3\\envs\\hf_gpu_env\\lib\\site-packages (from transformers) (0.5.3)\n",
      "Requirement already satisfied: tqdm>=4.27 in c:\\users\\yann\\anaconda3\\envs\\hf_gpu_env\\lib\\site-packages (from transformers) (4.67.1)\n",
      "Requirement already satisfied: fsspec>=2023.5.0 in c:\\users\\yann\\anaconda3\\envs\\hf_gpu_env\\lib\\site-packages (from huggingface-hub<1.0,>=0.23.0->transformers) (2024.6.1)\n",
      "Requirement already satisfied: typing-extensions>=3.7.4.3 in c:\\users\\yann\\anaconda3\\envs\\hf_gpu_env\\lib\\site-packages (from huggingface-hub<1.0,>=0.23.0->transformers) (4.12.2)\n",
      "Requirement already satisfied: pyarrow>=15.0.0 in c:\\users\\yann\\anaconda3\\envs\\hf_gpu_env\\lib\\site-packages (from datasets) (20.0.0)\n",
      "Requirement already satisfied: dill<0.3.9,>=0.3.0 in c:\\users\\yann\\anaconda3\\envs\\hf_gpu_env\\lib\\site-packages (from datasets) (0.3.8)\n",
      "Requirement already satisfied: pandas in c:\\users\\yann\\anaconda3\\envs\\hf_gpu_env\\lib\\site-packages (from datasets) (2.3.0)\n",
      "Requirement already satisfied: xxhash in c:\\users\\yann\\anaconda3\\envs\\hf_gpu_env\\lib\\site-packages (from datasets) (3.5.0)\n",
      "Requirement already satisfied: multiprocess<0.70.17 in c:\\users\\yann\\anaconda3\\envs\\hf_gpu_env\\lib\\site-packages (from datasets) (0.70.16)\n",
      "Requirement already satisfied: aiohttp!=4.0.0a0,!=4.0.0a1 in c:\\users\\yann\\anaconda3\\envs\\hf_gpu_env\\lib\\site-packages (from fsspec[http]<=2025.3.0,>=2023.1.0->datasets) (3.12.13)\n",
      "Requirement already satisfied: scipy>=1.8.0 in c:\\users\\yann\\anaconda3\\envs\\hf_gpu_env\\lib\\site-packages (from scikit-learn) (1.15.3)\n",
      "Requirement already satisfied: joblib>=1.2.0 in c:\\users\\yann\\anaconda3\\envs\\hf_gpu_env\\lib\\site-packages (from scikit-learn) (1.5.1)\n",
      "Requirement already satisfied: threadpoolctl>=3.1.0 in c:\\users\\yann\\anaconda3\\envs\\hf_gpu_env\\lib\\site-packages (from scikit-learn) (3.6.0)\n",
      "Requirement already satisfied: aiohappyeyeballs>=2.5.0 in c:\\users\\yann\\anaconda3\\envs\\hf_gpu_env\\lib\\site-packages (from aiohttp!=4.0.0a0,!=4.0.0a1->fsspec[http]<=2025.3.0,>=2023.1.0->datasets) (2.6.1)\n",
      "Requirement already satisfied: aiosignal>=1.1.2 in c:\\users\\yann\\anaconda3\\envs\\hf_gpu_env\\lib\\site-packages (from aiohttp!=4.0.0a0,!=4.0.0a1->fsspec[http]<=2025.3.0,>=2023.1.0->datasets) (1.3.2)\n",
      "Requirement already satisfied: async-timeout<6.0,>=4.0 in c:\\users\\yann\\anaconda3\\envs\\hf_gpu_env\\lib\\site-packages (from aiohttp!=4.0.0a0,!=4.0.0a1->fsspec[http]<=2025.3.0,>=2023.1.0->datasets) (5.0.1)\n",
      "Requirement already satisfied: attrs>=17.3.0 in c:\\users\\yann\\anaconda3\\envs\\hf_gpu_env\\lib\\site-packages (from aiohttp!=4.0.0a0,!=4.0.0a1->fsspec[http]<=2025.3.0,>=2023.1.0->datasets) (25.3.0)\n",
      "Requirement already satisfied: frozenlist>=1.1.1 in c:\\users\\yann\\anaconda3\\envs\\hf_gpu_env\\lib\\site-packages (from aiohttp!=4.0.0a0,!=4.0.0a1->fsspec[http]<=2025.3.0,>=2023.1.0->datasets) (1.7.0)\n",
      "Requirement already satisfied: multidict<7.0,>=4.5 in c:\\users\\yann\\anaconda3\\envs\\hf_gpu_env\\lib\\site-packages (from aiohttp!=4.0.0a0,!=4.0.0a1->fsspec[http]<=2025.3.0,>=2023.1.0->datasets) (6.6.3)\n",
      "Requirement already satisfied: propcache>=0.2.0 in c:\\users\\yann\\anaconda3\\envs\\hf_gpu_env\\lib\\site-packages (from aiohttp!=4.0.0a0,!=4.0.0a1->fsspec[http]<=2025.3.0,>=2023.1.0->datasets) (0.3.2)\n",
      "Requirement already satisfied: yarl<2.0,>=1.17.0 in c:\\users\\yann\\anaconda3\\envs\\hf_gpu_env\\lib\\site-packages (from aiohttp!=4.0.0a0,!=4.0.0a1->fsspec[http]<=2025.3.0,>=2023.1.0->datasets) (1.20.1)\n",
      "Requirement already satisfied: idna>=2.0 in c:\\users\\yann\\anaconda3\\envs\\hf_gpu_env\\lib\\site-packages (from yarl<2.0,>=1.17.0->aiohttp!=4.0.0a0,!=4.0.0a1->fsspec[http]<=2025.3.0,>=2023.1.0->datasets) (3.10)\n",
      "Requirement already satisfied: charset_normalizer<4,>=2 in c:\\users\\yann\\anaconda3\\envs\\hf_gpu_env\\lib\\site-packages (from requests->transformers) (3.4.2)\n",
      "Requirement already satisfied: urllib3<3,>=1.21.1 in c:\\users\\yann\\anaconda3\\envs\\hf_gpu_env\\lib\\site-packages (from requests->transformers) (2.5.0)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in c:\\users\\yann\\anaconda3\\envs\\hf_gpu_env\\lib\\site-packages (from requests->transformers) (2025.6.15)\n",
      "Requirement already satisfied: colorama in c:\\users\\yann\\anaconda3\\envs\\hf_gpu_env\\lib\\site-packages (from tqdm>=4.27->transformers) (0.4.6)\n",
      "Requirement already satisfied: python-dateutil>=2.8.2 in c:\\users\\yann\\anaconda3\\envs\\hf_gpu_env\\lib\\site-packages (from pandas->datasets) (2.9.0.post0)\n",
      "Requirement already satisfied: pytz>=2020.1 in c:\\users\\yann\\anaconda3\\envs\\hf_gpu_env\\lib\\site-packages (from pandas->datasets) (2025.2)\n",
      "Requirement already satisfied: tzdata>=2022.7 in c:\\users\\yann\\anaconda3\\envs\\hf_gpu_env\\lib\\site-packages (from pandas->datasets) (2025.2)\n",
      "Requirement already satisfied: six>=1.5 in c:\\users\\yann\\anaconda3\\envs\\hf_gpu_env\\lib\\site-packages (from python-dateutil>=2.8.2->pandas->datasets) (1.17.0)\n",
      "Using cached evaluate-0.4.4-py3-none-any.whl (84 kB)\n",
      "Installing collected packages: evaluate\n",
      "Successfully installed evaluate-0.4.4\n"
     ]
    }
   ],
   "source": [
    "!pip install transformers datasets evaluate scikit-learn\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "15ff3af6",
   "metadata": {},
   "outputs": [],
   "source": [
    "from datasets import Dataset, DatasetDict\n",
    "\n",
    "train_ds = Dataset.from_pandas(df_train)\n",
    "val_ds = Dataset.from_pandas(df_val)\n",
    "test_ds = Dataset.from_pandas(df_test)\n",
    "\n",
    "dataset = DatasetDict({\n",
    "    'train': train_ds,\n",
    "    'validation': val_ds,\n",
    "    'test': test_ds\n",
    "})\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "02459508",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Index(['id', 'text', 'example_very_unclear', 'admiration', 'amusement',\n",
       "       'anger', 'annoyance', 'approval', 'caring', 'confusion', 'curiosity',\n",
       "       'desire', 'disappointment', 'disapproval', 'disgust', 'embarrassment',\n",
       "       'excitement', 'fear', 'gratitude', 'grief', 'joy', 'love',\n",
       "       'nervousness', 'optimism', 'pride', 'realization', 'relief', 'remorse',\n",
       "       'sadness', 'surprise', 'neutral', 'text_length', 'num_labels'],\n",
       "      dtype='object')"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_train.columns"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f456c8ae",
   "metadata": {},
   "source": [
    "### Tokenisation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "4aed02d6",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "02c3993223cb457981a7bb77a4edba7e",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Map:   0%|          | 0/166242 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "8381e446ec1748a9914765edbaad62d4",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Map:   0%|          | 0/20780 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "e327b731e14c40acb09f08e7e40962a1",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Map:   0%|          | 0/20781 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "from transformers import AutoTokenizer\n",
    "\n",
    "tokenizer = AutoTokenizer.from_pretrained(\"roberta-base\")\n",
    "\n",
    "def tokenize_function(example):\n",
    "    return tokenizer(example[\"text\"], padding=\"max_length\", truncation=True, max_length=128)\n",
    "\n",
    "tokenized_dataset = dataset.map(tokenize_function, batched=True)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "d8798fcc",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "c671b07aa0fc423185f50e53977421c2",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Map:   0%|          | 0/166242 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "4c95f2a676184158a84ac83c62dce754",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Map:   0%|          | 0/20780 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "66e45942fd1746289cc580818fdec0c6",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Map:   0%|          | 0/20781 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Liste des colonnes d'émotions à extraire\n",
    "emotion_columns = [\n",
    "    'example_very_unclear', 'admiration', 'amusement', 'anger', 'annoyance', 'approval',\n",
    "    'caring', 'confusion', 'curiosity', 'desire', 'disappointment', 'disapproval',\n",
    "    'disgust', 'embarrassment', 'excitement', 'fear', 'gratitude', 'grief', 'joy',\n",
    "    'love', 'nervousness', 'optimism', 'pride', 'realization', 'relief', 'remorse',\n",
    "    'sadness', 'surprise', 'neutral'\n",
    "] \n",
    "\n",
    "def convert_labels_to_float(example):\n",
    "    labels = [float(example[col]) for col in emotion_columns]\n",
    "    example[\"labels\"] = labels\n",
    "    return example\n",
    "tokenized_dataset[\"train\"] = tokenized_dataset[\"train\"].map(convert_labels_to_float)\n",
    "tokenized_dataset[\"validation\"] = tokenized_dataset[\"validation\"].map(convert_labels_to_float)\n",
    "tokenized_dataset[\"test\"] = tokenized_dataset[\"test\"].map(convert_labels_to_float)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9b66bef7",
   "metadata": {},
   "source": [
    "### Format pour entraînement"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "49391036",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "5f040a8adfb14071bbf2338138b75e03",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Map:   0%|          | 0/166242 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "d3b4913be7b14d0babc6e53bc476d972",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Map:   0%|          | 0/20780 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "85ac2a317dc24676859bcbc8dda72fa9",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Map:   0%|          | 0/20781 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "def convert_labels(example):\n",
    "    example[\"labels\"] = [float(example[col]) for col in emotion_columns]\n",
    "    return example\n",
    "\n",
    "tokenized_dataset = tokenized_dataset.map(convert_labels)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "1e682706",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "dict_keys(['id', 'text', 'example_very_unclear', 'admiration', 'amusement', 'anger', 'annoyance', 'approval', 'caring', 'confusion', 'curiosity', 'desire', 'disappointment', 'disapproval', 'disgust', 'embarrassment', 'excitement', 'fear', 'gratitude', 'grief', 'joy', 'love', 'nervousness', 'optimism', 'pride', 'realization', 'relief', 'remorse', 'sadness', 'surprise', 'neutral', 'text_length', 'num_labels', '__index_level_0__', 'input_ids', 'attention_mask', 'labels'])\n"
     ]
    }
   ],
   "source": [
    "print(tokenized_dataset[\"train\"][0].keys())\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "309b81c9",
   "metadata": {},
   "outputs": [],
   "source": [
    "# retirer colonne inutlie\n",
    "tokenized_dataset = tokenized_dataset.remove_columns([\"text\", \"__index_level_0__\"] + list(emotion_columns))\n",
    "\n",
    "tokenized_dataset.set_format(\"torch\")\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "10a012e7",
   "metadata": {},
   "source": [
    "### Modèle + entraînement"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "cf5f244f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found existing installation: tensorflow 2.10.1\n",
      "Uninstalling tensorflow-2.10.1:\n",
      "  Successfully uninstalled tensorflow-2.10.1\n",
      "Found existing installation: keras 2.10.0\n",
      "Uninstalling keras-2.10.0:\n",
      "  Successfully uninstalled keras-2.10.0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING: Failed to remove contents in a temporary directory 'C:\\Users\\Yann\\anaconda3\\envs\\nlp_gpu_env\\Lib\\site-packages\\~ensorflow'.\n",
      "You can safely remove it manually.\n",
      "WARNING: Skipping tensorflow-cpu as it is not installed.\n",
      "WARNING: Skipping tensorflow-gpu as it is not installed.\n",
      "WARNING: Skipping tf-nightly as it is not installed.\n"
     ]
    }
   ],
   "source": [
    "!pip uninstall -y tensorflow tensorflow-cpu tensorflow-gpu tf-nightly keras"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "032220bc",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found existing installation: transformers 4.53.0\n",
      "Uninstalling transformers-4.53.0:\n",
      "  Successfully uninstalled transformers-4.53.0\n",
      "Collecting transformers==4.41.2\n",
      "  Downloading transformers-4.41.2-py3-none-any.whl.metadata (43 kB)\n",
      "Requirement already satisfied: filelock in c:\\users\\yann\\anaconda3\\envs\\nlp_gpu_env\\lib\\site-packages (from transformers==4.41.2) (3.18.0)\n",
      "Requirement already satisfied: huggingface-hub<1.0,>=0.23.0 in c:\\users\\yann\\anaconda3\\envs\\nlp_gpu_env\\lib\\site-packages (from transformers==4.41.2) (0.33.2)\n",
      "Requirement already satisfied: numpy>=1.17 in c:\\users\\yann\\anaconda3\\envs\\nlp_gpu_env\\lib\\site-packages (from transformers==4.41.2) (2.0.2)\n",
      "Requirement already satisfied: packaging>=20.0 in c:\\users\\yann\\anaconda3\\envs\\nlp_gpu_env\\lib\\site-packages (from transformers==4.41.2) (25.0)\n",
      "Requirement already satisfied: pyyaml>=5.1 in c:\\users\\yann\\anaconda3\\envs\\nlp_gpu_env\\lib\\site-packages (from transformers==4.41.2) (6.0.2)\n",
      "Requirement already satisfied: regex!=2019.12.17 in c:\\users\\yann\\anaconda3\\envs\\nlp_gpu_env\\lib\\site-packages (from transformers==4.41.2) (2024.11.6)\n",
      "Requirement already satisfied: requests in c:\\users\\yann\\anaconda3\\envs\\nlp_gpu_env\\lib\\site-packages (from transformers==4.41.2) (2.32.4)\n",
      "Collecting tokenizers<0.20,>=0.19 (from transformers==4.41.2)\n",
      "  Downloading tokenizers-0.19.1-cp39-none-win_amd64.whl.metadata (6.9 kB)\n",
      "Requirement already satisfied: safetensors>=0.4.1 in c:\\users\\yann\\anaconda3\\envs\\nlp_gpu_env\\lib\\site-packages (from transformers==4.41.2) (0.5.3)\n",
      "Requirement already satisfied: tqdm>=4.27 in c:\\users\\yann\\anaconda3\\envs\\nlp_gpu_env\\lib\\site-packages (from transformers==4.41.2) (4.67.1)\n",
      "Requirement already satisfied: fsspec>=2023.5.0 in c:\\users\\yann\\anaconda3\\envs\\nlp_gpu_env\\lib\\site-packages (from huggingface-hub<1.0,>=0.23.0->transformers==4.41.2) (2025.3.0)\n",
      "Requirement already satisfied: typing-extensions>=3.7.4.3 in c:\\users\\yann\\anaconda3\\envs\\nlp_gpu_env\\lib\\site-packages (from huggingface-hub<1.0,>=0.23.0->transformers==4.41.2) (4.14.0)\n",
      "Requirement already satisfied: colorama in c:\\users\\yann\\anaconda3\\envs\\nlp_gpu_env\\lib\\site-packages (from tqdm>=4.27->transformers==4.41.2) (0.4.6)\n",
      "Requirement already satisfied: charset_normalizer<4,>=2 in c:\\users\\yann\\anaconda3\\envs\\nlp_gpu_env\\lib\\site-packages (from requests->transformers==4.41.2) (3.4.2)\n",
      "Requirement already satisfied: idna<4,>=2.5 in c:\\users\\yann\\anaconda3\\envs\\nlp_gpu_env\\lib\\site-packages (from requests->transformers==4.41.2) (3.10)\n",
      "Requirement already satisfied: urllib3<3,>=1.21.1 in c:\\users\\yann\\anaconda3\\envs\\nlp_gpu_env\\lib\\site-packages (from requests->transformers==4.41.2) (2.5.0)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in c:\\users\\yann\\anaconda3\\envs\\nlp_gpu_env\\lib\\site-packages (from requests->transformers==4.41.2) (2025.6.15)\n",
      "Downloading transformers-4.41.2-py3-none-any.whl (9.1 MB)\n",
      "   ---------------------------------------- 0.0/9.1 MB ? eta -:--:--\n",
      "   -- ------------------------------------- 0.5/9.1 MB 3.4 MB/s eta 0:00:03\n",
      "   -------- ------------------------------- 1.8/9.1 MB 4.8 MB/s eta 0:00:02\n",
      "   -------------- ------------------------- 3.4/9.1 MB 5.8 MB/s eta 0:00:01\n",
      "   -------------------- ------------------- 4.7/9.1 MB 6.1 MB/s eta 0:00:01\n",
      "   --------------------------- ------------ 6.3/9.1 MB 6.3 MB/s eta 0:00:01\n",
      "   ---------------------------------- ----- 7.9/9.1 MB 6.4 MB/s eta 0:00:01\n",
      "   ---------------------------------------  8.9/9.1 MB 6.5 MB/s eta 0:00:01\n",
      "   ---------------------------------------- 9.1/9.1 MB 6.1 MB/s eta 0:00:00\n",
      "Downloading tokenizers-0.19.1-cp39-none-win_amd64.whl (2.2 MB)\n",
      "   ---------------------------------------- 0.0/2.2 MB ? eta -:--:--\n",
      "   ----------------------- ---------------- 1.3/2.2 MB 6.7 MB/s eta 0:00:01\n",
      "   ---------------------------------------- 2.2/2.2 MB 5.7 MB/s eta 0:00:00\n",
      "Installing collected packages: tokenizers, transformers\n",
      "\n",
      "  Attempting uninstall: tokenizers\n",
      "\n",
      "    Found existing installation: tokenizers 0.21.2\n",
      "\n",
      "    Uninstalling tokenizers-0.21.2:\n",
      "\n",
      "      Successfully uninstalled tokenizers-0.21.2\n",
      "\n",
      "   ---------------------------------------- 0/2 [tokenizers]\n",
      "   ---------------------------------------- 0/2 [tokenizers]\n",
      "   ---------------------------------------- 0/2 [tokenizers]\n",
      "   ---------------------------------------- 0/2 [tokenizers]\n",
      "   ---------------------------------------- 0/2 [tokenizers]\n",
      "   ---------------------------------------- 0/2 [tokenizers]\n",
      "   ---------------------------------------- 0/2 [tokenizers]\n",
      "   ---------------------------------------- 0/2 [tokenizers]\n",
      "   ---------------------------------------- 0/2 [tokenizers]\n",
      "   ---------------------------------------- 0/2 [tokenizers]\n",
      "   ---------------------------------------- 0/2 [tokenizers]\n",
      "   ---------------------------------------- 0/2 [tokenizers]\n",
      "   ---------------------------------------- 0/2 [tokenizers]\n",
      "   ---------------------------------------- 0/2 [tokenizers]\n",
      "   ---------------------------------------- 0/2 [tokenizers]\n",
      "   ---------------------------------------- 0/2 [tokenizers]\n",
      "   ---------------------------------------- 0/2 [tokenizers]\n",
      "   ---------------------------------------- 0/2 [tokenizers]\n",
      "   -------------------- ------------------- 1/2 [transformers]\n",
      "   -------------------- ------------------- 1/2 [transformers]\n",
      "   -------------------- ------------------- 1/2 [transformers]\n",
      "   -------------------- ------------------- 1/2 [transformers]\n",
      "   -------------------- ------------------- 1/2 [transformers]\n",
      "   -------------------- ------------------- 1/2 [transformers]\n",
      "   -------------------- ------------------- 1/2 [transformers]\n",
      "   -------------------- ------------------- 1/2 [transformers]\n",
      "   -------------------- ------------------- 1/2 [transformers]\n",
      "   -------------------- ------------------- 1/2 [transformers]\n",
      "   -------------------- ------------------- 1/2 [transformers]\n",
      "   -------------------- ------------------- 1/2 [transformers]\n",
      "   -------------------- ------------------- 1/2 [transformers]\n",
      "   -------------------- ------------------- 1/2 [transformers]\n",
      "   -------------------- ------------------- 1/2 [transformers]\n",
      "   -------------------- ------------------- 1/2 [transformers]\n",
      "   -------------------- ------------------- 1/2 [transformers]\n",
      "   -------------------- ------------------- 1/2 [transformers]\n",
      "   -------------------- ------------------- 1/2 [transformers]\n",
      "   -------------------- ------------------- 1/2 [transformers]\n",
      "   -------------------- ------------------- 1/2 [transformers]\n",
      "   -------------------- ------------------- 1/2 [transformers]\n",
      "   -------------------- ------------------- 1/2 [transformers]\n",
      "   -------------------- ------------------- 1/2 [transformers]\n",
      "   -------------------- ------------------- 1/2 [transformers]\n",
      "   -------------------- ------------------- 1/2 [transformers]\n",
      "   -------------------- ------------------- 1/2 [transformers]\n",
      "   -------------------- ------------------- 1/2 [transformers]\n",
      "   -------------------- ------------------- 1/2 [transformers]\n",
      "   -------------------- ------------------- 1/2 [transformers]\n",
      "   -------------------- ------------------- 1/2 [transformers]\n",
      "   -------------------- ------------------- 1/2 [transformers]\n",
      "   -------------------- ------------------- 1/2 [transformers]\n",
      "   -------------------- ------------------- 1/2 [transformers]\n",
      "   -------------------- ------------------- 1/2 [transformers]\n",
      "   -------------------- ------------------- 1/2 [transformers]\n",
      "   -------------------- ------------------- 1/2 [transformers]\n",
      "   -------------------- ------------------- 1/2 [transformers]\n",
      "   -------------------- ------------------- 1/2 [transformers]\n",
      "   -------------------- ------------------- 1/2 [transformers]\n",
      "   -------------------- ------------------- 1/2 [transformers]\n",
      "   -------------------- ------------------- 1/2 [transformers]\n",
      "   -------------------- ------------------- 1/2 [transformers]\n",
      "   -------------------- ------------------- 1/2 [transformers]\n",
      "   -------------------- ------------------- 1/2 [transformers]\n",
      "   -------------------- ------------------- 1/2 [transformers]\n",
      "   -------------------- ------------------- 1/2 [transformers]\n",
      "   -------------------- ------------------- 1/2 [transformers]\n",
      "   -------------------- ------------------- 1/2 [transformers]\n",
      "   -------------------- ------------------- 1/2 [transformers]\n",
      "   -------------------- ------------------- 1/2 [transformers]\n",
      "   -------------------- ------------------- 1/2 [transformers]\n",
      "   -------------------- ------------------- 1/2 [transformers]\n",
      "   -------------------- ------------------- 1/2 [transformers]\n",
      "   -------------------- ------------------- 1/2 [transformers]\n",
      "   -------------------- ------------------- 1/2 [transformers]\n",
      "   -------------------- ------------------- 1/2 [transformers]\n",
      "   -------------------- ------------------- 1/2 [transformers]\n",
      "   -------------------- ------------------- 1/2 [transformers]\n",
      "   -------------------- ------------------- 1/2 [transformers]\n",
      "   -------------------- ------------------- 1/2 [transformers]\n",
      "   -------------------- ------------------- 1/2 [transformers]\n",
      "   -------------------- ------------------- 1/2 [transformers]\n",
      "   -------------------- ------------------- 1/2 [transformers]\n",
      "   -------------------- ------------------- 1/2 [transformers]\n",
      "   -------------------- ------------------- 1/2 [transformers]\n",
      "   -------------------- ------------------- 1/2 [transformers]\n",
      "   -------------------- ------------------- 1/2 [transformers]\n",
      "   -------------------- ------------------- 1/2 [transformers]\n",
      "   -------------------- ------------------- 1/2 [transformers]\n",
      "   -------------------- ------------------- 1/2 [transformers]\n",
      "   -------------------- ------------------- 1/2 [transformers]\n",
      "   -------------------- ------------------- 1/2 [transformers]\n",
      "   -------------------- ------------------- 1/2 [transformers]\n",
      "   -------------------- ------------------- 1/2 [transformers]\n",
      "   -------------------- ------------------- 1/2 [transformers]\n",
      "   -------------------- ------------------- 1/2 [transformers]\n",
      "   -------------------- ------------------- 1/2 [transformers]\n",
      "   -------------------- ------------------- 1/2 [transformers]\n",
      "   -------------------- ------------------- 1/2 [transformers]\n",
      "   -------------------- ------------------- 1/2 [transformers]\n",
      "   -------------------- ------------------- 1/2 [transformers]\n",
      "   -------------------- ------------------- 1/2 [transformers]\n",
      "   -------------------- ------------------- 1/2 [transformers]\n",
      "   -------------------- ------------------- 1/2 [transformers]\n",
      "   -------------------- ------------------- 1/2 [transformers]\n",
      "   -------------------- ------------------- 1/2 [transformers]\n",
      "   -------------------- ------------------- 1/2 [transformers]\n",
      "   -------------------- ------------------- 1/2 [transformers]\n",
      "   -------------------- ------------------- 1/2 [transformers]\n",
      "   -------------------- ------------------- 1/2 [transformers]\n",
      "   -------------------- ------------------- 1/2 [transformers]\n",
      "   -------------------- ------------------- 1/2 [transformers]\n",
      "   -------------------- ------------------- 1/2 [transformers]\n",
      "   -------------------- ------------------- 1/2 [transformers]\n",
      "   -------------------- ------------------- 1/2 [transformers]\n",
      "   -------------------- ------------------- 1/2 [transformers]\n",
      "   -------------------- ------------------- 1/2 [transformers]\n",
      "   ---------------------------------------- 2/2 [transformers]\n",
      "\n",
      "Successfully installed tokenizers-0.19.1 transformers-4.41.2\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  WARNING: Failed to remove contents in a temporary directory 'C:\\Users\\Yann\\anaconda3\\envs\\nlp_gpu_env\\Lib\\site-packages\\~okenizers'.\n",
      "  You can safely remove it manually.\n"
     ]
    }
   ],
   "source": [
    "!pip uninstall -y transformers\n",
    "!pip install transformers==4.41.2\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "edf7e99e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "4.53.0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of RobertaForSequenceClassification were not initialized from the model checkpoint at roberta-base and are newly initialized: ['classifier.dense.bias', 'classifier.dense.weight', 'classifier.out_proj.bias', 'classifier.out_proj.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    }
   ],
   "source": [
    "\n",
    "\n",
    "import transformers\n",
    "print(transformers.__version__)\n",
    "from transformers import RobertaForSequenceClassification\n",
    "\n",
    "model = RobertaForSequenceClassification.from_pretrained(\n",
    "    \"roberta-base\",\n",
    "    num_labels=29,\n",
    "    problem_type=\"multi_label_classification\"\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ba13cca4",
   "metadata": {},
   "source": [
    "### Entraînement avec Trainer\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "54f0892d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: transformers in c:\\users\\yann\\anaconda3\\envs\\hf_gpu_env\\lib\\site-packages (4.41.2)\n",
      "Collecting transformers\n",
      "  Using cached transformers-4.53.0-py3-none-any.whl.metadata (39 kB)\n",
      "Requirement already satisfied: filelock in c:\\users\\yann\\anaconda3\\envs\\hf_gpu_env\\lib\\site-packages (from transformers) (3.13.1)\n",
      "Requirement already satisfied: huggingface-hub<1.0,>=0.30.0 in c:\\users\\yann\\anaconda3\\envs\\hf_gpu_env\\lib\\site-packages (from transformers) (0.33.2)\n",
      "Requirement already satisfied: numpy>=1.17 in c:\\users\\yann\\anaconda3\\envs\\hf_gpu_env\\lib\\site-packages (from transformers) (2.1.2)\n",
      "Requirement already satisfied: packaging>=20.0 in c:\\users\\yann\\anaconda3\\envs\\hf_gpu_env\\lib\\site-packages (from transformers) (25.0)\n",
      "Requirement already satisfied: pyyaml>=5.1 in c:\\users\\yann\\anaconda3\\envs\\hf_gpu_env\\lib\\site-packages (from transformers) (6.0.2)\n",
      "Requirement already satisfied: regex!=2019.12.17 in c:\\users\\yann\\anaconda3\\envs\\hf_gpu_env\\lib\\site-packages (from transformers) (2024.11.6)\n",
      "Requirement already satisfied: requests in c:\\users\\yann\\anaconda3\\envs\\hf_gpu_env\\lib\\site-packages (from transformers) (2.32.4)\n",
      "Collecting tokenizers<0.22,>=0.21 (from transformers)\n",
      "  Using cached tokenizers-0.21.2-cp39-abi3-win_amd64.whl.metadata (6.9 kB)\n",
      "Requirement already satisfied: safetensors>=0.4.3 in c:\\users\\yann\\anaconda3\\envs\\hf_gpu_env\\lib\\site-packages (from transformers) (0.5.3)\n",
      "Requirement already satisfied: tqdm>=4.27 in c:\\users\\yann\\anaconda3\\envs\\hf_gpu_env\\lib\\site-packages (from transformers) (4.67.1)\n",
      "Requirement already satisfied: fsspec>=2023.5.0 in c:\\users\\yann\\anaconda3\\envs\\hf_gpu_env\\lib\\site-packages (from huggingface-hub<1.0,>=0.30.0->transformers) (2024.6.1)\n",
      "Requirement already satisfied: typing-extensions>=3.7.4.3 in c:\\users\\yann\\anaconda3\\envs\\hf_gpu_env\\lib\\site-packages (from huggingface-hub<1.0,>=0.30.0->transformers) (4.12.2)\n",
      "Requirement already satisfied: colorama in c:\\users\\yann\\anaconda3\\envs\\hf_gpu_env\\lib\\site-packages (from tqdm>=4.27->transformers) (0.4.6)\n",
      "Requirement already satisfied: charset_normalizer<4,>=2 in c:\\users\\yann\\anaconda3\\envs\\hf_gpu_env\\lib\\site-packages (from requests->transformers) (3.4.2)\n",
      "Requirement already satisfied: idna<4,>=2.5 in c:\\users\\yann\\anaconda3\\envs\\hf_gpu_env\\lib\\site-packages (from requests->transformers) (3.10)\n",
      "Requirement already satisfied: urllib3<3,>=1.21.1 in c:\\users\\yann\\anaconda3\\envs\\hf_gpu_env\\lib\\site-packages (from requests->transformers) (2.5.0)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in c:\\users\\yann\\anaconda3\\envs\\hf_gpu_env\\lib\\site-packages (from requests->transformers) (2025.6.15)\n",
      "Using cached transformers-4.53.0-py3-none-any.whl (10.8 MB)\n",
      "Using cached tokenizers-0.21.2-cp39-abi3-win_amd64.whl (2.5 MB)\n",
      "Installing collected packages: tokenizers, transformers\n",
      "\n",
      "  Attempting uninstall: tokenizers\n",
      "\n",
      "    Found existing installation: tokenizers 0.19.1\n",
      "\n",
      "    Uninstalling tokenizers-0.19.1:\n",
      "\n",
      "      Successfully uninstalled tokenizers-0.19.1\n",
      "\n",
      "   ---------------------------------------- 0/2 [tokenizers]\n",
      "   ---------------------------------------- 0/2 [tokenizers]\n",
      "   ---------------------------------------- 0/2 [tokenizers]\n",
      "   ---------------------------------------- 0/2 [tokenizers]\n",
      "   ---------------------------------------- 0/2 [tokenizers]\n",
      "   ---------------------------------------- 0/2 [tokenizers]\n",
      "   ---------------------------------------- 0/2 [tokenizers]\n",
      "   ---------------------------------------- 0/2 [tokenizers]\n",
      "   ---------------------------------------- 0/2 [tokenizers]\n",
      "   ---------------------------------------- 0/2 [tokenizers]\n",
      "   ---------------------------------------- 0/2 [tokenizers]\n",
      "   ---------------------------------------- 0/2 [tokenizers]\n",
      "   ---------------------------------------- 0/2 [tokenizers]\n",
      "   ---------------------------------------- 0/2 [tokenizers]\n",
      "   ---------------------------------------- 0/2 [tokenizers]\n",
      "   ---------------------------------------- 0/2 [tokenizers]\n",
      "   ---------------------------------------- 0/2 [tokenizers]\n",
      "   ---------------------------------------- 0/2 [tokenizers]\n",
      "   ---------------------------------------- 0/2 [tokenizers]\n",
      "   ---------------------------------------- 0/2 [tokenizers]\n",
      "  Attempting uninstall: transformers\n",
      "   ---------------------------------------- 0/2 [tokenizers]\n",
      "    Found existing installation: transformers 4.41.2\n",
      "   ---------------------------------------- 0/2 [tokenizers]\n",
      "   -------------------- ------------------- 1/2 [transformers]\n",
      "    Uninstalling transformers-4.41.2:\n",
      "   -------------------- ------------------- 1/2 [transformers]\n",
      "   -------------------- ------------------- 1/2 [transformers]\n",
      "      Successfully uninstalled transformers-4.41.2\n",
      "   -------------------- ------------------- 1/2 [transformers]\n",
      "   -------------------- ------------------- 1/2 [transformers]\n",
      "   -------------------- ------------------- 1/2 [transformers]\n",
      "   -------------------- ------------------- 1/2 [transformers]\n",
      "   -------------------- ------------------- 1/2 [transformers]\n",
      "   -------------------- ------------------- 1/2 [transformers]\n",
      "   -------------------- ------------------- 1/2 [transformers]\n",
      "   -------------------- ------------------- 1/2 [transformers]\n",
      "   -------------------- ------------------- 1/2 [transformers]\n",
      "   -------------------- ------------------- 1/2 [transformers]\n",
      "   -------------------- ------------------- 1/2 [transformers]\n",
      "   -------------------- ------------------- 1/2 [transformers]\n",
      "   -------------------- ------------------- 1/2 [transformers]\n",
      "   -------------------- ------------------- 1/2 [transformers]\n",
      "   -------------------- ------------------- 1/2 [transformers]\n",
      "   -------------------- ------------------- 1/2 [transformers]\n",
      "   -------------------- ------------------- 1/2 [transformers]\n",
      "   -------------------- ------------------- 1/2 [transformers]\n",
      "   -------------------- ------------------- 1/2 [transformers]\n",
      "   -------------------- ------------------- 1/2 [transformers]\n",
      "   -------------------- ------------------- 1/2 [transformers]\n",
      "   -------------------- ------------------- 1/2 [transformers]\n",
      "   -------------------- ------------------- 1/2 [transformers]\n",
      "   -------------------- ------------------- 1/2 [transformers]\n",
      "   -------------------- ------------------- 1/2 [transformers]\n",
      "   -------------------- ------------------- 1/2 [transformers]\n",
      "   -------------------- ------------------- 1/2 [transformers]\n",
      "   -------------------- ------------------- 1/2 [transformers]\n",
      "   -------------------- ------------------- 1/2 [transformers]\n",
      "   -------------------- ------------------- 1/2 [transformers]\n",
      "   -------------------- ------------------- 1/2 [transformers]\n",
      "   -------------------- ------------------- 1/2 [transformers]\n",
      "   -------------------- ------------------- 1/2 [transformers]\n",
      "   -------------------- ------------------- 1/2 [transformers]\n",
      "   -------------------- ------------------- 1/2 [transformers]\n",
      "   -------------------- ------------------- 1/2 [transformers]\n",
      "   -------------------- ------------------- 1/2 [transformers]\n",
      "   -------------------- ------------------- 1/2 [transformers]\n",
      "   -------------------- ------------------- 1/2 [transformers]\n",
      "   -------------------- ------------------- 1/2 [transformers]\n",
      "   -------------------- ------------------- 1/2 [transformers]\n",
      "   -------------------- ------------------- 1/2 [transformers]\n",
      "   -------------------- ------------------- 1/2 [transformers]\n",
      "   -------------------- ------------------- 1/2 [transformers]\n",
      "   -------------------- ------------------- 1/2 [transformers]\n",
      "   -------------------- ------------------- 1/2 [transformers]\n",
      "   -------------------- ------------------- 1/2 [transformers]\n",
      "   -------------------- ------------------- 1/2 [transformers]\n",
      "   -------------------- ------------------- 1/2 [transformers]\n",
      "   -------------------- ------------------- 1/2 [transformers]\n",
      "   -------------------- ------------------- 1/2 [transformers]\n",
      "   -------------------- ------------------- 1/2 [transformers]\n",
      "   -------------------- ------------------- 1/2 [transformers]\n",
      "   -------------------- ------------------- 1/2 [transformers]\n",
      "   -------------------- ------------------- 1/2 [transformers]\n",
      "   -------------------- ------------------- 1/2 [transformers]\n",
      "   -------------------- ------------------- 1/2 [transformers]\n",
      "   -------------------- ------------------- 1/2 [transformers]\n",
      "   -------------------- ------------------- 1/2 [transformers]\n",
      "   -------------------- ------------------- 1/2 [transformers]\n",
      "   -------------------- ------------------- 1/2 [transformers]\n",
      "   -------------------- ------------------- 1/2 [transformers]\n",
      "   -------------------- ------------------- 1/2 [transformers]\n",
      "   -------------------- ------------------- 1/2 [transformers]\n",
      "   -------------------- ------------------- 1/2 [transformers]\n",
      "   -------------------- ------------------- 1/2 [transformers]\n",
      "   -------------------- ------------------- 1/2 [transformers]\n",
      "   -------------------- ------------------- 1/2 [transformers]\n",
      "   -------------------- ------------------- 1/2 [transformers]\n",
      "   -------------------- ------------------- 1/2 [transformers]\n",
      "   -------------------- ------------------- 1/2 [transformers]\n",
      "   -------------------- ------------------- 1/2 [transformers]\n",
      "   -------------------- ------------------- 1/2 [transformers]\n",
      "   -------------------- ------------------- 1/2 [transformers]\n",
      "   -------------------- ------------------- 1/2 [transformers]\n",
      "   -------------------- ------------------- 1/2 [transformers]\n",
      "   -------------------- ------------------- 1/2 [transformers]\n",
      "   -------------------- ------------------- 1/2 [transformers]\n",
      "   -------------------- ------------------- 1/2 [transformers]\n",
      "   -------------------- ------------------- 1/2 [transformers]\n",
      "   -------------------- ------------------- 1/2 [transformers]\n",
      "   -------------------- ------------------- 1/2 [transformers]\n",
      "   -------------------- ------------------- 1/2 [transformers]\n",
      "   -------------------- ------------------- 1/2 [transformers]\n",
      "   -------------------- ------------------- 1/2 [transformers]\n",
      "   -------------------- ------------------- 1/2 [transformers]\n",
      "   -------------------- ------------------- 1/2 [transformers]\n",
      "   -------------------- ------------------- 1/2 [transformers]\n",
      "   -------------------- ------------------- 1/2 [transformers]\n",
      "   -------------------- ------------------- 1/2 [transformers]\n",
      "   -------------------- ------------------- 1/2 [transformers]\n",
      "   -------------------- ------------------- 1/2 [transformers]\n",
      "   -------------------- ------------------- 1/2 [transformers]\n",
      "   -------------------- ------------------- 1/2 [transformers]\n",
      "   -------------------- ------------------- 1/2 [transformers]\n",
      "   -------------------- ------------------- 1/2 [transformers]\n",
      "   -------------------- ------------------- 1/2 [transformers]\n",
      "   -------------------- ------------------- 1/2 [transformers]\n",
      "   -------------------- ------------------- 1/2 [transformers]\n",
      "   -------------------- ------------------- 1/2 [transformers]\n",
      "   -------------------- ------------------- 1/2 [transformers]\n",
      "   -------------------- ------------------- 1/2 [transformers]\n",
      "   -------------------- ------------------- 1/2 [transformers]\n",
      "   -------------------- ------------------- 1/2 [transformers]\n",
      "   -------------------- ------------------- 1/2 [transformers]\n",
      "   -------------------- ------------------- 1/2 [transformers]\n",
      "   -------------------- ------------------- 1/2 [transformers]\n",
      "   -------------------- ------------------- 1/2 [transformers]\n",
      "   -------------------- ------------------- 1/2 [transformers]\n",
      "   -------------------- ------------------- 1/2 [transformers]\n",
      "   -------------------- ------------------- 1/2 [transformers]\n",
      "   -------------------- ------------------- 1/2 [transformers]\n",
      "   -------------------- ------------------- 1/2 [transformers]\n",
      "   -------------------- ------------------- 1/2 [transformers]\n",
      "   -------------------- ------------------- 1/2 [transformers]\n",
      "   -------------------- ------------------- 1/2 [transformers]\n",
      "   -------------------- ------------------- 1/2 [transformers]\n",
      "   -------------------- ------------------- 1/2 [transformers]\n",
      "   -------------------- ------------------- 1/2 [transformers]\n",
      "   -------------------- ------------------- 1/2 [transformers]\n",
      "   -------------------- ------------------- 1/2 [transformers]\n",
      "   -------------------- ------------------- 1/2 [transformers]\n",
      "   -------------------- ------------------- 1/2 [transformers]\n",
      "   -------------------- ------------------- 1/2 [transformers]\n",
      "   -------------------- ------------------- 1/2 [transformers]\n",
      "   -------------------- ------------------- 1/2 [transformers]\n",
      "   -------------------- ------------------- 1/2 [transformers]\n",
      "   -------------------- ------------------- 1/2 [transformers]\n",
      "   -------------------- ------------------- 1/2 [transformers]\n",
      "   -------------------- ------------------- 1/2 [transformers]\n",
      "   -------------------- ------------------- 1/2 [transformers]\n",
      "   -------------------- ------------------- 1/2 [transformers]\n",
      "   -------------------- ------------------- 1/2 [transformers]\n",
      "   -------------------- ------------------- 1/2 [transformers]\n",
      "   ---------------------------------------- 2/2 [transformers]\n",
      "\n",
      "Successfully installed tokenizers-0.21.2 transformers-4.53.0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  WARNING: Failed to remove contents in a temporary directory 'C:\\Users\\Yann\\anaconda3\\envs\\hf_gpu_env\\Lib\\site-packages\\~okenizers'.\n",
      "  You can safely remove it manually.\n"
     ]
    }
   ],
   "source": [
    "!pip install --upgrade transformers\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "01da5dd2",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "4.41.2\n"
     ]
    }
   ],
   "source": [
    "import transformers\n",
    "print(transformers.__version__)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "id": "2f7bf030",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: transformers[torch] in c:\\users\\yann\\anaconda3\\envs\\hf_gpu_env\\lib\\site-packages (4.53.0)\n",
      "Requirement already satisfied: filelock in c:\\users\\yann\\anaconda3\\envs\\hf_gpu_env\\lib\\site-packages (from transformers[torch]) (3.13.1)\n",
      "Requirement already satisfied: huggingface-hub<1.0,>=0.30.0 in c:\\users\\yann\\anaconda3\\envs\\hf_gpu_env\\lib\\site-packages (from transformers[torch]) (0.33.2)\n",
      "Requirement already satisfied: numpy>=1.17 in c:\\users\\yann\\anaconda3\\envs\\hf_gpu_env\\lib\\site-packages (from transformers[torch]) (2.1.2)\n",
      "Requirement already satisfied: packaging>=20.0 in c:\\users\\yann\\anaconda3\\envs\\hf_gpu_env\\lib\\site-packages (from transformers[torch]) (25.0)\n",
      "Requirement already satisfied: pyyaml>=5.1 in c:\\users\\yann\\anaconda3\\envs\\hf_gpu_env\\lib\\site-packages (from transformers[torch]) (6.0.2)\n",
      "Requirement already satisfied: regex!=2019.12.17 in c:\\users\\yann\\anaconda3\\envs\\hf_gpu_env\\lib\\site-packages (from transformers[torch]) (2024.11.6)\n",
      "Requirement already satisfied: requests in c:\\users\\yann\\anaconda3\\envs\\hf_gpu_env\\lib\\site-packages (from transformers[torch]) (2.32.4)\n",
      "Requirement already satisfied: tokenizers<0.22,>=0.21 in c:\\users\\yann\\anaconda3\\envs\\hf_gpu_env\\lib\\site-packages (from transformers[torch]) (0.21.2)\n",
      "Requirement already satisfied: safetensors>=0.4.3 in c:\\users\\yann\\anaconda3\\envs\\hf_gpu_env\\lib\\site-packages (from transformers[torch]) (0.5.3)\n",
      "Requirement already satisfied: tqdm>=4.27 in c:\\users\\yann\\anaconda3\\envs\\hf_gpu_env\\lib\\site-packages (from transformers[torch]) (4.67.1)\n",
      "Requirement already satisfied: torch>=2.1 in c:\\users\\yann\\anaconda3\\envs\\hf_gpu_env\\lib\\site-packages (from transformers[torch]) (2.5.1+cu121)\n",
      "Requirement already satisfied: accelerate>=0.26.0 in c:\\users\\yann\\anaconda3\\envs\\hf_gpu_env\\lib\\site-packages (from transformers[torch]) (1.8.1)\n",
      "Requirement already satisfied: fsspec>=2023.5.0 in c:\\users\\yann\\anaconda3\\envs\\hf_gpu_env\\lib\\site-packages (from huggingface-hub<1.0,>=0.30.0->transformers[torch]) (2024.6.1)\n",
      "Requirement already satisfied: typing-extensions>=3.7.4.3 in c:\\users\\yann\\anaconda3\\envs\\hf_gpu_env\\lib\\site-packages (from huggingface-hub<1.0,>=0.30.0->transformers[torch]) (4.12.2)\n",
      "Requirement already satisfied: psutil in c:\\users\\yann\\anaconda3\\envs\\hf_gpu_env\\lib\\site-packages (from accelerate>=0.26.0->transformers[torch]) (7.0.0)\n",
      "Requirement already satisfied: networkx in c:\\users\\yann\\anaconda3\\envs\\hf_gpu_env\\lib\\site-packages (from torch>=2.1->transformers[torch]) (3.3)\n",
      "Requirement already satisfied: jinja2 in c:\\users\\yann\\anaconda3\\envs\\hf_gpu_env\\lib\\site-packages (from torch>=2.1->transformers[torch]) (3.1.4)\n",
      "Requirement already satisfied: sympy==1.13.1 in c:\\users\\yann\\anaconda3\\envs\\hf_gpu_env\\lib\\site-packages (from torch>=2.1->transformers[torch]) (1.13.1)\n",
      "Requirement already satisfied: mpmath<1.4,>=1.1.0 in c:\\users\\yann\\anaconda3\\envs\\hf_gpu_env\\lib\\site-packages (from sympy==1.13.1->torch>=2.1->transformers[torch]) (1.3.0)\n",
      "Requirement already satisfied: colorama in c:\\users\\yann\\anaconda3\\envs\\hf_gpu_env\\lib\\site-packages (from tqdm>=4.27->transformers[torch]) (0.4.6)\n",
      "Requirement already satisfied: MarkupSafe>=2.0 in c:\\users\\yann\\anaconda3\\envs\\hf_gpu_env\\lib\\site-packages (from jinja2->torch>=2.1->transformers[torch]) (2.1.5)\n",
      "Requirement already satisfied: charset_normalizer<4,>=2 in c:\\users\\yann\\anaconda3\\envs\\hf_gpu_env\\lib\\site-packages (from requests->transformers[torch]) (3.4.2)\n",
      "Requirement already satisfied: idna<4,>=2.5 in c:\\users\\yann\\anaconda3\\envs\\hf_gpu_env\\lib\\site-packages (from requests->transformers[torch]) (3.10)\n",
      "Requirement already satisfied: urllib3<3,>=1.21.1 in c:\\users\\yann\\anaconda3\\envs\\hf_gpu_env\\lib\\site-packages (from requests->transformers[torch]) (2.5.0)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in c:\\users\\yann\\anaconda3\\envs\\hf_gpu_env\\lib\\site-packages (from requests->transformers[torch]) (2025.6.15)\n"
     ]
    }
   ],
   "source": [
    "!pip install accelerate>=0.26.0\n",
    "!pip install transformers[torch]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "baf587c3",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "dict_keys(['id', 'text_length', 'num_labels', 'input_ids', 'attention_mask', 'labels'])"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tokenized_dataset[\"train\"][0].keys()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ec36494a",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Yann\\AppData\\Local\\Temp\\ipykernel_29532\\3666918694.py:39: FutureWarning: `tokenizer` is deprecated and will be removed in version 5.0.0 for `Trainer.__init__`. Use `processing_class` instead.\n",
      "  trainer = Trainer(\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='742' max='31173' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [  742/31173 28:11 < 19:19:15, 0.44 it/s, Epoch 0.07/3]\n",
       "    </div>\n",
       "    <table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       " <tr style=\"text-align: left;\">\n",
       "      <th>Epoch</th>\n",
       "      <th>Training Loss</th>\n",
       "      <th>Validation Loss</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "  </tbody>\n",
       "</table><p>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[31m---------------------------------------------------------------------------\u001b[39m",
      "\u001b[31mKeyboardInterrupt\u001b[39m                         Traceback (most recent call last)",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[50]\u001b[39m\u001b[32m, line 48\u001b[39m\n\u001b[32m     24\u001b[39m training_args = TrainingArguments(\n\u001b[32m     25\u001b[39m     output_dir=\u001b[33m\"\u001b[39m\u001b[33m./results\u001b[39m\u001b[33m\"\u001b[39m,\n\u001b[32m     26\u001b[39m     eval_strategy=IntervalStrategy.EPOCH,\n\u001b[32m   (...)\u001b[39m\u001b[32m     36\u001b[39m     metric_for_best_model=\u001b[33m\"\u001b[39m\u001b[33mf1_micro\u001b[39m\u001b[33m\"\u001b[39m\n\u001b[32m     37\u001b[39m )\n\u001b[32m     39\u001b[39m trainer = Trainer(\n\u001b[32m     40\u001b[39m     model=model,\n\u001b[32m     41\u001b[39m     args=training_args,\n\u001b[32m   (...)\u001b[39m\u001b[32m     45\u001b[39m     compute_metrics=compute_metrics\n\u001b[32m     46\u001b[39m )\n\u001b[32m---> \u001b[39m\u001b[32m48\u001b[39m \u001b[43mtrainer\u001b[49m\u001b[43m.\u001b[49m\u001b[43mtrain\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[36mFile \u001b[39m\u001b[32mc:\\Users\\Yann\\Desktop\\DEV\\School\\ml_m1\\NLP\\CustomGPT\\scraper_env\\Lib\\site-packages\\transformers\\trainer.py:2207\u001b[39m, in \u001b[36mTrainer.train\u001b[39m\u001b[34m(self, resume_from_checkpoint, trial, ignore_keys_for_eval, **kwargs)\u001b[39m\n\u001b[32m   2205\u001b[39m         hf_hub_utils.enable_progress_bars()\n\u001b[32m   2206\u001b[39m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[32m-> \u001b[39m\u001b[32m2207\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43minner_training_loop\u001b[49m\u001b[43m(\u001b[49m\n\u001b[32m   2208\u001b[39m \u001b[43m        \u001b[49m\u001b[43margs\u001b[49m\u001b[43m=\u001b[49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   2209\u001b[39m \u001b[43m        \u001b[49m\u001b[43mresume_from_checkpoint\u001b[49m\u001b[43m=\u001b[49m\u001b[43mresume_from_checkpoint\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   2210\u001b[39m \u001b[43m        \u001b[49m\u001b[43mtrial\u001b[49m\u001b[43m=\u001b[49m\u001b[43mtrial\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   2211\u001b[39m \u001b[43m        \u001b[49m\u001b[43mignore_keys_for_eval\u001b[49m\u001b[43m=\u001b[49m\u001b[43mignore_keys_for_eval\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   2212\u001b[39m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[36mFile \u001b[39m\u001b[32mc:\\Users\\Yann\\Desktop\\DEV\\School\\ml_m1\\NLP\\CustomGPT\\scraper_env\\Lib\\site-packages\\transformers\\trainer.py:2549\u001b[39m, in \u001b[36mTrainer._inner_training_loop\u001b[39m\u001b[34m(self, batch_size, args, resume_from_checkpoint, trial, ignore_keys_for_eval)\u001b[39m\n\u001b[32m   2542\u001b[39m context = (\n\u001b[32m   2543\u001b[39m     functools.partial(\u001b[38;5;28mself\u001b[39m.accelerator.no_sync, model=model)\n\u001b[32m   2544\u001b[39m     \u001b[38;5;28;01mif\u001b[39;00m i != \u001b[38;5;28mlen\u001b[39m(batch_samples) - \u001b[32m1\u001b[39m\n\u001b[32m   2545\u001b[39m     \u001b[38;5;129;01mand\u001b[39;00m \u001b[38;5;28mself\u001b[39m.accelerator.distributed_type != DistributedType.DEEPSPEED\n\u001b[32m   2546\u001b[39m     \u001b[38;5;28;01melse\u001b[39;00m contextlib.nullcontext\n\u001b[32m   2547\u001b[39m )\n\u001b[32m   2548\u001b[39m \u001b[38;5;28;01mwith\u001b[39;00m context():\n\u001b[32m-> \u001b[39m\u001b[32m2549\u001b[39m     tr_loss_step = \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43mtraining_step\u001b[49m\u001b[43m(\u001b[49m\u001b[43mmodel\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43minputs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mnum_items_in_batch\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m   2551\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m (\n\u001b[32m   2552\u001b[39m     args.logging_nan_inf_filter\n\u001b[32m   2553\u001b[39m     \u001b[38;5;129;01mand\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m is_torch_xla_available()\n\u001b[32m   2554\u001b[39m     \u001b[38;5;129;01mand\u001b[39;00m (torch.isnan(tr_loss_step) \u001b[38;5;129;01mor\u001b[39;00m torch.isinf(tr_loss_step))\n\u001b[32m   2555\u001b[39m ):\n\u001b[32m   2556\u001b[39m     \u001b[38;5;66;03m# if loss is nan or inf simply add the average of previous logged losses\u001b[39;00m\n\u001b[32m   2557\u001b[39m     tr_loss = tr_loss + tr_loss / (\u001b[32m1\u001b[39m + \u001b[38;5;28mself\u001b[39m.state.global_step - \u001b[38;5;28mself\u001b[39m._globalstep_last_logged)\n",
      "\u001b[36mFile \u001b[39m\u001b[32mc:\\Users\\Yann\\Desktop\\DEV\\School\\ml_m1\\NLP\\CustomGPT\\scraper_env\\Lib\\site-packages\\transformers\\trainer.py:3750\u001b[39m, in \u001b[36mTrainer.training_step\u001b[39m\u001b[34m(self, model, inputs, num_items_in_batch)\u001b[39m\n\u001b[32m   3747\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m loss_mb.reduce_mean().detach().to(\u001b[38;5;28mself\u001b[39m.args.device)\n\u001b[32m   3749\u001b[39m \u001b[38;5;28;01mwith\u001b[39;00m \u001b[38;5;28mself\u001b[39m.compute_loss_context_manager():\n\u001b[32m-> \u001b[39m\u001b[32m3750\u001b[39m     loss = \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43mcompute_loss\u001b[49m\u001b[43m(\u001b[49m\u001b[43mmodel\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43minputs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mnum_items_in_batch\u001b[49m\u001b[43m=\u001b[49m\u001b[43mnum_items_in_batch\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m   3752\u001b[39m \u001b[38;5;28;01mdel\u001b[39;00m inputs\n\u001b[32m   3753\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m (\n\u001b[32m   3754\u001b[39m     \u001b[38;5;28mself\u001b[39m.args.torch_empty_cache_steps \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[32m   3755\u001b[39m     \u001b[38;5;129;01mand\u001b[39;00m \u001b[38;5;28mself\u001b[39m.state.global_step % \u001b[38;5;28mself\u001b[39m.args.torch_empty_cache_steps == \u001b[32m0\u001b[39m\n\u001b[32m   3756\u001b[39m ):\n",
      "\u001b[36mFile \u001b[39m\u001b[32mc:\\Users\\Yann\\Desktop\\DEV\\School\\ml_m1\\NLP\\CustomGPT\\scraper_env\\Lib\\site-packages\\transformers\\trainer.py:3837\u001b[39m, in \u001b[36mTrainer.compute_loss\u001b[39m\u001b[34m(self, model, inputs, return_outputs, num_items_in_batch)\u001b[39m\n\u001b[32m   3835\u001b[39m         loss_kwargs[\u001b[33m\"\u001b[39m\u001b[33mnum_items_in_batch\u001b[39m\u001b[33m\"\u001b[39m] = num_items_in_batch\n\u001b[32m   3836\u001b[39m     inputs = {**inputs, **loss_kwargs}\n\u001b[32m-> \u001b[39m\u001b[32m3837\u001b[39m outputs = \u001b[43mmodel\u001b[49m\u001b[43m(\u001b[49m\u001b[43m*\u001b[49m\u001b[43m*\u001b[49m\u001b[43minputs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m   3838\u001b[39m \u001b[38;5;66;03m# Save past state if it exists\u001b[39;00m\n\u001b[32m   3839\u001b[39m \u001b[38;5;66;03m# TODO: this needs to be fixed and made cleaner later.\u001b[39;00m\n\u001b[32m   3840\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m.args.past_index >= \u001b[32m0\u001b[39m:\n",
      "\u001b[36mFile \u001b[39m\u001b[32mc:\\Users\\Yann\\Desktop\\DEV\\School\\ml_m1\\NLP\\CustomGPT\\scraper_env\\Lib\\site-packages\\torch\\nn\\modules\\module.py:1751\u001b[39m, in \u001b[36mModule._wrapped_call_impl\u001b[39m\u001b[34m(self, *args, **kwargs)\u001b[39m\n\u001b[32m   1749\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m._compiled_call_impl(*args, **kwargs)  \u001b[38;5;66;03m# type: ignore[misc]\u001b[39;00m\n\u001b[32m   1750\u001b[39m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[32m-> \u001b[39m\u001b[32m1751\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43m_call_impl\u001b[49m\u001b[43m(\u001b[49m\u001b[43m*\u001b[49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m*\u001b[49m\u001b[43m*\u001b[49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[36mFile \u001b[39m\u001b[32mc:\\Users\\Yann\\Desktop\\DEV\\School\\ml_m1\\NLP\\CustomGPT\\scraper_env\\Lib\\site-packages\\torch\\nn\\modules\\module.py:1762\u001b[39m, in \u001b[36mModule._call_impl\u001b[39m\u001b[34m(self, *args, **kwargs)\u001b[39m\n\u001b[32m   1757\u001b[39m \u001b[38;5;66;03m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[32m   1758\u001b[39m \u001b[38;5;66;03m# this function, and just call forward.\u001b[39;00m\n\u001b[32m   1759\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m (\u001b[38;5;28mself\u001b[39m._backward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m._backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m._forward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m._forward_pre_hooks\n\u001b[32m   1760\u001b[39m         \u001b[38;5;129;01mor\u001b[39;00m _global_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_backward_hooks\n\u001b[32m   1761\u001b[39m         \u001b[38;5;129;01mor\u001b[39;00m _global_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[32m-> \u001b[39m\u001b[32m1762\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mforward_call\u001b[49m\u001b[43m(\u001b[49m\u001b[43m*\u001b[49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m*\u001b[49m\u001b[43m*\u001b[49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m   1764\u001b[39m result = \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[32m   1765\u001b[39m called_always_called_hooks = \u001b[38;5;28mset\u001b[39m()\n",
      "\u001b[36mFile \u001b[39m\u001b[32mc:\\Users\\Yann\\Desktop\\DEV\\School\\ml_m1\\NLP\\CustomGPT\\scraper_env\\Lib\\site-packages\\transformers\\models\\roberta\\modeling_roberta.py:1191\u001b[39m, in \u001b[36mRobertaForSequenceClassification.forward\u001b[39m\u001b[34m(self, input_ids, attention_mask, token_type_ids, position_ids, head_mask, inputs_embeds, labels, output_attentions, output_hidden_states, return_dict)\u001b[39m\n\u001b[32m   1174\u001b[39m \u001b[38;5;250m\u001b[39m\u001b[33mr\u001b[39m\u001b[33;03m\"\"\"\u001b[39;00m\n\u001b[32m   1175\u001b[39m \u001b[33;03mtoken_type_ids (`torch.LongTensor` of shape `(batch_size, sequence_length)`, *optional*):\u001b[39;00m\n\u001b[32m   1176\u001b[39m \u001b[33;03m    Segment token indices to indicate first and second portions of the inputs. Indices are selected in `[0,1]`:\u001b[39;00m\n\u001b[32m   (...)\u001b[39m\u001b[32m   1187\u001b[39m \u001b[33;03m    `config.num_labels > 1` a classification loss is computed (Cross-Entropy).\u001b[39;00m\n\u001b[32m   1188\u001b[39m \u001b[33;03m\"\"\"\u001b[39;00m\n\u001b[32m   1189\u001b[39m return_dict = return_dict \u001b[38;5;28;01mif\u001b[39;00m return_dict \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m \u001b[38;5;28;01melse\u001b[39;00m \u001b[38;5;28mself\u001b[39m.config.use_return_dict\n\u001b[32m-> \u001b[39m\u001b[32m1191\u001b[39m outputs = \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43mroberta\u001b[49m\u001b[43m(\u001b[49m\n\u001b[32m   1192\u001b[39m \u001b[43m    \u001b[49m\u001b[43minput_ids\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   1193\u001b[39m \u001b[43m    \u001b[49m\u001b[43mattention_mask\u001b[49m\u001b[43m=\u001b[49m\u001b[43mattention_mask\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   1194\u001b[39m \u001b[43m    \u001b[49m\u001b[43mtoken_type_ids\u001b[49m\u001b[43m=\u001b[49m\u001b[43mtoken_type_ids\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   1195\u001b[39m \u001b[43m    \u001b[49m\u001b[43mposition_ids\u001b[49m\u001b[43m=\u001b[49m\u001b[43mposition_ids\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   1196\u001b[39m \u001b[43m    \u001b[49m\u001b[43mhead_mask\u001b[49m\u001b[43m=\u001b[49m\u001b[43mhead_mask\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   1197\u001b[39m \u001b[43m    \u001b[49m\u001b[43minputs_embeds\u001b[49m\u001b[43m=\u001b[49m\u001b[43minputs_embeds\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   1198\u001b[39m \u001b[43m    \u001b[49m\u001b[43moutput_attentions\u001b[49m\u001b[43m=\u001b[49m\u001b[43moutput_attentions\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   1199\u001b[39m \u001b[43m    \u001b[49m\u001b[43moutput_hidden_states\u001b[49m\u001b[43m=\u001b[49m\u001b[43moutput_hidden_states\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   1200\u001b[39m \u001b[43m    \u001b[49m\u001b[43mreturn_dict\u001b[49m\u001b[43m=\u001b[49m\u001b[43mreturn_dict\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   1201\u001b[39m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m   1202\u001b[39m sequence_output = outputs[\u001b[32m0\u001b[39m]\n\u001b[32m   1203\u001b[39m logits = \u001b[38;5;28mself\u001b[39m.classifier(sequence_output)\n",
      "\u001b[36mFile \u001b[39m\u001b[32mc:\\Users\\Yann\\Desktop\\DEV\\School\\ml_m1\\NLP\\CustomGPT\\scraper_env\\Lib\\site-packages\\torch\\nn\\modules\\module.py:1751\u001b[39m, in \u001b[36mModule._wrapped_call_impl\u001b[39m\u001b[34m(self, *args, **kwargs)\u001b[39m\n\u001b[32m   1749\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m._compiled_call_impl(*args, **kwargs)  \u001b[38;5;66;03m# type: ignore[misc]\u001b[39;00m\n\u001b[32m   1750\u001b[39m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[32m-> \u001b[39m\u001b[32m1751\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43m_call_impl\u001b[49m\u001b[43m(\u001b[49m\u001b[43m*\u001b[49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m*\u001b[49m\u001b[43m*\u001b[49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[36mFile \u001b[39m\u001b[32mc:\\Users\\Yann\\Desktop\\DEV\\School\\ml_m1\\NLP\\CustomGPT\\scraper_env\\Lib\\site-packages\\torch\\nn\\modules\\module.py:1762\u001b[39m, in \u001b[36mModule._call_impl\u001b[39m\u001b[34m(self, *args, **kwargs)\u001b[39m\n\u001b[32m   1757\u001b[39m \u001b[38;5;66;03m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[32m   1758\u001b[39m \u001b[38;5;66;03m# this function, and just call forward.\u001b[39;00m\n\u001b[32m   1759\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m (\u001b[38;5;28mself\u001b[39m._backward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m._backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m._forward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m._forward_pre_hooks\n\u001b[32m   1760\u001b[39m         \u001b[38;5;129;01mor\u001b[39;00m _global_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_backward_hooks\n\u001b[32m   1761\u001b[39m         \u001b[38;5;129;01mor\u001b[39;00m _global_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[32m-> \u001b[39m\u001b[32m1762\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mforward_call\u001b[49m\u001b[43m(\u001b[49m\u001b[43m*\u001b[49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m*\u001b[49m\u001b[43m*\u001b[49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m   1764\u001b[39m result = \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[32m   1765\u001b[39m called_always_called_hooks = \u001b[38;5;28mset\u001b[39m()\n",
      "\u001b[36mFile \u001b[39m\u001b[32mc:\\Users\\Yann\\Desktop\\DEV\\School\\ml_m1\\NLP\\CustomGPT\\scraper_env\\Lib\\site-packages\\transformers\\models\\roberta\\modeling_roberta.py:858\u001b[39m, in \u001b[36mRobertaModel.forward\u001b[39m\u001b[34m(self, input_ids, attention_mask, token_type_ids, position_ids, head_mask, inputs_embeds, encoder_hidden_states, encoder_attention_mask, past_key_values, use_cache, output_attentions, output_hidden_states, return_dict)\u001b[39m\n\u001b[32m    851\u001b[39m \u001b[38;5;66;03m# Prepare head mask if needed\u001b[39;00m\n\u001b[32m    852\u001b[39m \u001b[38;5;66;03m# 1.0 in head_mask indicate we keep the head\u001b[39;00m\n\u001b[32m    853\u001b[39m \u001b[38;5;66;03m# attention_probs has shape bsz x n_heads x N x N\u001b[39;00m\n\u001b[32m    854\u001b[39m \u001b[38;5;66;03m# input head_mask has shape [num_heads] or [num_hidden_layers x num_heads]\u001b[39;00m\n\u001b[32m    855\u001b[39m \u001b[38;5;66;03m# and head_mask is converted to shape [num_hidden_layers x batch x num_heads x seq_length x seq_length]\u001b[39;00m\n\u001b[32m    856\u001b[39m head_mask = \u001b[38;5;28mself\u001b[39m.get_head_mask(head_mask, \u001b[38;5;28mself\u001b[39m.config.num_hidden_layers)\n\u001b[32m--> \u001b[39m\u001b[32m858\u001b[39m encoder_outputs = \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43mencoder\u001b[49m\u001b[43m(\u001b[49m\n\u001b[32m    859\u001b[39m \u001b[43m    \u001b[49m\u001b[43membedding_output\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    860\u001b[39m \u001b[43m    \u001b[49m\u001b[43mattention_mask\u001b[49m\u001b[43m=\u001b[49m\u001b[43mextended_attention_mask\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    861\u001b[39m \u001b[43m    \u001b[49m\u001b[43mhead_mask\u001b[49m\u001b[43m=\u001b[49m\u001b[43mhead_mask\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    862\u001b[39m \u001b[43m    \u001b[49m\u001b[43mencoder_hidden_states\u001b[49m\u001b[43m=\u001b[49m\u001b[43mencoder_hidden_states\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    863\u001b[39m \u001b[43m    \u001b[49m\u001b[43mencoder_attention_mask\u001b[49m\u001b[43m=\u001b[49m\u001b[43mencoder_extended_attention_mask\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    864\u001b[39m \u001b[43m    \u001b[49m\u001b[43mpast_key_values\u001b[49m\u001b[43m=\u001b[49m\u001b[43mpast_key_values\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    865\u001b[39m \u001b[43m    \u001b[49m\u001b[43muse_cache\u001b[49m\u001b[43m=\u001b[49m\u001b[43muse_cache\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    866\u001b[39m \u001b[43m    \u001b[49m\u001b[43moutput_attentions\u001b[49m\u001b[43m=\u001b[49m\u001b[43moutput_attentions\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    867\u001b[39m \u001b[43m    \u001b[49m\u001b[43moutput_hidden_states\u001b[49m\u001b[43m=\u001b[49m\u001b[43moutput_hidden_states\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    868\u001b[39m \u001b[43m    \u001b[49m\u001b[43mreturn_dict\u001b[49m\u001b[43m=\u001b[49m\u001b[43mreturn_dict\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    869\u001b[39m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    870\u001b[39m sequence_output = encoder_outputs[\u001b[32m0\u001b[39m]\n\u001b[32m    871\u001b[39m pooled_output = \u001b[38;5;28mself\u001b[39m.pooler(sequence_output) \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m.pooler \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m \u001b[38;5;28;01melse\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m\n",
      "\u001b[36mFile \u001b[39m\u001b[32mc:\\Users\\Yann\\Desktop\\DEV\\School\\ml_m1\\NLP\\CustomGPT\\scraper_env\\Lib\\site-packages\\torch\\nn\\modules\\module.py:1751\u001b[39m, in \u001b[36mModule._wrapped_call_impl\u001b[39m\u001b[34m(self, *args, **kwargs)\u001b[39m\n\u001b[32m   1749\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m._compiled_call_impl(*args, **kwargs)  \u001b[38;5;66;03m# type: ignore[misc]\u001b[39;00m\n\u001b[32m   1750\u001b[39m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[32m-> \u001b[39m\u001b[32m1751\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43m_call_impl\u001b[49m\u001b[43m(\u001b[49m\u001b[43m*\u001b[49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m*\u001b[49m\u001b[43m*\u001b[49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[36mFile \u001b[39m\u001b[32mc:\\Users\\Yann\\Desktop\\DEV\\School\\ml_m1\\NLP\\CustomGPT\\scraper_env\\Lib\\site-packages\\torch\\nn\\modules\\module.py:1762\u001b[39m, in \u001b[36mModule._call_impl\u001b[39m\u001b[34m(self, *args, **kwargs)\u001b[39m\n\u001b[32m   1757\u001b[39m \u001b[38;5;66;03m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[32m   1758\u001b[39m \u001b[38;5;66;03m# this function, and just call forward.\u001b[39;00m\n\u001b[32m   1759\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m (\u001b[38;5;28mself\u001b[39m._backward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m._backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m._forward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m._forward_pre_hooks\n\u001b[32m   1760\u001b[39m         \u001b[38;5;129;01mor\u001b[39;00m _global_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_backward_hooks\n\u001b[32m   1761\u001b[39m         \u001b[38;5;129;01mor\u001b[39;00m _global_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[32m-> \u001b[39m\u001b[32m1762\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mforward_call\u001b[49m\u001b[43m(\u001b[49m\u001b[43m*\u001b[49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m*\u001b[49m\u001b[43m*\u001b[49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m   1764\u001b[39m result = \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[32m   1765\u001b[39m called_always_called_hooks = \u001b[38;5;28mset\u001b[39m()\n",
      "\u001b[36mFile \u001b[39m\u001b[32mc:\\Users\\Yann\\Desktop\\DEV\\School\\ml_m1\\NLP\\CustomGPT\\scraper_env\\Lib\\site-packages\\transformers\\models\\roberta\\modeling_roberta.py:607\u001b[39m, in \u001b[36mRobertaEncoder.forward\u001b[39m\u001b[34m(self, hidden_states, attention_mask, head_mask, encoder_hidden_states, encoder_attention_mask, past_key_values, use_cache, output_attentions, output_hidden_states, return_dict)\u001b[39m\n\u001b[32m    604\u001b[39m layer_head_mask = head_mask[i] \u001b[38;5;28;01mif\u001b[39;00m head_mask \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m \u001b[38;5;28;01melse\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[32m    605\u001b[39m past_key_value = past_key_values[i] \u001b[38;5;28;01mif\u001b[39;00m past_key_values \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m \u001b[38;5;28;01melse\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[32m--> \u001b[39m\u001b[32m607\u001b[39m layer_outputs = \u001b[43mlayer_module\u001b[49m\u001b[43m(\u001b[49m\n\u001b[32m    608\u001b[39m \u001b[43m    \u001b[49m\u001b[43mhidden_states\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    609\u001b[39m \u001b[43m    \u001b[49m\u001b[43mattention_mask\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    610\u001b[39m \u001b[43m    \u001b[49m\u001b[43mlayer_head_mask\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    611\u001b[39m \u001b[43m    \u001b[49m\u001b[43mencoder_hidden_states\u001b[49m\u001b[43m,\u001b[49m\u001b[43m  \u001b[49m\u001b[38;5;66;43;03m# as a positional argument for gradient checkpointing\u001b[39;49;00m\n\u001b[32m    612\u001b[39m \u001b[43m    \u001b[49m\u001b[43mencoder_attention_mask\u001b[49m\u001b[43m=\u001b[49m\u001b[43mencoder_attention_mask\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    613\u001b[39m \u001b[43m    \u001b[49m\u001b[43mpast_key_value\u001b[49m\u001b[43m=\u001b[49m\u001b[43mpast_key_value\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    614\u001b[39m \u001b[43m    \u001b[49m\u001b[43moutput_attentions\u001b[49m\u001b[43m=\u001b[49m\u001b[43moutput_attentions\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    615\u001b[39m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    617\u001b[39m hidden_states = layer_outputs[\u001b[32m0\u001b[39m]\n\u001b[32m    618\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m use_cache:\n",
      "\u001b[36mFile \u001b[39m\u001b[32mc:\\Users\\Yann\\Desktop\\DEV\\School\\ml_m1\\NLP\\CustomGPT\\scraper_env\\Lib\\site-packages\\transformers\\modeling_layers.py:83\u001b[39m, in \u001b[36mGradientCheckpointingLayer.__call__\u001b[39m\u001b[34m(self, *args, **kwargs)\u001b[39m\n\u001b[32m     80\u001b[39m         logger.warning(message)\n\u001b[32m     82\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m._gradient_checkpointing_func(partial(\u001b[38;5;28msuper\u001b[39m().\u001b[34m__call__\u001b[39m, **kwargs), *args)\n\u001b[32m---> \u001b[39m\u001b[32m83\u001b[39m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43msuper\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\u001b[43m.\u001b[49m\u001b[34;43m__call__\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43m*\u001b[49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m*\u001b[49m\u001b[43m*\u001b[49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[36mFile \u001b[39m\u001b[32mc:\\Users\\Yann\\Desktop\\DEV\\School\\ml_m1\\NLP\\CustomGPT\\scraper_env\\Lib\\site-packages\\torch\\nn\\modules\\module.py:1751\u001b[39m, in \u001b[36mModule._wrapped_call_impl\u001b[39m\u001b[34m(self, *args, **kwargs)\u001b[39m\n\u001b[32m   1749\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m._compiled_call_impl(*args, **kwargs)  \u001b[38;5;66;03m# type: ignore[misc]\u001b[39;00m\n\u001b[32m   1750\u001b[39m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[32m-> \u001b[39m\u001b[32m1751\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43m_call_impl\u001b[49m\u001b[43m(\u001b[49m\u001b[43m*\u001b[49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m*\u001b[49m\u001b[43m*\u001b[49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[36mFile \u001b[39m\u001b[32mc:\\Users\\Yann\\Desktop\\DEV\\School\\ml_m1\\NLP\\CustomGPT\\scraper_env\\Lib\\site-packages\\torch\\nn\\modules\\module.py:1762\u001b[39m, in \u001b[36mModule._call_impl\u001b[39m\u001b[34m(self, *args, **kwargs)\u001b[39m\n\u001b[32m   1757\u001b[39m \u001b[38;5;66;03m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[32m   1758\u001b[39m \u001b[38;5;66;03m# this function, and just call forward.\u001b[39;00m\n\u001b[32m   1759\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m (\u001b[38;5;28mself\u001b[39m._backward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m._backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m._forward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m._forward_pre_hooks\n\u001b[32m   1760\u001b[39m         \u001b[38;5;129;01mor\u001b[39;00m _global_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_backward_hooks\n\u001b[32m   1761\u001b[39m         \u001b[38;5;129;01mor\u001b[39;00m _global_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[32m-> \u001b[39m\u001b[32m1762\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mforward_call\u001b[49m\u001b[43m(\u001b[49m\u001b[43m*\u001b[49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m*\u001b[49m\u001b[43m*\u001b[49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m   1764\u001b[39m result = \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[32m   1765\u001b[39m called_always_called_hooks = \u001b[38;5;28mset\u001b[39m()\n",
      "\u001b[36mFile \u001b[39m\u001b[32mc:\\Users\\Yann\\Desktop\\DEV\\School\\ml_m1\\NLP\\CustomGPT\\scraper_env\\Lib\\site-packages\\transformers\\models\\roberta\\modeling_roberta.py:508\u001b[39m, in \u001b[36mRobertaLayer.forward\u001b[39m\u001b[34m(self, hidden_states, attention_mask, head_mask, encoder_hidden_states, encoder_attention_mask, past_key_value, output_attentions)\u001b[39m\n\u001b[32m    496\u001b[39m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34mforward\u001b[39m(\n\u001b[32m    497\u001b[39m     \u001b[38;5;28mself\u001b[39m,\n\u001b[32m    498\u001b[39m     hidden_states: torch.Tensor,\n\u001b[32m   (...)\u001b[39m\u001b[32m    505\u001b[39m ) -> \u001b[38;5;28mtuple\u001b[39m[torch.Tensor]:\n\u001b[32m    506\u001b[39m     \u001b[38;5;66;03m# decoder uni-directional self-attention cached key/values tuple is at positions 1,2\u001b[39;00m\n\u001b[32m    507\u001b[39m     self_attn_past_key_value = past_key_value[:\u001b[32m2\u001b[39m] \u001b[38;5;28;01mif\u001b[39;00m past_key_value \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m \u001b[38;5;28;01melse\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[32m--> \u001b[39m\u001b[32m508\u001b[39m     self_attention_outputs = \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43mattention\u001b[49m\u001b[43m(\u001b[49m\n\u001b[32m    509\u001b[39m \u001b[43m        \u001b[49m\u001b[43mhidden_states\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    510\u001b[39m \u001b[43m        \u001b[49m\u001b[43mattention_mask\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    511\u001b[39m \u001b[43m        \u001b[49m\u001b[43mhead_mask\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    512\u001b[39m \u001b[43m        \u001b[49m\u001b[43moutput_attentions\u001b[49m\u001b[43m=\u001b[49m\u001b[43moutput_attentions\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    513\u001b[39m \u001b[43m        \u001b[49m\u001b[43mpast_key_value\u001b[49m\u001b[43m=\u001b[49m\u001b[43mself_attn_past_key_value\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    514\u001b[39m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    515\u001b[39m     attention_output = self_attention_outputs[\u001b[32m0\u001b[39m]\n\u001b[32m    517\u001b[39m     \u001b[38;5;66;03m# if decoder, the last output is tuple of self-attn cache\u001b[39;00m\n",
      "\u001b[36mFile \u001b[39m\u001b[32mc:\\Users\\Yann\\Desktop\\DEV\\School\\ml_m1\\NLP\\CustomGPT\\scraper_env\\Lib\\site-packages\\torch\\nn\\modules\\module.py:1751\u001b[39m, in \u001b[36mModule._wrapped_call_impl\u001b[39m\u001b[34m(self, *args, **kwargs)\u001b[39m\n\u001b[32m   1749\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m._compiled_call_impl(*args, **kwargs)  \u001b[38;5;66;03m# type: ignore[misc]\u001b[39;00m\n\u001b[32m   1750\u001b[39m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[32m-> \u001b[39m\u001b[32m1751\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43m_call_impl\u001b[49m\u001b[43m(\u001b[49m\u001b[43m*\u001b[49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m*\u001b[49m\u001b[43m*\u001b[49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[36mFile \u001b[39m\u001b[32mc:\\Users\\Yann\\Desktop\\DEV\\School\\ml_m1\\NLP\\CustomGPT\\scraper_env\\Lib\\site-packages\\torch\\nn\\modules\\module.py:1762\u001b[39m, in \u001b[36mModule._call_impl\u001b[39m\u001b[34m(self, *args, **kwargs)\u001b[39m\n\u001b[32m   1757\u001b[39m \u001b[38;5;66;03m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[32m   1758\u001b[39m \u001b[38;5;66;03m# this function, and just call forward.\u001b[39;00m\n\u001b[32m   1759\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m (\u001b[38;5;28mself\u001b[39m._backward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m._backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m._forward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m._forward_pre_hooks\n\u001b[32m   1760\u001b[39m         \u001b[38;5;129;01mor\u001b[39;00m _global_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_backward_hooks\n\u001b[32m   1761\u001b[39m         \u001b[38;5;129;01mor\u001b[39;00m _global_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[32m-> \u001b[39m\u001b[32m1762\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mforward_call\u001b[49m\u001b[43m(\u001b[49m\u001b[43m*\u001b[49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m*\u001b[49m\u001b[43m*\u001b[49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m   1764\u001b[39m result = \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[32m   1765\u001b[39m called_always_called_hooks = \u001b[38;5;28mset\u001b[39m()\n",
      "\u001b[36mFile \u001b[39m\u001b[32mc:\\Users\\Yann\\Desktop\\DEV\\School\\ml_m1\\NLP\\CustomGPT\\scraper_env\\Lib\\site-packages\\transformers\\models\\roberta\\modeling_roberta.py:444\u001b[39m, in \u001b[36mRobertaAttention.forward\u001b[39m\u001b[34m(self, hidden_states, attention_mask, head_mask, encoder_hidden_states, encoder_attention_mask, past_key_value, output_attentions)\u001b[39m\n\u001b[32m    425\u001b[39m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34mforward\u001b[39m(\n\u001b[32m    426\u001b[39m     \u001b[38;5;28mself\u001b[39m,\n\u001b[32m    427\u001b[39m     hidden_states: torch.Tensor,\n\u001b[32m   (...)\u001b[39m\u001b[32m    433\u001b[39m     output_attentions: Optional[\u001b[38;5;28mbool\u001b[39m] = \u001b[38;5;28;01mFalse\u001b[39;00m,\n\u001b[32m    434\u001b[39m ) -> \u001b[38;5;28mtuple\u001b[39m[torch.Tensor]:\n\u001b[32m    435\u001b[39m     self_outputs = \u001b[38;5;28mself\u001b[39m.self(\n\u001b[32m    436\u001b[39m         hidden_states,\n\u001b[32m    437\u001b[39m         attention_mask,\n\u001b[32m   (...)\u001b[39m\u001b[32m    442\u001b[39m         output_attentions,\n\u001b[32m    443\u001b[39m     )\n\u001b[32m--> \u001b[39m\u001b[32m444\u001b[39m     attention_output = \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43moutput\u001b[49m\u001b[43m(\u001b[49m\u001b[43mself_outputs\u001b[49m\u001b[43m[\u001b[49m\u001b[32;43m0\u001b[39;49m\u001b[43m]\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mhidden_states\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    445\u001b[39m     outputs = (attention_output,) + self_outputs[\u001b[32m1\u001b[39m:]  \u001b[38;5;66;03m# add attentions if we output them\u001b[39;00m\n\u001b[32m    446\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m outputs\n",
      "\u001b[36mFile \u001b[39m\u001b[32mc:\\Users\\Yann\\Desktop\\DEV\\School\\ml_m1\\NLP\\CustomGPT\\scraper_env\\Lib\\site-packages\\torch\\nn\\modules\\module.py:1751\u001b[39m, in \u001b[36mModule._wrapped_call_impl\u001b[39m\u001b[34m(self, *args, **kwargs)\u001b[39m\n\u001b[32m   1749\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m._compiled_call_impl(*args, **kwargs)  \u001b[38;5;66;03m# type: ignore[misc]\u001b[39;00m\n\u001b[32m   1750\u001b[39m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[32m-> \u001b[39m\u001b[32m1751\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43m_call_impl\u001b[49m\u001b[43m(\u001b[49m\u001b[43m*\u001b[49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m*\u001b[49m\u001b[43m*\u001b[49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[36mFile \u001b[39m\u001b[32mc:\\Users\\Yann\\Desktop\\DEV\\School\\ml_m1\\NLP\\CustomGPT\\scraper_env\\Lib\\site-packages\\torch\\nn\\modules\\module.py:1762\u001b[39m, in \u001b[36mModule._call_impl\u001b[39m\u001b[34m(self, *args, **kwargs)\u001b[39m\n\u001b[32m   1757\u001b[39m \u001b[38;5;66;03m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[32m   1758\u001b[39m \u001b[38;5;66;03m# this function, and just call forward.\u001b[39;00m\n\u001b[32m   1759\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m (\u001b[38;5;28mself\u001b[39m._backward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m._backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m._forward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m._forward_pre_hooks\n\u001b[32m   1760\u001b[39m         \u001b[38;5;129;01mor\u001b[39;00m _global_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_backward_hooks\n\u001b[32m   1761\u001b[39m         \u001b[38;5;129;01mor\u001b[39;00m _global_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[32m-> \u001b[39m\u001b[32m1762\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mforward_call\u001b[49m\u001b[43m(\u001b[49m\u001b[43m*\u001b[49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m*\u001b[49m\u001b[43m*\u001b[49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m   1764\u001b[39m result = \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[32m   1765\u001b[39m called_always_called_hooks = \u001b[38;5;28mset\u001b[39m()\n",
      "\u001b[36mFile \u001b[39m\u001b[32mc:\\Users\\Yann\\Desktop\\DEV\\School\\ml_m1\\NLP\\CustomGPT\\scraper_env\\Lib\\site-packages\\transformers\\models\\roberta\\modeling_roberta.py:386\u001b[39m, in \u001b[36mRobertaSelfOutput.forward\u001b[39m\u001b[34m(self, hidden_states, input_tensor)\u001b[39m\n\u001b[32m    384\u001b[39m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34mforward\u001b[39m(\u001b[38;5;28mself\u001b[39m, hidden_states: torch.Tensor, input_tensor: torch.Tensor) -> torch.Tensor:\n\u001b[32m    385\u001b[39m     hidden_states = \u001b[38;5;28mself\u001b[39m.dense(hidden_states)\n\u001b[32m--> \u001b[39m\u001b[32m386\u001b[39m     hidden_states = \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43mdropout\u001b[49m\u001b[43m(\u001b[49m\u001b[43mhidden_states\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    387\u001b[39m     hidden_states = \u001b[38;5;28mself\u001b[39m.LayerNorm(hidden_states + input_tensor)\n\u001b[32m    388\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m hidden_states\n",
      "\u001b[36mFile \u001b[39m\u001b[32mc:\\Users\\Yann\\Desktop\\DEV\\School\\ml_m1\\NLP\\CustomGPT\\scraper_env\\Lib\\site-packages\\torch\\nn\\modules\\module.py:1751\u001b[39m, in \u001b[36mModule._wrapped_call_impl\u001b[39m\u001b[34m(self, *args, **kwargs)\u001b[39m\n\u001b[32m   1749\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m._compiled_call_impl(*args, **kwargs)  \u001b[38;5;66;03m# type: ignore[misc]\u001b[39;00m\n\u001b[32m   1750\u001b[39m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[32m-> \u001b[39m\u001b[32m1751\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43m_call_impl\u001b[49m\u001b[43m(\u001b[49m\u001b[43m*\u001b[49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m*\u001b[49m\u001b[43m*\u001b[49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[36mFile \u001b[39m\u001b[32mc:\\Users\\Yann\\Desktop\\DEV\\School\\ml_m1\\NLP\\CustomGPT\\scraper_env\\Lib\\site-packages\\torch\\nn\\modules\\module.py:1762\u001b[39m, in \u001b[36mModule._call_impl\u001b[39m\u001b[34m(self, *args, **kwargs)\u001b[39m\n\u001b[32m   1757\u001b[39m \u001b[38;5;66;03m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[32m   1758\u001b[39m \u001b[38;5;66;03m# this function, and just call forward.\u001b[39;00m\n\u001b[32m   1759\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m (\u001b[38;5;28mself\u001b[39m._backward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m._backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m._forward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m._forward_pre_hooks\n\u001b[32m   1760\u001b[39m         \u001b[38;5;129;01mor\u001b[39;00m _global_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_backward_hooks\n\u001b[32m   1761\u001b[39m         \u001b[38;5;129;01mor\u001b[39;00m _global_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[32m-> \u001b[39m\u001b[32m1762\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mforward_call\u001b[49m\u001b[43m(\u001b[49m\u001b[43m*\u001b[49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m*\u001b[49m\u001b[43m*\u001b[49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m   1764\u001b[39m result = \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[32m   1765\u001b[39m called_always_called_hooks = \u001b[38;5;28mset\u001b[39m()\n",
      "\u001b[36mFile \u001b[39m\u001b[32mc:\\Users\\Yann\\Desktop\\DEV\\School\\ml_m1\\NLP\\CustomGPT\\scraper_env\\Lib\\site-packages\\torch\\nn\\modules\\dropout.py:70\u001b[39m, in \u001b[36mDropout.forward\u001b[39m\u001b[34m(self, input)\u001b[39m\n\u001b[32m     69\u001b[39m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34mforward\u001b[39m(\u001b[38;5;28mself\u001b[39m, \u001b[38;5;28minput\u001b[39m: Tensor) -> Tensor:\n\u001b[32m---> \u001b[39m\u001b[32m70\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mF\u001b[49m\u001b[43m.\u001b[49m\u001b[43mdropout\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43minput\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43mp\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43mtraining\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43minplace\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[36mFile \u001b[39m\u001b[32mc:\\Users\\Yann\\Desktop\\DEV\\School\\ml_m1\\NLP\\CustomGPT\\scraper_env\\Lib\\site-packages\\torch\\nn\\functional.py:1425\u001b[39m, in \u001b[36mdropout\u001b[39m\u001b[34m(input, p, training, inplace)\u001b[39m\n\u001b[32m   1422\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m p < \u001b[32m0.0\u001b[39m \u001b[38;5;129;01mor\u001b[39;00m p > \u001b[32m1.0\u001b[39m:\n\u001b[32m   1423\u001b[39m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mValueError\u001b[39;00m(\u001b[33mf\u001b[39m\u001b[33m\"\u001b[39m\u001b[33mdropout probability has to be between 0 and 1, but got \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mp\u001b[38;5;132;01m}\u001b[39;00m\u001b[33m\"\u001b[39m)\n\u001b[32m   1424\u001b[39m \u001b[38;5;28;01mreturn\u001b[39;00m (\n\u001b[32m-> \u001b[39m\u001b[32m1425\u001b[39m     _VF.dropout_(\u001b[38;5;28minput\u001b[39m, p, training) \u001b[38;5;28;01mif\u001b[39;00m inplace \u001b[38;5;28;01melse\u001b[39;00m \u001b[43m_VF\u001b[49m\u001b[43m.\u001b[49m\u001b[43mdropout\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43minput\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mp\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mtraining\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m   1426\u001b[39m )\n",
      "\u001b[31mKeyboardInterrupt\u001b[39m: "
     ]
    }
   ],
   "source": [
    "from transformers import TrainingArguments, Trainer, IntervalStrategy\n",
    "from sklearn.metrics import f1_score, hamming_loss\n",
    "import numpy as np\n",
    "import torch\n",
    "\n",
    "def compute_metrics(eval_pred):\n",
    "    logits, labels = eval_pred\n",
    "    sigmoid = torch.nn.Sigmoid()\n",
    "    probs = sigmoid(torch.tensor(logits))\n",
    "    y_pred = (probs > 0.5).int().numpy()\n",
    "    y_true = np.array(labels)\n",
    "\n",
    "    return {\n",
    "        \"f1_micro\": f1_score(y_true, y_pred, average=\"micro\", zero_division=0),\n",
    "        \"f1_macro\": f1_score(y_true, y_pred, average=\"macro\", zero_division=0),\n",
    "        \"hamming_loss\": hamming_loss(y_true, y_pred),\n",
    "    }\n",
    "def convert_labels_to_float(example):\n",
    "    example[\"labels\"] = [float(x) for x in example[\"labels\"]]\n",
    "    return example\n",
    "\n",
    "\n",
    "\n",
    "training_args = TrainingArguments(\n",
    "    output_dir=\"./results\",\n",
    "    eval_strategy=IntervalStrategy.EPOCH,\n",
    "    save_strategy=IntervalStrategy.EPOCH,\n",
    "    logging_strategy=IntervalStrategy.EPOCH,\n",
    "    logging_dir=\"./logs\",\n",
    "    num_train_epochs=3,\n",
    "    per_device_train_batch_size=16,\n",
    "    per_device_eval_batch_size=32,\n",
    "    learning_rate=2e-5,\n",
    "    weight_decay=0.01,\n",
    "    load_best_model_at_end=True,\n",
    "    metric_for_best_model=\"f1_micro\"\n",
    ")\n",
    "\n",
    "trainer = Trainer(\n",
    "    model=model,\n",
    "    args=training_args,\n",
    "    train_dataset=tokenized_dataset[\"train\"],\n",
    "    eval_dataset=tokenized_dataset[\"validation\"],\n",
    "    tokenizer=tokenizer,\n",
    "    compute_metrics=compute_metrics\n",
    ")\n",
    "\n",
    "trainer.train()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "cb2a3f05",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using device: cuda\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Yann\\AppData\\Local\\Temp\\ipykernel_14552\\1225474775.py:43: FutureWarning: `tokenizer` is deprecated and will be removed in version 5.0.0 for `Trainer.__init__`. Use `processing_class` instead.\n",
      "  trainer = Trainer(\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='31173' max='31173' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [31173/31173 25:05, Epoch 3/3]\n",
       "    </div>\n",
       "    <table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       " <tr style=\"text-align: left;\">\n",
       "      <th>Epoch</th>\n",
       "      <th>Training Loss</th>\n",
       "      <th>Validation Loss</th>\n",
       "      <th>F1 Micro</th>\n",
       "      <th>F1 Macro</th>\n",
       "      <th>Hamming Loss</th>\n",
       "      <th>Runtime</th>\n",
       "      <th>Samples Per Second</th>\n",
       "      <th>Steps Per Second</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>1</td>\n",
       "      <td>0.120200</td>\n",
       "      <td>0.109728</td>\n",
       "      <td>0.328467</td>\n",
       "      <td>0.229520</td>\n",
       "      <td>0.037400</td>\n",
       "      <td>9.733800</td>\n",
       "      <td>2134.830000</td>\n",
       "      <td>66.778000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2</td>\n",
       "      <td>0.106700</td>\n",
       "      <td>0.107908</td>\n",
       "      <td>0.358921</td>\n",
       "      <td>0.257844</td>\n",
       "      <td>0.037043</td>\n",
       "      <td>9.847800</td>\n",
       "      <td>2110.119000</td>\n",
       "      <td>66.005000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3</td>\n",
       "      <td>0.101600</td>\n",
       "      <td>0.107412</td>\n",
       "      <td>0.373370</td>\n",
       "      <td>0.276749</td>\n",
       "      <td>0.037080</td>\n",
       "      <td>9.680300</td>\n",
       "      <td>2146.631000</td>\n",
       "      <td>67.147000</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table><p>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "TrainOutput(global_step=31173, training_loss=0.10948652871299883, metrics={'train_runtime': 1505.4789, 'train_samples_per_second': 331.274, 'train_steps_per_second': 20.706, 'total_flos': 3.2813033725684224e+16, 'train_loss': 0.10948652871299883, 'epoch': 3.0})"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from transformers import EarlyStoppingCallback\n",
    "from transformers import TrainingArguments, Trainer, IntervalStrategy\n",
    "from sklearn.metrics import f1_score, hamming_loss\n",
    "import numpy as np\n",
    "import torch\n",
    "\n",
    "def compute_metrics(eval_pred):\n",
    "    logits, labels = eval_pred\n",
    "    sigmoid = torch.nn.Sigmoid()\n",
    "    probs = sigmoid(torch.tensor(logits))\n",
    "    y_pred = (probs > 0.5).int().numpy()\n",
    "    y_true = np.array(labels)\n",
    "\n",
    "    return {\n",
    "        \"f1_micro\": f1_score(y_true, y_pred, average=\"micro\", zero_division=0),\n",
    "        \"f1_macro\": f1_score(y_true, y_pred, average=\"macro\", zero_division=0),\n",
    "        \"hamming_loss\": hamming_loss(y_true, y_pred),\n",
    "    }\n",
    "def convert_labels_to_float(example):\n",
    "    example[\"labels\"] = [float(x) for x in example[\"labels\"]]\n",
    "    return example\n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "print(f\"Using device: {device}\")\n",
    "\n",
    "training_args = TrainingArguments(\n",
    "    output_dir=\"./results\",\n",
    "    eval_strategy=IntervalStrategy.EPOCH,\n",
    "    save_strategy=IntervalStrategy.EPOCH,\n",
    "    logging_strategy=IntervalStrategy.EPOCH,\n",
    "    logging_dir=\"./logs\",\n",
    "    num_train_epochs=3,\n",
    "    per_device_train_batch_size=16,\n",
    "    per_device_eval_batch_size=32,\n",
    "    learning_rate=2e-5,\n",
    "    weight_decay=0.01,\n",
    "    load_best_model_at_end=True,\n",
    "    metric_for_best_model=\"f1_micro\",\n",
    "    report_to=\"none\",  # désactiver Weights & Biases/TensorBoard si inutiles\n",
    "    fp16=torch.cuda.is_available(),  # ⚡️ active mixed precision si GPU dispo\n",
    ")\n",
    "\n",
    "# === 4. Déclaration du Trainer ===\n",
    "trainer = Trainer(\n",
    "    model=model.to(device),\n",
    "    args=training_args,\n",
    "    train_dataset=tokenized_dataset[\"train\"],\n",
    "    eval_dataset=tokenized_dataset[\"validation\"],\n",
    "    tokenizer=tokenizer,\n",
    "    compute_metrics=compute_metrics,\n",
    ")\n",
    "\n",
    "# === 5. Lancement de l'entraînement ===\n",
    "trainer.train()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8752f220",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "False\n",
      "No GPU detected\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "print(torch.cuda.is_available())\n",
    "print(torch.cuda.get_device_name(0) if torch.cuda.is_available() else \"No GPU detected\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "edfc12c3",
   "metadata": {},
   "source": [
    "### evaluation finale"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "6a8043dc",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "{'eval_loss': 0.10706266015768051,\n",
       " 'eval_f1_micro': 0.37800398194105606,\n",
       " 'eval_f1_macro': 0.2717322882601445,\n",
       " 'eval_hamming_loss': 0.0368058355692949,\n",
       " 'eval_runtime': 10.0559,\n",
       " 'eval_samples_per_second': 2066.542,\n",
       " 'eval_steps_per_second': 64.638,\n",
       " 'epoch': 3.0}"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "trainer.evaluate(tokenized_dataset[\"test\"])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "3d612d96",
   "metadata": {},
   "outputs": [
    {
     "ename": "ValueError",
     "evalue": "Number of classes, 29, does not match size of target_names, 28. Try specifying the labels parameter",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[29], line 8\u001b[0m\n\u001b[0;32m      5\u001b[0m probs \u001b[38;5;241m=\u001b[39m torch\u001b[38;5;241m.\u001b[39msigmoid(torch\u001b[38;5;241m.\u001b[39mtensor(raw_preds\u001b[38;5;241m.\u001b[39mpredictions))\u001b[38;5;241m.\u001b[39mnumpy()\n\u001b[0;32m      6\u001b[0m preds \u001b[38;5;241m=\u001b[39m (probs \u001b[38;5;241m>\u001b[39m \u001b[38;5;241m0.5\u001b[39m)\u001b[38;5;241m.\u001b[39mastype(\u001b[38;5;28mint\u001b[39m)\n\u001b[1;32m----> 8\u001b[0m \u001b[38;5;28mprint\u001b[39m(\u001b[43mclassification_report\u001b[49m\u001b[43m(\u001b[49m\u001b[43mraw_preds\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mlabel_ids\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mpreds\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mtarget_names\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mlabel_cols\u001b[49m\u001b[43m)\u001b[49m)\n",
      "File \u001b[1;32mc:\\Users\\Yann\\anaconda3\\envs\\hf_gpu_env\\lib\\site-packages\\sklearn\\utils\\_param_validation.py:218\u001b[0m, in \u001b[0;36mvalidate_params.<locals>.decorator.<locals>.wrapper\u001b[1;34m(*args, **kwargs)\u001b[0m\n\u001b[0;32m    212\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[0;32m    213\u001b[0m     \u001b[38;5;28;01mwith\u001b[39;00m config_context(\n\u001b[0;32m    214\u001b[0m         skip_parameter_validation\u001b[38;5;241m=\u001b[39m(\n\u001b[0;32m    215\u001b[0m             prefer_skip_nested_validation \u001b[38;5;129;01mor\u001b[39;00m global_skip_validation\n\u001b[0;32m    216\u001b[0m         )\n\u001b[0;32m    217\u001b[0m     ):\n\u001b[1;32m--> 218\u001b[0m         \u001b[38;5;28;01mreturn\u001b[39;00m func(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n\u001b[0;32m    219\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m InvalidParameterError \u001b[38;5;28;01mas\u001b[39;00m e:\n\u001b[0;32m    220\u001b[0m     \u001b[38;5;66;03m# When the function is just a wrapper around an estimator, we allow\u001b[39;00m\n\u001b[0;32m    221\u001b[0m     \u001b[38;5;66;03m# the function to delegate validation to the estimator, but we replace\u001b[39;00m\n\u001b[0;32m    222\u001b[0m     \u001b[38;5;66;03m# the name of the estimator by the name of the function in the error\u001b[39;00m\n\u001b[0;32m    223\u001b[0m     \u001b[38;5;66;03m# message to avoid confusion.\u001b[39;00m\n\u001b[0;32m    224\u001b[0m     msg \u001b[38;5;241m=\u001b[39m re\u001b[38;5;241m.\u001b[39msub(\n\u001b[0;32m    225\u001b[0m         \u001b[38;5;124mr\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mparameter of \u001b[39m\u001b[38;5;124m\\\u001b[39m\u001b[38;5;124mw+ must be\u001b[39m\u001b[38;5;124m\"\u001b[39m,\n\u001b[0;32m    226\u001b[0m         \u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mparameter of \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mfunc\u001b[38;5;241m.\u001b[39m\u001b[38;5;18m__qualname__\u001b[39m\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m must be\u001b[39m\u001b[38;5;124m\"\u001b[39m,\n\u001b[0;32m    227\u001b[0m         \u001b[38;5;28mstr\u001b[39m(e),\n\u001b[0;32m    228\u001b[0m     )\n",
      "File \u001b[1;32mc:\\Users\\Yann\\anaconda3\\envs\\hf_gpu_env\\lib\\site-packages\\sklearn\\metrics\\_classification.py:2945\u001b[0m, in \u001b[0;36mclassification_report\u001b[1;34m(y_true, y_pred, labels, target_names, sample_weight, digits, output_dict, zero_division)\u001b[0m\n\u001b[0;32m   2939\u001b[0m         warnings\u001b[38;5;241m.\u001b[39mwarn(\n\u001b[0;32m   2940\u001b[0m             \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mlabels size, \u001b[39m\u001b[38;5;132;01m{0}\u001b[39;00m\u001b[38;5;124m, does not match size of target_names, \u001b[39m\u001b[38;5;132;01m{1}\u001b[39;00m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;241m.\u001b[39mformat(\n\u001b[0;32m   2941\u001b[0m                 \u001b[38;5;28mlen\u001b[39m(labels), \u001b[38;5;28mlen\u001b[39m(target_names)\n\u001b[0;32m   2942\u001b[0m             )\n\u001b[0;32m   2943\u001b[0m         )\n\u001b[0;32m   2944\u001b[0m     \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m-> 2945\u001b[0m         \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mValueError\u001b[39;00m(\n\u001b[0;32m   2946\u001b[0m             \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mNumber of classes, \u001b[39m\u001b[38;5;132;01m{0}\u001b[39;00m\u001b[38;5;124m, does not match size of \u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m   2947\u001b[0m             \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mtarget_names, \u001b[39m\u001b[38;5;132;01m{1}\u001b[39;00m\u001b[38;5;124m. Try specifying the labels \u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m   2948\u001b[0m             \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mparameter\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;241m.\u001b[39mformat(\u001b[38;5;28mlen\u001b[39m(labels), \u001b[38;5;28mlen\u001b[39m(target_names))\n\u001b[0;32m   2949\u001b[0m         )\n\u001b[0;32m   2950\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m target_names \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[0;32m   2951\u001b[0m     target_names \u001b[38;5;241m=\u001b[39m [\u001b[38;5;124m\"\u001b[39m\u001b[38;5;132;01m%s\u001b[39;00m\u001b[38;5;124m\"\u001b[39m \u001b[38;5;241m%\u001b[39m l \u001b[38;5;28;01mfor\u001b[39;00m l \u001b[38;5;129;01min\u001b[39;00m labels]\n",
      "\u001b[1;31mValueError\u001b[0m: Number of classes, 29, does not match size of target_names, 28. Try specifying the labels parameter"
     ]
    }
   ],
   "source": [
    "from sklearn.metrics import classification_report\n",
    "\n",
    "# Get predictions\n",
    "raw_preds = trainer.predict(tokenized_dataset[\"test\"])\n",
    "probs = torch.sigmoid(torch.tensor(raw_preds.predictions)).numpy()\n",
    "preds = (probs > 0.5).astype(int)\n",
    "\n",
    "print(classification_report(raw_preds.label_ids, preds, target_names=label_cols))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "14833067",
   "metadata": {},
   "source": [
    "## Classification multilabel détaillée par label"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "ad1eac47",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "ename": "ValueError",
     "evalue": "Number of classes, 29, does not match size of target_names, 28. Try specifying the labels parameter",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[32], line 17\u001b[0m\n\u001b[0;32m     14\u001b[0m target_names \u001b[38;5;241m=\u001b[39m label_cols  \u001b[38;5;66;03m# par exemple : ['joy', 'anger', 'admiration', ...]\u001b[39;00m\n\u001b[0;32m     16\u001b[0m \u001b[38;5;66;03m# Rapport détaillé\u001b[39;00m\n\u001b[1;32m---> 17\u001b[0m \u001b[38;5;28mprint\u001b[39m(\u001b[43mclassification_report\u001b[49m\u001b[43m(\u001b[49m\u001b[43my_true\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mpreds\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mtarget_names\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mtarget_names\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mzero_division\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;241;43m0\u001b[39;49m\u001b[43m)\u001b[49m)\n",
      "File \u001b[1;32mc:\\Users\\Yann\\anaconda3\\envs\\hf_gpu_env\\lib\\site-packages\\sklearn\\utils\\_param_validation.py:218\u001b[0m, in \u001b[0;36mvalidate_params.<locals>.decorator.<locals>.wrapper\u001b[1;34m(*args, **kwargs)\u001b[0m\n\u001b[0;32m    212\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[0;32m    213\u001b[0m     \u001b[38;5;28;01mwith\u001b[39;00m config_context(\n\u001b[0;32m    214\u001b[0m         skip_parameter_validation\u001b[38;5;241m=\u001b[39m(\n\u001b[0;32m    215\u001b[0m             prefer_skip_nested_validation \u001b[38;5;129;01mor\u001b[39;00m global_skip_validation\n\u001b[0;32m    216\u001b[0m         )\n\u001b[0;32m    217\u001b[0m     ):\n\u001b[1;32m--> 218\u001b[0m         \u001b[38;5;28;01mreturn\u001b[39;00m func(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n\u001b[0;32m    219\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m InvalidParameterError \u001b[38;5;28;01mas\u001b[39;00m e:\n\u001b[0;32m    220\u001b[0m     \u001b[38;5;66;03m# When the function is just a wrapper around an estimator, we allow\u001b[39;00m\n\u001b[0;32m    221\u001b[0m     \u001b[38;5;66;03m# the function to delegate validation to the estimator, but we replace\u001b[39;00m\n\u001b[0;32m    222\u001b[0m     \u001b[38;5;66;03m# the name of the estimator by the name of the function in the error\u001b[39;00m\n\u001b[0;32m    223\u001b[0m     \u001b[38;5;66;03m# message to avoid confusion.\u001b[39;00m\n\u001b[0;32m    224\u001b[0m     msg \u001b[38;5;241m=\u001b[39m re\u001b[38;5;241m.\u001b[39msub(\n\u001b[0;32m    225\u001b[0m         \u001b[38;5;124mr\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mparameter of \u001b[39m\u001b[38;5;124m\\\u001b[39m\u001b[38;5;124mw+ must be\u001b[39m\u001b[38;5;124m\"\u001b[39m,\n\u001b[0;32m    226\u001b[0m         \u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mparameter of \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mfunc\u001b[38;5;241m.\u001b[39m\u001b[38;5;18m__qualname__\u001b[39m\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m must be\u001b[39m\u001b[38;5;124m\"\u001b[39m,\n\u001b[0;32m    227\u001b[0m         \u001b[38;5;28mstr\u001b[39m(e),\n\u001b[0;32m    228\u001b[0m     )\n",
      "File \u001b[1;32mc:\\Users\\Yann\\anaconda3\\envs\\hf_gpu_env\\lib\\site-packages\\sklearn\\metrics\\_classification.py:2945\u001b[0m, in \u001b[0;36mclassification_report\u001b[1;34m(y_true, y_pred, labels, target_names, sample_weight, digits, output_dict, zero_division)\u001b[0m\n\u001b[0;32m   2939\u001b[0m         warnings\u001b[38;5;241m.\u001b[39mwarn(\n\u001b[0;32m   2940\u001b[0m             \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mlabels size, \u001b[39m\u001b[38;5;132;01m{0}\u001b[39;00m\u001b[38;5;124m, does not match size of target_names, \u001b[39m\u001b[38;5;132;01m{1}\u001b[39;00m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;241m.\u001b[39mformat(\n\u001b[0;32m   2941\u001b[0m                 \u001b[38;5;28mlen\u001b[39m(labels), \u001b[38;5;28mlen\u001b[39m(target_names)\n\u001b[0;32m   2942\u001b[0m             )\n\u001b[0;32m   2943\u001b[0m         )\n\u001b[0;32m   2944\u001b[0m     \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m-> 2945\u001b[0m         \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mValueError\u001b[39;00m(\n\u001b[0;32m   2946\u001b[0m             \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mNumber of classes, \u001b[39m\u001b[38;5;132;01m{0}\u001b[39;00m\u001b[38;5;124m, does not match size of \u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m   2947\u001b[0m             \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mtarget_names, \u001b[39m\u001b[38;5;132;01m{1}\u001b[39;00m\u001b[38;5;124m. Try specifying the labels \u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m   2948\u001b[0m             \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mparameter\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;241m.\u001b[39mformat(\u001b[38;5;28mlen\u001b[39m(labels), \u001b[38;5;28mlen\u001b[39m(target_names))\n\u001b[0;32m   2949\u001b[0m         )\n\u001b[0;32m   2950\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m target_names \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[0;32m   2951\u001b[0m     target_names \u001b[38;5;241m=\u001b[39m [\u001b[38;5;124m\"\u001b[39m\u001b[38;5;132;01m%s\u001b[39;00m\u001b[38;5;124m\"\u001b[39m \u001b[38;5;241m%\u001b[39m l \u001b[38;5;28;01mfor\u001b[39;00m l \u001b[38;5;129;01min\u001b[39;00m labels]\n",
      "\u001b[1;31mValueError\u001b[0m: Number of classes, 29, does not match size of target_names, 28. Try specifying the labels parameter"
     ]
    }
   ],
   "source": [
    "from sklearn.metrics import classification_report\n",
    "import numpy as np\n",
    "import torch\n",
    "\n",
    "# Générer les prédictions finales\n",
    "raw_preds = trainer.predict(tokenized_dataset[\"test\"])\n",
    "probs = torch.sigmoid(torch.tensor(raw_preds.predictions)).numpy()\n",
    "preds = (probs > 0.5).astype(int)\n",
    "\n",
    "# Labels ground truth\n",
    "y_true = raw_preds.label_ids\n",
    "\n",
    "# Liste des noms d’émotions\n",
    "target_names = label_cols  # par exemple : ['joy', 'anger', 'admiration', ...]\n",
    "\n",
    "# Rapport détaillé\n",
    "print(classification_report(y_true, preds, target_names=target_names, zero_division=0))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5bdca836",
   "metadata": {},
   "source": [
    "## heatmap (emotion vs performance)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "0ac23be4",
   "metadata": {},
   "outputs": [
    {
     "ename": "ValueError",
     "evalue": "Number of classes, 29, does not match size of target_names, 28. Try specifying the labels parameter",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[31], line 13\u001b[0m\n\u001b[0;32m     10\u001b[0m y_true \u001b[38;5;241m=\u001b[39m raw_preds\u001b[38;5;241m.\u001b[39mlabel_ids\n\u001b[0;32m     12\u001b[0m \u001b[38;5;66;03m# Générer rapport détaillé\u001b[39;00m\n\u001b[1;32m---> 13\u001b[0m report \u001b[38;5;241m=\u001b[39m \u001b[43mclassification_report\u001b[49m\u001b[43m(\u001b[49m\u001b[43my_true\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mpreds\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mtarget_names\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mlabel_cols\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mzero_division\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;241;43m0\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43moutput_dict\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43;01mTrue\u001b[39;49;00m\u001b[43m)\u001b[49m\n\u001b[0;32m     15\u001b[0m \u001b[38;5;66;03m# Convertir en DataFrame\u001b[39;00m\n\u001b[0;32m     16\u001b[0m df_report \u001b[38;5;241m=\u001b[39m pd\u001b[38;5;241m.\u001b[39mDataFrame(report)\u001b[38;5;241m.\u001b[39mtranspose()\n",
      "File \u001b[1;32mc:\\Users\\Yann\\anaconda3\\envs\\hf_gpu_env\\lib\\site-packages\\sklearn\\utils\\_param_validation.py:218\u001b[0m, in \u001b[0;36mvalidate_params.<locals>.decorator.<locals>.wrapper\u001b[1;34m(*args, **kwargs)\u001b[0m\n\u001b[0;32m    212\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[0;32m    213\u001b[0m     \u001b[38;5;28;01mwith\u001b[39;00m config_context(\n\u001b[0;32m    214\u001b[0m         skip_parameter_validation\u001b[38;5;241m=\u001b[39m(\n\u001b[0;32m    215\u001b[0m             prefer_skip_nested_validation \u001b[38;5;129;01mor\u001b[39;00m global_skip_validation\n\u001b[0;32m    216\u001b[0m         )\n\u001b[0;32m    217\u001b[0m     ):\n\u001b[1;32m--> 218\u001b[0m         \u001b[38;5;28;01mreturn\u001b[39;00m func(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n\u001b[0;32m    219\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m InvalidParameterError \u001b[38;5;28;01mas\u001b[39;00m e:\n\u001b[0;32m    220\u001b[0m     \u001b[38;5;66;03m# When the function is just a wrapper around an estimator, we allow\u001b[39;00m\n\u001b[0;32m    221\u001b[0m     \u001b[38;5;66;03m# the function to delegate validation to the estimator, but we replace\u001b[39;00m\n\u001b[0;32m    222\u001b[0m     \u001b[38;5;66;03m# the name of the estimator by the name of the function in the error\u001b[39;00m\n\u001b[0;32m    223\u001b[0m     \u001b[38;5;66;03m# message to avoid confusion.\u001b[39;00m\n\u001b[0;32m    224\u001b[0m     msg \u001b[38;5;241m=\u001b[39m re\u001b[38;5;241m.\u001b[39msub(\n\u001b[0;32m    225\u001b[0m         \u001b[38;5;124mr\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mparameter of \u001b[39m\u001b[38;5;124m\\\u001b[39m\u001b[38;5;124mw+ must be\u001b[39m\u001b[38;5;124m\"\u001b[39m,\n\u001b[0;32m    226\u001b[0m         \u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mparameter of \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mfunc\u001b[38;5;241m.\u001b[39m\u001b[38;5;18m__qualname__\u001b[39m\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m must be\u001b[39m\u001b[38;5;124m\"\u001b[39m,\n\u001b[0;32m    227\u001b[0m         \u001b[38;5;28mstr\u001b[39m(e),\n\u001b[0;32m    228\u001b[0m     )\n",
      "File \u001b[1;32mc:\\Users\\Yann\\anaconda3\\envs\\hf_gpu_env\\lib\\site-packages\\sklearn\\metrics\\_classification.py:2945\u001b[0m, in \u001b[0;36mclassification_report\u001b[1;34m(y_true, y_pred, labels, target_names, sample_weight, digits, output_dict, zero_division)\u001b[0m\n\u001b[0;32m   2939\u001b[0m         warnings\u001b[38;5;241m.\u001b[39mwarn(\n\u001b[0;32m   2940\u001b[0m             \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mlabels size, \u001b[39m\u001b[38;5;132;01m{0}\u001b[39;00m\u001b[38;5;124m, does not match size of target_names, \u001b[39m\u001b[38;5;132;01m{1}\u001b[39;00m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;241m.\u001b[39mformat(\n\u001b[0;32m   2941\u001b[0m                 \u001b[38;5;28mlen\u001b[39m(labels), \u001b[38;5;28mlen\u001b[39m(target_names)\n\u001b[0;32m   2942\u001b[0m             )\n\u001b[0;32m   2943\u001b[0m         )\n\u001b[0;32m   2944\u001b[0m     \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m-> 2945\u001b[0m         \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mValueError\u001b[39;00m(\n\u001b[0;32m   2946\u001b[0m             \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mNumber of classes, \u001b[39m\u001b[38;5;132;01m{0}\u001b[39;00m\u001b[38;5;124m, does not match size of \u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m   2947\u001b[0m             \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mtarget_names, \u001b[39m\u001b[38;5;132;01m{1}\u001b[39;00m\u001b[38;5;124m. Try specifying the labels \u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m   2948\u001b[0m             \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mparameter\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;241m.\u001b[39mformat(\u001b[38;5;28mlen\u001b[39m(labels), \u001b[38;5;28mlen\u001b[39m(target_names))\n\u001b[0;32m   2949\u001b[0m         )\n\u001b[0;32m   2950\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m target_names \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[0;32m   2951\u001b[0m     target_names \u001b[38;5;241m=\u001b[39m [\u001b[38;5;124m\"\u001b[39m\u001b[38;5;132;01m%s\u001b[39;00m\u001b[38;5;124m\"\u001b[39m \u001b[38;5;241m%\u001b[39m l \u001b[38;5;28;01mfor\u001b[39;00m l \u001b[38;5;129;01min\u001b[39;00m labels]\n",
      "\u001b[1;31mValueError\u001b[0m: Number of classes, 29, does not match size of target_names, 28. Try specifying the labels parameter"
     ]
    }
   ],
   "source": [
    "from sklearn.metrics import classification_report\n",
    "import pandas as pd\n",
    "import torch\n",
    "import seaborn as sns\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "# Prédictions avec seuil 0.5\n",
    "probs = torch.sigmoid(torch.tensor(raw_preds.predictions)).numpy()\n",
    "preds = (probs > 0.5).astype(int)\n",
    "y_true = raw_preds.label_ids\n",
    "\n",
    "# Générer rapport détaillé\n",
    "report = classification_report(y_true, preds, target_names=label_cols, zero_division=0, output_dict=True)\n",
    "\n",
    "# Convertir en DataFrame\n",
    "df_report = pd.DataFrame(report).transpose()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "6de075e6",
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'df_report' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[30], line 3\u001b[0m\n\u001b[0;32m      1\u001b[0m plt\u001b[38;5;241m.\u001b[39mfigure(figsize\u001b[38;5;241m=\u001b[39m(\u001b[38;5;241m12\u001b[39m, \u001b[38;5;241m6\u001b[39m))\n\u001b[0;32m      2\u001b[0m sns\u001b[38;5;241m.\u001b[39mheatmap(\n\u001b[1;32m----> 3\u001b[0m     \u001b[43mdf_report\u001b[49m\u001b[38;5;241m.\u001b[39mloc[label_cols][[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mprecision\u001b[39m\u001b[38;5;124m'\u001b[39m, \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mrecall\u001b[39m\u001b[38;5;124m'\u001b[39m, \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mf1-score\u001b[39m\u001b[38;5;124m'\u001b[39m]],\n\u001b[0;32m      4\u001b[0m     annot\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mTrue\u001b[39;00m, fmt\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m.2f\u001b[39m\u001b[38;5;124m\"\u001b[39m, cmap\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mYlGnBu\u001b[39m\u001b[38;5;124m\"\u001b[39m, cbar\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mTrue\u001b[39;00m\n\u001b[0;32m      5\u001b[0m )\n\u001b[0;32m      6\u001b[0m plt\u001b[38;5;241m.\u001b[39mtitle(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m🎯 Classification Multilabel — Par Émotion\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[0;32m      7\u001b[0m plt\u001b[38;5;241m.\u001b[39mylabel(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mÉmotions\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n",
      "\u001b[1;31mNameError\u001b[0m: name 'df_report' is not defined"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<Figure size 1200x600 with 0 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.figure(figsize=(12, 6))\n",
    "sns.heatmap(\n",
    "    df_report.loc[label_cols][['precision', 'recall', 'f1-score']],\n",
    "    annot=True, fmt=\".2f\", cmap=\"YlGnBu\", cbar=True\n",
    ")\n",
    "plt.title(\"🎯 Classification Multilabel — Par Émotion\")\n",
    "plt.ylabel(\"Émotions\")\n",
    "plt.xlabel(\"Métriques\")\n",
    "plt.tight_layout()\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d585f1ac",
   "metadata": {},
   "source": [
    "# Top modèle"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c4335a56",
   "metadata": {},
   "source": [
    "🏆 Classement Final des Modèles (du meilleur au moins bon)\n",
    "1. 🥇 RoBERTa Fine-tuning\n",
    "F1 micro : 0.373\n",
    "F1 macro : 0.277\n",
    "Hamming loss : 0.037\n",
    "✅ MEILLEUR MODÈLE - Performance supérieure grâce au fine-tuning\n",
    "2. 🥈 TF-IDF + Random Forest\n",
    "F1 micro : 0.352\n",
    "F1 macro : 0.276\n",
    "Hamming loss : 0.045\n",
    "✅ Excellent rapport performance/simplicité\n",
    "3. 🥉 Sentence-BERT (MPNet) + MLP Classifier\n",
    "F1 micro : 0.350\n",
    "F1 macro : 0.267\n",
    "Hamming loss : 0.043\n",
    "✅ Bonnes performances avec embeddings riches\n",
    "4. TF-IDF + Régression Logistique\n",
    "F1 micro : 0.238\n",
    "F1 macro : 0.170\n",
    "Hamming loss : 0.040\n",
    "⚪ Baseline acceptable mais limitée\n",
    "5. Sentence-BERT + LightGBM\n",
    "F1 micro : 0.185\n",
    "F1 macro : 0.168\n",
    "❌ Performance décevante\n",
    "6. Sentence-BERT (MiniLM) + Régression Logistique\n",
    "F1 micro : 0.184\n",
    "F1 macro : 0.124\n",
    "❌ Résultats inattendus et décevants\n",
    "7. Sentence-BERT (MPNet) + Régression Logistique\n",
    "F1 micro : 0.171\n",
    "F1 macro : 0.112\n",
    "❌ Plus mauvaises performances\n",
    "🎯 Conclusion\n",
    "RoBERTa avec fine-tuning est désormais le champion ! Il dépasse tous les autres modèles grâce à :\n",
    "Sa capacité à apprendre des représentations spécifiques au dataset d'émotions\n",
    "L'adaptation de ses poids pré-entraînés à la tâche de classification multi-label\n",
    "Une architecture transformer complète plutôt que des embeddings figés\n",
    "Le Random Forest reste une excellente alternative avec un bon rapport performance/simplicité pour une approche non-transformer."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "343a2197",
   "metadata": {},
   "source": [
    "# Suite"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ae4994c2",
   "metadata": {},
   "source": [
    "bien que roberta à le meilleur modèle, et les autres modèles sont plus simple, nous cherchons la perforamnce maximale pour notre modèle car la précision est importante en terme de service support client"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "da9b1aeb",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting transformers==4.35.0\n",
      "  Downloading transformers-4.35.0-py3-none-any.whl.metadata (123 kB)\n",
      "Requirement already satisfied: filelock in c:\\users\\yann\\anaconda3\\envs\\hf_gpu_env\\lib\\site-packages (from transformers==4.35.0) (3.13.1)\n",
      "Requirement already satisfied: huggingface-hub<1.0,>=0.16.4 in c:\\users\\yann\\anaconda3\\envs\\hf_gpu_env\\lib\\site-packages (from transformers==4.35.0) (0.33.2)\n",
      "Requirement already satisfied: numpy>=1.17 in c:\\users\\yann\\anaconda3\\envs\\hf_gpu_env\\lib\\site-packages (from transformers==4.35.0) (2.1.2)\n",
      "Requirement already satisfied: packaging>=20.0 in c:\\users\\yann\\anaconda3\\envs\\hf_gpu_env\\lib\\site-packages (from transformers==4.35.0) (25.0)\n",
      "Requirement already satisfied: pyyaml>=5.1 in c:\\users\\yann\\anaconda3\\envs\\hf_gpu_env\\lib\\site-packages (from transformers==4.35.0) (6.0.2)\n",
      "Requirement already satisfied: regex!=2019.12.17 in c:\\users\\yann\\anaconda3\\envs\\hf_gpu_env\\lib\\site-packages (from transformers==4.35.0) (2024.11.6)\n",
      "Requirement already satisfied: requests in c:\\users\\yann\\anaconda3\\envs\\hf_gpu_env\\lib\\site-packages (from transformers==4.35.0) (2.32.4)\n",
      "Collecting tokenizers<0.15,>=0.14 (from transformers==4.35.0)\n",
      "  Downloading tokenizers-0.14.1-cp310-none-win_amd64.whl.metadata (6.8 kB)\n",
      "Requirement already satisfied: safetensors>=0.3.1 in c:\\users\\yann\\anaconda3\\envs\\hf_gpu_env\\lib\\site-packages (from transformers==4.35.0) (0.5.3)\n",
      "Requirement already satisfied: tqdm>=4.27 in c:\\users\\yann\\anaconda3\\envs\\hf_gpu_env\\lib\\site-packages (from transformers==4.35.0) (4.67.1)\n",
      "Requirement already satisfied: fsspec>=2023.5.0 in c:\\users\\yann\\anaconda3\\envs\\hf_gpu_env\\lib\\site-packages (from huggingface-hub<1.0,>=0.16.4->transformers==4.35.0) (2024.6.1)\n",
      "Requirement already satisfied: typing-extensions>=3.7.4.3 in c:\\users\\yann\\anaconda3\\envs\\hf_gpu_env\\lib\\site-packages (from huggingface-hub<1.0,>=0.16.4->transformers==4.35.0) (4.12.2)\n",
      "Collecting huggingface-hub<1.0,>=0.16.4 (from transformers==4.35.0)\n",
      "  Downloading huggingface_hub-0.17.3-py3-none-any.whl.metadata (13 kB)\n",
      "Requirement already satisfied: colorama in c:\\users\\yann\\anaconda3\\envs\\hf_gpu_env\\lib\\site-packages (from tqdm>=4.27->transformers==4.35.0) (0.4.6)\n",
      "Requirement already satisfied: charset_normalizer<4,>=2 in c:\\users\\yann\\anaconda3\\envs\\hf_gpu_env\\lib\\site-packages (from requests->transformers==4.35.0) (3.4.2)\n",
      "Requirement already satisfied: idna<4,>=2.5 in c:\\users\\yann\\anaconda3\\envs\\hf_gpu_env\\lib\\site-packages (from requests->transformers==4.35.0) (3.10)\n",
      "Requirement already satisfied: urllib3<3,>=1.21.1 in c:\\users\\yann\\anaconda3\\envs\\hf_gpu_env\\lib\\site-packages (from requests->transformers==4.35.0) (2.5.0)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in c:\\users\\yann\\anaconda3\\envs\\hf_gpu_env\\lib\\site-packages (from requests->transformers==4.35.0) (2025.6.15)\n",
      "Downloading transformers-4.35.0-py3-none-any.whl (7.9 MB)\n",
      "   ---------------------------------------- 0.0/7.9 MB ? eta -:--:--\n",
      "   --- ------------------------------------ 0.8/7.9 MB 4.2 MB/s eta 0:00:02\n",
      "   --------- ------------------------------ 1.8/7.9 MB 4.4 MB/s eta 0:00:02\n",
      "   --------------- ------------------------ 3.1/7.9 MB 5.1 MB/s eta 0:00:01\n",
      "   --------------------- ------------------ 4.2/7.9 MB 5.5 MB/s eta 0:00:01\n",
      "   --------------------------- ------------ 5.5/7.9 MB 5.6 MB/s eta 0:00:01\n",
      "   ---------------------------------- ----- 6.8/7.9 MB 5.7 MB/s eta 0:00:01\n",
      "   ---------------------------------------  7.9/7.9 MB 5.8 MB/s eta 0:00:01\n",
      "   ---------------------------------------- 7.9/7.9 MB 5.3 MB/s eta 0:00:00\n",
      "Downloading tokenizers-0.14.1-cp310-none-win_amd64.whl (2.2 MB)\n",
      "   ---------------------------------------- 0.0/2.2 MB ? eta -:--:--\n",
      "   ----------------------- ---------------- 1.3/2.2 MB 6.7 MB/s eta 0:00:01\n",
      "   -------------------------------------- - 2.1/2.2 MB 6.2 MB/s eta 0:00:01\n",
      "   ---------------------------------------- 2.2/2.2 MB 5.2 MB/s eta 0:00:00\n",
      "Downloading huggingface_hub-0.17.3-py3-none-any.whl (295 kB)\n",
      "Installing collected packages: huggingface-hub, tokenizers, transformers\n",
      "\n",
      "  Attempting uninstall: huggingface-hub\n",
      "\n",
      "    Found existing installation: huggingface-hub 0.33.2\n",
      "\n",
      "    Uninstalling huggingface-hub-0.33.2:\n",
      "\n",
      "      Successfully uninstalled huggingface-hub-0.33.2\n",
      "\n",
      "   ---------------------------------------- 0/3 [huggingface-hub]\n",
      "   ---------------------------------------- 0/3 [huggingface-hub]\n",
      "   ---------------------------------------- 0/3 [huggingface-hub]\n",
      "  Attempting uninstall: tokenizers\n",
      "   ---------------------------------------- 0/3 [huggingface-hub]\n",
      "    Found existing installation: tokenizers 0.21.2\n",
      "   ---------------------------------------- 0/3 [huggingface-hub]\n",
      "    Uninstalling tokenizers-0.21.2:\n",
      "   ---------------------------------------- 0/3 [huggingface-hub]\n",
      "      Successfully uninstalled tokenizers-0.21.2\n",
      "   ---------------------------------------- 0/3 [huggingface-hub]\n",
      "   ------------- -------------------------- 1/3 [tokenizers]\n",
      "   ------------- -------------------------- 1/3 [tokenizers]\n",
      "   ------------- -------------------------- 1/3 [tokenizers]\n",
      "   ------------- -------------------------- 1/3 [tokenizers]\n",
      "   ------------- -------------------------- 1/3 [tokenizers]\n",
      "   ------------- -------------------------- 1/3 [tokenizers]\n",
      "   ------------- -------------------------- 1/3 [tokenizers]\n",
      "   ------------- -------------------------- 1/3 [tokenizers]\n",
      "   ------------- -------------------------- 1/3 [tokenizers]\n",
      "   ------------- -------------------------- 1/3 [tokenizers]\n",
      "   ------------- -------------------------- 1/3 [tokenizers]\n",
      "   ------------- -------------------------- 1/3 [tokenizers]\n",
      "   ------------- -------------------------- 1/3 [tokenizers]\n",
      "   ------------- -------------------------- 1/3 [tokenizers]\n",
      "   ------------- -------------------------- 1/3 [tokenizers]\n",
      "   ------------- -------------------------- 1/3 [tokenizers]\n",
      "   ------------- -------------------------- 1/3 [tokenizers]\n",
      "   ------------- -------------------------- 1/3 [tokenizers]\n",
      "   ------------- -------------------------- 1/3 [tokenizers]\n",
      "  Attempting uninstall: transformers\n",
      "   ------------- -------------------------- 1/3 [tokenizers]\n",
      "    Found existing installation: transformers 4.53.0\n",
      "   ------------- -------------------------- 1/3 [tokenizers]\n",
      "   -------------------------- ------------- 2/3 [transformers]\n",
      "   -------------------------- ------------- 2/3 [transformers]\n",
      "   -------------------------- ------------- 2/3 [transformers]\n",
      "    Uninstalling transformers-4.53.0:\n",
      "   -------------------------- ------------- 2/3 [transformers]\n",
      "   -------------------------- ------------- 2/3 [transformers]\n",
      "      Successfully uninstalled transformers-4.53.0\n",
      "   -------------------------- ------------- 2/3 [transformers]\n",
      "   -------------------------- ------------- 2/3 [transformers]\n",
      "   -------------------------- ------------- 2/3 [transformers]\n",
      "   -------------------------- ------------- 2/3 [transformers]\n",
      "   -------------------------- ------------- 2/3 [transformers]\n",
      "   -------------------------- ------------- 2/3 [transformers]\n",
      "   -------------------------- ------------- 2/3 [transformers]\n",
      "   -------------------------- ------------- 2/3 [transformers]\n",
      "   -------------------------- ------------- 2/3 [transformers]\n",
      "   -------------------------- ------------- 2/3 [transformers]\n",
      "   -------------------------- ------------- 2/3 [transformers]\n",
      "   -------------------------- ------------- 2/3 [transformers]\n",
      "   -------------------------- ------------- 2/3 [transformers]\n",
      "   -------------------------- ------------- 2/3 [transformers]\n",
      "   -------------------------- ------------- 2/3 [transformers]\n",
      "   -------------------------- ------------- 2/3 [transformers]\n",
      "   -------------------------- ------------- 2/3 [transformers]\n",
      "   -------------------------- ------------- 2/3 [transformers]\n",
      "   -------------------------- ------------- 2/3 [transformers]\n",
      "   -------------------------- ------------- 2/3 [transformers]\n",
      "   -------------------------- ------------- 2/3 [transformers]\n",
      "   -------------------------- ------------- 2/3 [transformers]\n",
      "   -------------------------- ------------- 2/3 [transformers]\n",
      "   -------------------------- ------------- 2/3 [transformers]\n",
      "   -------------------------- ------------- 2/3 [transformers]\n",
      "   -------------------------- ------------- 2/3 [transformers]\n",
      "   -------------------------- ------------- 2/3 [transformers]\n",
      "   -------------------------- ------------- 2/3 [transformers]\n",
      "   -------------------------- ------------- 2/3 [transformers]\n",
      "   -------------------------- ------------- 2/3 [transformers]\n",
      "   -------------------------- ------------- 2/3 [transformers]\n",
      "   -------------------------- ------------- 2/3 [transformers]\n",
      "   -------------------------- ------------- 2/3 [transformers]\n",
      "   -------------------------- ------------- 2/3 [transformers]\n",
      "   -------------------------- ------------- 2/3 [transformers]\n",
      "   -------------------------- ------------- 2/3 [transformers]\n",
      "   -------------------------- ------------- 2/3 [transformers]\n",
      "   -------------------------- ------------- 2/3 [transformers]\n",
      "   -------------------------- ------------- 2/3 [transformers]\n",
      "   -------------------------- ------------- 2/3 [transformers]\n",
      "   -------------------------- ------------- 2/3 [transformers]\n",
      "   -------------------------- ------------- 2/3 [transformers]\n",
      "   -------------------------- ------------- 2/3 [transformers]\n",
      "   -------------------------- ------------- 2/3 [transformers]\n",
      "   -------------------------- ------------- 2/3 [transformers]\n",
      "   -------------------------- ------------- 2/3 [transformers]\n",
      "   -------------------------- ------------- 2/3 [transformers]\n",
      "   -------------------------- ------------- 2/3 [transformers]\n",
      "   -------------------------- ------------- 2/3 [transformers]\n",
      "   -------------------------- ------------- 2/3 [transformers]\n",
      "   -------------------------- ------------- 2/3 [transformers]\n",
      "   -------------------------- ------------- 2/3 [transformers]\n",
      "   -------------------------- ------------- 2/3 [transformers]\n",
      "   -------------------------- ------------- 2/3 [transformers]\n",
      "   -------------------------- ------------- 2/3 [transformers]\n",
      "   -------------------------- ------------- 2/3 [transformers]\n",
      "   -------------------------- ------------- 2/3 [transformers]\n",
      "   -------------------------- ------------- 2/3 [transformers]\n",
      "   -------------------------- ------------- 2/3 [transformers]\n",
      "   -------------------------- ------------- 2/3 [transformers]\n",
      "   -------------------------- ------------- 2/3 [transformers]\n",
      "   -------------------------- ------------- 2/3 [transformers]\n",
      "   -------------------------- ------------- 2/3 [transformers]\n",
      "   -------------------------- ------------- 2/3 [transformers]\n",
      "   -------------------------- ------------- 2/3 [transformers]\n",
      "   -------------------------- ------------- 2/3 [transformers]\n",
      "   -------------------------- ------------- 2/3 [transformers]\n",
      "   -------------------------- ------------- 2/3 [transformers]\n",
      "   -------------------------- ------------- 2/3 [transformers]\n",
      "   -------------------------- ------------- 2/3 [transformers]\n",
      "   -------------------------- ------------- 2/3 [transformers]\n",
      "   -------------------------- ------------- 2/3 [transformers]\n",
      "   -------------------------- ------------- 2/3 [transformers]\n",
      "   -------------------------- ------------- 2/3 [transformers]\n",
      "   -------------------------- ------------- 2/3 [transformers]\n",
      "   -------------------------- ------------- 2/3 [transformers]\n",
      "   -------------------------- ------------- 2/3 [transformers]\n",
      "   -------------------------- ------------- 2/3 [transformers]\n",
      "   -------------------------- ------------- 2/3 [transformers]\n",
      "   -------------------------- ------------- 2/3 [transformers]\n",
      "   -------------------------- ------------- 2/3 [transformers]\n",
      "   -------------------------- ------------- 2/3 [transformers]\n",
      "   -------------------------- ------------- 2/3 [transformers]\n",
      "   -------------------------- ------------- 2/3 [transformers]\n",
      "   -------------------------- ------------- 2/3 [transformers]\n",
      "   -------------------------- ------------- 2/3 [transformers]\n",
      "   -------------------------- ------------- 2/3 [transformers]\n",
      "   -------------------------- ------------- 2/3 [transformers]\n",
      "   -------------------------- ------------- 2/3 [transformers]\n",
      "   -------------------------- ------------- 2/3 [transformers]\n",
      "   -------------------------- ------------- 2/3 [transformers]\n",
      "   -------------------------- ------------- 2/3 [transformers]\n",
      "   -------------------------- ------------- 2/3 [transformers]\n",
      "   ---------------------------------------- 3/3 [transformers]\n",
      "\n",
      "Successfully installed huggingface-hub-0.17.3 tokenizers-0.14.1 transformers-4.35.0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  WARNING: Failed to remove contents in a temporary directory 'C:\\Users\\Yann\\anaconda3\\envs\\hf_gpu_env\\Lib\\site-packages\\~-kenizers'.\n",
      "  You can safely remove it manually.\n",
      "ERROR: pip's dependency resolver does not currently take into account all the packages that are installed. This behaviour is the source of the following dependency conflicts.\n",
      "accelerate 1.8.1 requires huggingface_hub>=0.21.0, but you have huggingface-hub 0.17.3 which is incompatible.\n",
      "datasets 3.6.0 requires huggingface-hub>=0.24.0, but you have huggingface-hub 0.17.3 which is incompatible.\n",
      "sentence-transformers 5.0.0 requires huggingface-hub>=0.20.0, but you have huggingface-hub 0.17.3 which is incompatible.\n",
      "sentence-transformers 5.0.0 requires transformers<5.0.0,>=4.41.0, but you have transformers 4.35.0 which is incompatible.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: datasets in c:\\users\\yann\\anaconda3\\envs\\hf_gpu_env\\lib\\site-packages (3.6.0)\n",
      "Requirement already satisfied: filelock in c:\\users\\yann\\anaconda3\\envs\\hf_gpu_env\\lib\\site-packages (from datasets) (3.13.1)\n",
      "Requirement already satisfied: numpy>=1.17 in c:\\users\\yann\\anaconda3\\envs\\hf_gpu_env\\lib\\site-packages (from datasets) (2.1.2)\n",
      "Requirement already satisfied: pyarrow>=15.0.0 in c:\\users\\yann\\anaconda3\\envs\\hf_gpu_env\\lib\\site-packages (from datasets) (20.0.0)\n",
      "Requirement already satisfied: dill<0.3.9,>=0.3.0 in c:\\users\\yann\\anaconda3\\envs\\hf_gpu_env\\lib\\site-packages (from datasets) (0.3.8)\n",
      "Requirement already satisfied: pandas in c:\\users\\yann\\anaconda3\\envs\\hf_gpu_env\\lib\\site-packages (from datasets) (2.3.0)\n",
      "Requirement already satisfied: requests>=2.32.2 in c:\\users\\yann\\anaconda3\\envs\\hf_gpu_env\\lib\\site-packages (from datasets) (2.32.4)\n",
      "Requirement already satisfied: tqdm>=4.66.3 in c:\\users\\yann\\anaconda3\\envs\\hf_gpu_env\\lib\\site-packages (from datasets) (4.67.1)\n",
      "Requirement already satisfied: xxhash in c:\\users\\yann\\anaconda3\\envs\\hf_gpu_env\\lib\\site-packages (from datasets) (3.5.0)\n",
      "Requirement already satisfied: multiprocess<0.70.17 in c:\\users\\yann\\anaconda3\\envs\\hf_gpu_env\\lib\\site-packages (from datasets) (0.70.16)\n",
      "Requirement already satisfied: fsspec<=2025.3.0,>=2023.1.0 in c:\\users\\yann\\anaconda3\\envs\\hf_gpu_env\\lib\\site-packages (from fsspec[http]<=2025.3.0,>=2023.1.0->datasets) (2024.6.1)\n",
      "Collecting huggingface-hub>=0.24.0 (from datasets)\n",
      "  Using cached huggingface_hub-0.33.2-py3-none-any.whl.metadata (14 kB)\n",
      "Requirement already satisfied: packaging in c:\\users\\yann\\anaconda3\\envs\\hf_gpu_env\\lib\\site-packages (from datasets) (25.0)\n",
      "Requirement already satisfied: pyyaml>=5.1 in c:\\users\\yann\\anaconda3\\envs\\hf_gpu_env\\lib\\site-packages (from datasets) (6.0.2)\n",
      "Requirement already satisfied: aiohttp!=4.0.0a0,!=4.0.0a1 in c:\\users\\yann\\anaconda3\\envs\\hf_gpu_env\\lib\\site-packages (from fsspec[http]<=2025.3.0,>=2023.1.0->datasets) (3.12.13)\n",
      "Requirement already satisfied: aiohappyeyeballs>=2.5.0 in c:\\users\\yann\\anaconda3\\envs\\hf_gpu_env\\lib\\site-packages (from aiohttp!=4.0.0a0,!=4.0.0a1->fsspec[http]<=2025.3.0,>=2023.1.0->datasets) (2.6.1)\n",
      "Requirement already satisfied: aiosignal>=1.1.2 in c:\\users\\yann\\anaconda3\\envs\\hf_gpu_env\\lib\\site-packages (from aiohttp!=4.0.0a0,!=4.0.0a1->fsspec[http]<=2025.3.0,>=2023.1.0->datasets) (1.3.2)\n",
      "Requirement already satisfied: async-timeout<6.0,>=4.0 in c:\\users\\yann\\anaconda3\\envs\\hf_gpu_env\\lib\\site-packages (from aiohttp!=4.0.0a0,!=4.0.0a1->fsspec[http]<=2025.3.0,>=2023.1.0->datasets) (5.0.1)\n",
      "Requirement already satisfied: attrs>=17.3.0 in c:\\users\\yann\\anaconda3\\envs\\hf_gpu_env\\lib\\site-packages (from aiohttp!=4.0.0a0,!=4.0.0a1->fsspec[http]<=2025.3.0,>=2023.1.0->datasets) (25.3.0)\n",
      "Requirement already satisfied: frozenlist>=1.1.1 in c:\\users\\yann\\anaconda3\\envs\\hf_gpu_env\\lib\\site-packages (from aiohttp!=4.0.0a0,!=4.0.0a1->fsspec[http]<=2025.3.0,>=2023.1.0->datasets) (1.7.0)\n",
      "Requirement already satisfied: multidict<7.0,>=4.5 in c:\\users\\yann\\anaconda3\\envs\\hf_gpu_env\\lib\\site-packages (from aiohttp!=4.0.0a0,!=4.0.0a1->fsspec[http]<=2025.3.0,>=2023.1.0->datasets) (6.6.3)\n",
      "Requirement already satisfied: propcache>=0.2.0 in c:\\users\\yann\\anaconda3\\envs\\hf_gpu_env\\lib\\site-packages (from aiohttp!=4.0.0a0,!=4.0.0a1->fsspec[http]<=2025.3.0,>=2023.1.0->datasets) (0.3.2)\n",
      "Requirement already satisfied: yarl<2.0,>=1.17.0 in c:\\users\\yann\\anaconda3\\envs\\hf_gpu_env\\lib\\site-packages (from aiohttp!=4.0.0a0,!=4.0.0a1->fsspec[http]<=2025.3.0,>=2023.1.0->datasets) (1.20.1)\n",
      "Requirement already satisfied: typing-extensions>=4.1.0 in c:\\users\\yann\\anaconda3\\envs\\hf_gpu_env\\lib\\site-packages (from multidict<7.0,>=4.5->aiohttp!=4.0.0a0,!=4.0.0a1->fsspec[http]<=2025.3.0,>=2023.1.0->datasets) (4.12.2)\n",
      "Requirement already satisfied: idna>=2.0 in c:\\users\\yann\\anaconda3\\envs\\hf_gpu_env\\lib\\site-packages (from yarl<2.0,>=1.17.0->aiohttp!=4.0.0a0,!=4.0.0a1->fsspec[http]<=2025.3.0,>=2023.1.0->datasets) (3.10)\n",
      "Requirement already satisfied: charset_normalizer<4,>=2 in c:\\users\\yann\\anaconda3\\envs\\hf_gpu_env\\lib\\site-packages (from requests>=2.32.2->datasets) (3.4.2)\n",
      "Requirement already satisfied: urllib3<3,>=1.21.1 in c:\\users\\yann\\anaconda3\\envs\\hf_gpu_env\\lib\\site-packages (from requests>=2.32.2->datasets) (2.5.0)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in c:\\users\\yann\\anaconda3\\envs\\hf_gpu_env\\lib\\site-packages (from requests>=2.32.2->datasets) (2025.6.15)\n",
      "Requirement already satisfied: colorama in c:\\users\\yann\\anaconda3\\envs\\hf_gpu_env\\lib\\site-packages (from tqdm>=4.66.3->datasets) (0.4.6)\n",
      "Requirement already satisfied: python-dateutil>=2.8.2 in c:\\users\\yann\\anaconda3\\envs\\hf_gpu_env\\lib\\site-packages (from pandas->datasets) (2.9.0.post0)\n",
      "Requirement already satisfied: pytz>=2020.1 in c:\\users\\yann\\anaconda3\\envs\\hf_gpu_env\\lib\\site-packages (from pandas->datasets) (2025.2)\n",
      "Requirement already satisfied: tzdata>=2022.7 in c:\\users\\yann\\anaconda3\\envs\\hf_gpu_env\\lib\\site-packages (from pandas->datasets) (2025.2)\n",
      "Requirement already satisfied: six>=1.5 in c:\\users\\yann\\anaconda3\\envs\\hf_gpu_env\\lib\\site-packages (from python-dateutil>=2.8.2->pandas->datasets) (1.17.0)\n",
      "Using cached huggingface_hub-0.33.2-py3-none-any.whl (515 kB)\n",
      "Installing collected packages: huggingface-hub\n",
      "  Attempting uninstall: huggingface-hub\n",
      "    Found existing installation: huggingface-hub 0.17.3\n",
      "    Uninstalling huggingface-hub-0.17.3:\n",
      "      Successfully uninstalled huggingface-hub-0.17.3\n",
      "Successfully installed huggingface-hub-0.33.2\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "ERROR: pip's dependency resolver does not currently take into account all the packages that are installed. This behaviour is the source of the following dependency conflicts.\n",
      "sentence-transformers 5.0.0 requires transformers<5.0.0,>=4.41.0, but you have transformers 4.35.0 which is incompatible.\n",
      "tokenizers 0.14.1 requires huggingface_hub<0.18,>=0.16.4, but you have huggingface-hub 0.33.2 which is incompatible.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: accelerate in c:\\users\\yann\\anaconda3\\envs\\hf_gpu_env\\lib\\site-packages (1.8.1)\n",
      "Requirement already satisfied: numpy<3.0.0,>=1.17 in c:\\users\\yann\\anaconda3\\envs\\hf_gpu_env\\lib\\site-packages (from accelerate) (2.1.2)\n",
      "Requirement already satisfied: packaging>=20.0 in c:\\users\\yann\\anaconda3\\envs\\hf_gpu_env\\lib\\site-packages (from accelerate) (25.0)\n",
      "Requirement already satisfied: psutil in c:\\users\\yann\\anaconda3\\envs\\hf_gpu_env\\lib\\site-packages (from accelerate) (7.0.0)\n",
      "Requirement already satisfied: pyyaml in c:\\users\\yann\\anaconda3\\envs\\hf_gpu_env\\lib\\site-packages (from accelerate) (6.0.2)\n",
      "Requirement already satisfied: torch>=2.0.0 in c:\\users\\yann\\anaconda3\\envs\\hf_gpu_env\\lib\\site-packages (from accelerate) (2.5.1+cu121)\n",
      "Requirement already satisfied: huggingface_hub>=0.21.0 in c:\\users\\yann\\anaconda3\\envs\\hf_gpu_env\\lib\\site-packages (from accelerate) (0.33.2)\n",
      "Requirement already satisfied: safetensors>=0.4.3 in c:\\users\\yann\\anaconda3\\envs\\hf_gpu_env\\lib\\site-packages (from accelerate) (0.5.3)\n",
      "Requirement already satisfied: filelock in c:\\users\\yann\\anaconda3\\envs\\hf_gpu_env\\lib\\site-packages (from huggingface_hub>=0.21.0->accelerate) (3.13.1)\n",
      "Requirement already satisfied: fsspec>=2023.5.0 in c:\\users\\yann\\anaconda3\\envs\\hf_gpu_env\\lib\\site-packages (from huggingface_hub>=0.21.0->accelerate) (2024.6.1)\n",
      "Requirement already satisfied: requests in c:\\users\\yann\\anaconda3\\envs\\hf_gpu_env\\lib\\site-packages (from huggingface_hub>=0.21.0->accelerate) (2.32.4)\n",
      "Requirement already satisfied: tqdm>=4.42.1 in c:\\users\\yann\\anaconda3\\envs\\hf_gpu_env\\lib\\site-packages (from huggingface_hub>=0.21.0->accelerate) (4.67.1)\n",
      "Requirement already satisfied: typing-extensions>=3.7.4.3 in c:\\users\\yann\\anaconda3\\envs\\hf_gpu_env\\lib\\site-packages (from huggingface_hub>=0.21.0->accelerate) (4.12.2)\n",
      "Requirement already satisfied: networkx in c:\\users\\yann\\anaconda3\\envs\\hf_gpu_env\\lib\\site-packages (from torch>=2.0.0->accelerate) (3.3)\n",
      "Requirement already satisfied: jinja2 in c:\\users\\yann\\anaconda3\\envs\\hf_gpu_env\\lib\\site-packages (from torch>=2.0.0->accelerate) (3.1.4)\n",
      "Requirement already satisfied: sympy==1.13.1 in c:\\users\\yann\\anaconda3\\envs\\hf_gpu_env\\lib\\site-packages (from torch>=2.0.0->accelerate) (1.13.1)\n",
      "Requirement already satisfied: mpmath<1.4,>=1.1.0 in c:\\users\\yann\\anaconda3\\envs\\hf_gpu_env\\lib\\site-packages (from sympy==1.13.1->torch>=2.0.0->accelerate) (1.3.0)\n",
      "Requirement already satisfied: colorama in c:\\users\\yann\\anaconda3\\envs\\hf_gpu_env\\lib\\site-packages (from tqdm>=4.42.1->huggingface_hub>=0.21.0->accelerate) (0.4.6)\n",
      "Requirement already satisfied: MarkupSafe>=2.0 in c:\\users\\yann\\anaconda3\\envs\\hf_gpu_env\\lib\\site-packages (from jinja2->torch>=2.0.0->accelerate) (2.1.5)\n",
      "Requirement already satisfied: charset_normalizer<4,>=2 in c:\\users\\yann\\anaconda3\\envs\\hf_gpu_env\\lib\\site-packages (from requests->huggingface_hub>=0.21.0->accelerate) (3.4.2)\n",
      "Requirement already satisfied: idna<4,>=2.5 in c:\\users\\yann\\anaconda3\\envs\\hf_gpu_env\\lib\\site-packages (from requests->huggingface_hub>=0.21.0->accelerate) (3.10)\n",
      "Requirement already satisfied: urllib3<3,>=1.21.1 in c:\\users\\yann\\anaconda3\\envs\\hf_gpu_env\\lib\\site-packages (from requests->huggingface_hub>=0.21.0->accelerate) (2.5.0)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in c:\\users\\yann\\anaconda3\\envs\\hf_gpu_env\\lib\\site-packages (from requests->huggingface_hub>=0.21.0->accelerate) (2025.6.15)\n",
      "Requirement already satisfied: evaluate in c:\\users\\yann\\anaconda3\\envs\\hf_gpu_env\\lib\\site-packages (0.4.4)\n",
      "Requirement already satisfied: datasets>=2.0.0 in c:\\users\\yann\\anaconda3\\envs\\hf_gpu_env\\lib\\site-packages (from evaluate) (3.6.0)\n",
      "Requirement already satisfied: numpy>=1.17 in c:\\users\\yann\\anaconda3\\envs\\hf_gpu_env\\lib\\site-packages (from evaluate) (2.1.2)\n",
      "Requirement already satisfied: dill in c:\\users\\yann\\anaconda3\\envs\\hf_gpu_env\\lib\\site-packages (from evaluate) (0.3.8)\n",
      "Requirement already satisfied: pandas in c:\\users\\yann\\anaconda3\\envs\\hf_gpu_env\\lib\\site-packages (from evaluate) (2.3.0)\n",
      "Requirement already satisfied: requests>=2.19.0 in c:\\users\\yann\\anaconda3\\envs\\hf_gpu_env\\lib\\site-packages (from evaluate) (2.32.4)\n",
      "Requirement already satisfied: tqdm>=4.62.1 in c:\\users\\yann\\anaconda3\\envs\\hf_gpu_env\\lib\\site-packages (from evaluate) (4.67.1)\n",
      "Requirement already satisfied: xxhash in c:\\users\\yann\\anaconda3\\envs\\hf_gpu_env\\lib\\site-packages (from evaluate) (3.5.0)\n",
      "Requirement already satisfied: multiprocess in c:\\users\\yann\\anaconda3\\envs\\hf_gpu_env\\lib\\site-packages (from evaluate) (0.70.16)\n",
      "Requirement already satisfied: fsspec>=2021.05.0 in c:\\users\\yann\\anaconda3\\envs\\hf_gpu_env\\lib\\site-packages (from fsspec[http]>=2021.05.0->evaluate) (2024.6.1)\n",
      "Requirement already satisfied: huggingface-hub>=0.7.0 in c:\\users\\yann\\anaconda3\\envs\\hf_gpu_env\\lib\\site-packages (from evaluate) (0.33.2)\n",
      "Requirement already satisfied: packaging in c:\\users\\yann\\anaconda3\\envs\\hf_gpu_env\\lib\\site-packages (from evaluate) (25.0)\n",
      "Requirement already satisfied: filelock in c:\\users\\yann\\anaconda3\\envs\\hf_gpu_env\\lib\\site-packages (from datasets>=2.0.0->evaluate) (3.13.1)\n",
      "Requirement already satisfied: pyarrow>=15.0.0 in c:\\users\\yann\\anaconda3\\envs\\hf_gpu_env\\lib\\site-packages (from datasets>=2.0.0->evaluate) (20.0.0)\n",
      "Requirement already satisfied: pyyaml>=5.1 in c:\\users\\yann\\anaconda3\\envs\\hf_gpu_env\\lib\\site-packages (from datasets>=2.0.0->evaluate) (6.0.2)\n",
      "Requirement already satisfied: aiohttp!=4.0.0a0,!=4.0.0a1 in c:\\users\\yann\\anaconda3\\envs\\hf_gpu_env\\lib\\site-packages (from fsspec[http]>=2021.05.0->evaluate) (3.12.13)\n",
      "Requirement already satisfied: aiohappyeyeballs>=2.5.0 in c:\\users\\yann\\anaconda3\\envs\\hf_gpu_env\\lib\\site-packages (from aiohttp!=4.0.0a0,!=4.0.0a1->fsspec[http]>=2021.05.0->evaluate) (2.6.1)\n",
      "Requirement already satisfied: aiosignal>=1.1.2 in c:\\users\\yann\\anaconda3\\envs\\hf_gpu_env\\lib\\site-packages (from aiohttp!=4.0.0a0,!=4.0.0a1->fsspec[http]>=2021.05.0->evaluate) (1.3.2)\n",
      "Requirement already satisfied: async-timeout<6.0,>=4.0 in c:\\users\\yann\\anaconda3\\envs\\hf_gpu_env\\lib\\site-packages (from aiohttp!=4.0.0a0,!=4.0.0a1->fsspec[http]>=2021.05.0->evaluate) (5.0.1)\n",
      "Requirement already satisfied: attrs>=17.3.0 in c:\\users\\yann\\anaconda3\\envs\\hf_gpu_env\\lib\\site-packages (from aiohttp!=4.0.0a0,!=4.0.0a1->fsspec[http]>=2021.05.0->evaluate) (25.3.0)\n",
      "Requirement already satisfied: frozenlist>=1.1.1 in c:\\users\\yann\\anaconda3\\envs\\hf_gpu_env\\lib\\site-packages (from aiohttp!=4.0.0a0,!=4.0.0a1->fsspec[http]>=2021.05.0->evaluate) (1.7.0)\n",
      "Requirement already satisfied: multidict<7.0,>=4.5 in c:\\users\\yann\\anaconda3\\envs\\hf_gpu_env\\lib\\site-packages (from aiohttp!=4.0.0a0,!=4.0.0a1->fsspec[http]>=2021.05.0->evaluate) (6.6.3)\n",
      "Requirement already satisfied: propcache>=0.2.0 in c:\\users\\yann\\anaconda3\\envs\\hf_gpu_env\\lib\\site-packages (from aiohttp!=4.0.0a0,!=4.0.0a1->fsspec[http]>=2021.05.0->evaluate) (0.3.2)\n",
      "Requirement already satisfied: yarl<2.0,>=1.17.0 in c:\\users\\yann\\anaconda3\\envs\\hf_gpu_env\\lib\\site-packages (from aiohttp!=4.0.0a0,!=4.0.0a1->fsspec[http]>=2021.05.0->evaluate) (1.20.1)\n",
      "Requirement already satisfied: typing-extensions>=4.1.0 in c:\\users\\yann\\anaconda3\\envs\\hf_gpu_env\\lib\\site-packages (from multidict<7.0,>=4.5->aiohttp!=4.0.0a0,!=4.0.0a1->fsspec[http]>=2021.05.0->evaluate) (4.12.2)\n",
      "Requirement already satisfied: idna>=2.0 in c:\\users\\yann\\anaconda3\\envs\\hf_gpu_env\\lib\\site-packages (from yarl<2.0,>=1.17.0->aiohttp!=4.0.0a0,!=4.0.0a1->fsspec[http]>=2021.05.0->evaluate) (3.10)\n",
      "Requirement already satisfied: charset_normalizer<4,>=2 in c:\\users\\yann\\anaconda3\\envs\\hf_gpu_env\\lib\\site-packages (from requests>=2.19.0->evaluate) (3.4.2)\n",
      "Requirement already satisfied: urllib3<3,>=1.21.1 in c:\\users\\yann\\anaconda3\\envs\\hf_gpu_env\\lib\\site-packages (from requests>=2.19.0->evaluate) (2.5.0)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in c:\\users\\yann\\anaconda3\\envs\\hf_gpu_env\\lib\\site-packages (from requests>=2.19.0->evaluate) (2025.6.15)\n",
      "Requirement already satisfied: colorama in c:\\users\\yann\\anaconda3\\envs\\hf_gpu_env\\lib\\site-packages (from tqdm>=4.62.1->evaluate) (0.4.6)\n",
      "Requirement already satisfied: python-dateutil>=2.8.2 in c:\\users\\yann\\anaconda3\\envs\\hf_gpu_env\\lib\\site-packages (from pandas->evaluate) (2.9.0.post0)\n",
      "Requirement already satisfied: pytz>=2020.1 in c:\\users\\yann\\anaconda3\\envs\\hf_gpu_env\\lib\\site-packages (from pandas->evaluate) (2025.2)\n",
      "Requirement already satisfied: tzdata>=2022.7 in c:\\users\\yann\\anaconda3\\envs\\hf_gpu_env\\lib\\site-packages (from pandas->evaluate) (2025.2)\n",
      "Requirement already satisfied: six>=1.5 in c:\\users\\yann\\anaconda3\\envs\\hf_gpu_env\\lib\\site-packages (from python-dateutil>=2.8.2->pandas->evaluate) (1.17.0)\n",
      "Requirement already satisfied: scikit-learn in c:\\users\\yann\\anaconda3\\envs\\hf_gpu_env\\lib\\site-packages (1.7.0)\n",
      "Requirement already satisfied: numpy>=1.22.0 in c:\\users\\yann\\anaconda3\\envs\\hf_gpu_env\\lib\\site-packages (from scikit-learn) (2.1.2)\n",
      "Requirement already satisfied: scipy>=1.8.0 in c:\\users\\yann\\anaconda3\\envs\\hf_gpu_env\\lib\\site-packages (from scikit-learn) (1.15.3)\n",
      "Requirement already satisfied: joblib>=1.2.0 in c:\\users\\yann\\anaconda3\\envs\\hf_gpu_env\\lib\\site-packages (from scikit-learn) (1.5.1)\n",
      "Requirement already satisfied: threadpoolctl>=3.1.0 in c:\\users\\yann\\anaconda3\\envs\\hf_gpu_env\\lib\\site-packages (from scikit-learn) (3.6.0)\n",
      "Requirement already satisfied: torch in c:\\users\\yann\\anaconda3\\envs\\hf_gpu_env\\lib\\site-packages (2.5.1+cu121)\n",
      "Requirement already satisfied: torchvision in c:\\users\\yann\\anaconda3\\envs\\hf_gpu_env\\lib\\site-packages (0.20.1+cu121)\n",
      "Requirement already satisfied: torchaudio in c:\\users\\yann\\anaconda3\\envs\\hf_gpu_env\\lib\\site-packages (2.5.1+cu121)\n",
      "Requirement already satisfied: filelock in c:\\users\\yann\\anaconda3\\envs\\hf_gpu_env\\lib\\site-packages (from torch) (3.13.1)\n",
      "Requirement already satisfied: typing-extensions>=4.8.0 in c:\\users\\yann\\anaconda3\\envs\\hf_gpu_env\\lib\\site-packages (from torch) (4.12.2)\n",
      "Requirement already satisfied: networkx in c:\\users\\yann\\anaconda3\\envs\\hf_gpu_env\\lib\\site-packages (from torch) (3.3)\n",
      "Requirement already satisfied: jinja2 in c:\\users\\yann\\anaconda3\\envs\\hf_gpu_env\\lib\\site-packages (from torch) (3.1.4)\n",
      "Requirement already satisfied: fsspec in c:\\users\\yann\\anaconda3\\envs\\hf_gpu_env\\lib\\site-packages (from torch) (2024.6.1)\n",
      "Requirement already satisfied: sympy==1.13.1 in c:\\users\\yann\\anaconda3\\envs\\hf_gpu_env\\lib\\site-packages (from torch) (1.13.1)\n",
      "Requirement already satisfied: mpmath<1.4,>=1.1.0 in c:\\users\\yann\\anaconda3\\envs\\hf_gpu_env\\lib\\site-packages (from sympy==1.13.1->torch) (1.3.0)\n",
      "Requirement already satisfied: numpy in c:\\users\\yann\\anaconda3\\envs\\hf_gpu_env\\lib\\site-packages (from torchvision) (2.1.2)\n",
      "Requirement already satisfied: pillow!=8.3.*,>=5.3.0 in c:\\users\\yann\\anaconda3\\envs\\hf_gpu_env\\lib\\site-packages (from torchvision) (11.0.0)\n",
      "Requirement already satisfied: MarkupSafe>=2.0 in c:\\users\\yann\\anaconda3\\envs\\hf_gpu_env\\lib\\site-packages (from jinja2->torch) (2.1.5)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "ERROR: Invalid requirement: '#': Expected package name at the start of dependency specifier\n",
      "    #\n",
      "    ^\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting nlpaug\n",
      "  Downloading nlpaug-1.1.11-py3-none-any.whl.metadata (14 kB)\n",
      "Requirement already satisfied: numpy>=1.16.2 in c:\\users\\yann\\anaconda3\\envs\\hf_gpu_env\\lib\\site-packages (from nlpaug) (2.1.2)\n",
      "Requirement already satisfied: pandas>=1.2.0 in c:\\users\\yann\\anaconda3\\envs\\hf_gpu_env\\lib\\site-packages (from nlpaug) (2.3.0)\n",
      "Requirement already satisfied: requests>=2.22.0 in c:\\users\\yann\\anaconda3\\envs\\hf_gpu_env\\lib\\site-packages (from nlpaug) (2.32.4)\n",
      "Collecting gdown>=4.0.0 (from nlpaug)\n",
      "  Downloading gdown-5.2.0-py3-none-any.whl.metadata (5.8 kB)\n",
      "Requirement already satisfied: beautifulsoup4 in c:\\users\\yann\\anaconda3\\envs\\hf_gpu_env\\lib\\site-packages (from gdown>=4.0.0->nlpaug) (4.13.4)\n",
      "Requirement already satisfied: filelock in c:\\users\\yann\\anaconda3\\envs\\hf_gpu_env\\lib\\site-packages (from gdown>=4.0.0->nlpaug) (3.13.1)\n",
      "Requirement already satisfied: tqdm in c:\\users\\yann\\anaconda3\\envs\\hf_gpu_env\\lib\\site-packages (from gdown>=4.0.0->nlpaug) (4.67.1)\n",
      "Requirement already satisfied: python-dateutil>=2.8.2 in c:\\users\\yann\\anaconda3\\envs\\hf_gpu_env\\lib\\site-packages (from pandas>=1.2.0->nlpaug) (2.9.0.post0)\n",
      "Requirement already satisfied: pytz>=2020.1 in c:\\users\\yann\\anaconda3\\envs\\hf_gpu_env\\lib\\site-packages (from pandas>=1.2.0->nlpaug) (2025.2)\n",
      "Requirement already satisfied: tzdata>=2022.7 in c:\\users\\yann\\anaconda3\\envs\\hf_gpu_env\\lib\\site-packages (from pandas>=1.2.0->nlpaug) (2025.2)\n",
      "Requirement already satisfied: six>=1.5 in c:\\users\\yann\\anaconda3\\envs\\hf_gpu_env\\lib\\site-packages (from python-dateutil>=2.8.2->pandas>=1.2.0->nlpaug) (1.17.0)\n",
      "Requirement already satisfied: charset_normalizer<4,>=2 in c:\\users\\yann\\anaconda3\\envs\\hf_gpu_env\\lib\\site-packages (from requests>=2.22.0->nlpaug) (3.4.2)\n",
      "Requirement already satisfied: idna<4,>=2.5 in c:\\users\\yann\\anaconda3\\envs\\hf_gpu_env\\lib\\site-packages (from requests>=2.22.0->nlpaug) (3.10)\n",
      "Requirement already satisfied: urllib3<3,>=1.21.1 in c:\\users\\yann\\anaconda3\\envs\\hf_gpu_env\\lib\\site-packages (from requests>=2.22.0->nlpaug) (2.5.0)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in c:\\users\\yann\\anaconda3\\envs\\hf_gpu_env\\lib\\site-packages (from requests>=2.22.0->nlpaug) (2025.6.15)\n",
      "Requirement already satisfied: soupsieve>1.2 in c:\\users\\yann\\anaconda3\\envs\\hf_gpu_env\\lib\\site-packages (from beautifulsoup4->gdown>=4.0.0->nlpaug) (2.7)\n",
      "Requirement already satisfied: typing-extensions>=4.0.0 in c:\\users\\yann\\anaconda3\\envs\\hf_gpu_env\\lib\\site-packages (from beautifulsoup4->gdown>=4.0.0->nlpaug) (4.12.2)\n",
      "Collecting PySocks!=1.5.7,>=1.5.6 (from requests[socks]->gdown>=4.0.0->nlpaug)\n",
      "  Downloading PySocks-1.7.1-py3-none-any.whl.metadata (13 kB)\n",
      "Requirement already satisfied: colorama in c:\\users\\yann\\anaconda3\\envs\\hf_gpu_env\\lib\\site-packages (from tqdm->gdown>=4.0.0->nlpaug) (0.4.6)\n",
      "Downloading nlpaug-1.1.11-py3-none-any.whl (410 kB)\n",
      "Downloading gdown-5.2.0-py3-none-any.whl (18 kB)\n",
      "Downloading PySocks-1.7.1-py3-none-any.whl (16 kB)\n",
      "Installing collected packages: PySocks, gdown, nlpaug\n",
      "\n",
      "   ------------- -------------------------- 1/3 [gdown]\n",
      "   -------------------------- ------------- 2/3 [nlpaug]\n",
      "   -------------------------- ------------- 2/3 [nlpaug]\n",
      "   -------------------------- ------------- 2/3 [nlpaug]\n",
      "   -------------------------- ------------- 2/3 [nlpaug]\n",
      "   -------------------------- ------------- 2/3 [nlpaug]\n",
      "   -------------------------- ------------- 2/3 [nlpaug]\n",
      "   ---------------------------------------- 3/3 [nlpaug]\n",
      "\n",
      "Successfully installed PySocks-1.7.1 gdown-5.2.0 nlpaug-1.1.11\n"
     ]
    }
   ],
   "source": [
    "!pip install transformers==4.35.0\n",
    "!pip install datasets\n",
    "!pip install accelerate\n",
    "!pip install evaluate\n",
    "!pip install scikit-learn\n",
    "!pip install torch torchvision torchaudio\n",
    "!pip install wandb  # Pour le tracking\n",
    "!pip install nlpaug # augmentation données"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "847dfb55",
   "metadata": {},
   "source": [
    "## Import"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "af354644",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: transformers==4.40.1 in c:\\users\\yann\\anaconda3\\envs\\hf_gpu_env\\lib\\site-packages (4.40.1)\n",
      "Requirement already satisfied: huggingface_hub==0.23.1 in c:\\users\\yann\\anaconda3\\envs\\hf_gpu_env\\lib\\site-packages (0.23.1)\n",
      "Requirement already satisfied: filelock in c:\\users\\yann\\anaconda3\\envs\\hf_gpu_env\\lib\\site-packages (from transformers==4.40.1) (3.13.1)\n",
      "Requirement already satisfied: numpy>=1.17 in c:\\users\\yann\\anaconda3\\envs\\hf_gpu_env\\lib\\site-packages (from transformers==4.40.1) (2.1.2)\n",
      "Requirement already satisfied: packaging>=20.0 in c:\\users\\yann\\anaconda3\\envs\\hf_gpu_env\\lib\\site-packages (from transformers==4.40.1) (25.0)\n",
      "Requirement already satisfied: pyyaml>=5.1 in c:\\users\\yann\\anaconda3\\envs\\hf_gpu_env\\lib\\site-packages (from transformers==4.40.1) (6.0.2)\n",
      "Requirement already satisfied: regex!=2019.12.17 in c:\\users\\yann\\anaconda3\\envs\\hf_gpu_env\\lib\\site-packages (from transformers==4.40.1) (2024.11.6)\n",
      "Requirement already satisfied: requests in c:\\users\\yann\\anaconda3\\envs\\hf_gpu_env\\lib\\site-packages (from transformers==4.40.1) (2.32.4)\n",
      "Requirement already satisfied: tokenizers<0.20,>=0.19 in c:\\users\\yann\\anaconda3\\envs\\hf_gpu_env\\lib\\site-packages (from transformers==4.40.1) (0.19.1)\n",
      "Requirement already satisfied: safetensors>=0.4.1 in c:\\users\\yann\\anaconda3\\envs\\hf_gpu_env\\lib\\site-packages (from transformers==4.40.1) (0.5.3)\n",
      "Requirement already satisfied: tqdm>=4.27 in c:\\users\\yann\\anaconda3\\envs\\hf_gpu_env\\lib\\site-packages (from transformers==4.40.1) (4.67.1)\n",
      "Requirement already satisfied: fsspec>=2023.5.0 in c:\\users\\yann\\anaconda3\\envs\\hf_gpu_env\\lib\\site-packages (from huggingface_hub==0.23.1) (2024.6.1)\n",
      "Requirement already satisfied: typing-extensions>=3.7.4.3 in c:\\users\\yann\\anaconda3\\envs\\hf_gpu_env\\lib\\site-packages (from huggingface_hub==0.23.1) (4.12.2)\n",
      "Requirement already satisfied: colorama in c:\\users\\yann\\anaconda3\\envs\\hf_gpu_env\\lib\\site-packages (from tqdm>=4.27->transformers==4.40.1) (0.4.6)\n",
      "Requirement already satisfied: charset_normalizer<4,>=2 in c:\\users\\yann\\anaconda3\\envs\\hf_gpu_env\\lib\\site-packages (from requests->transformers==4.40.1) (3.4.2)\n",
      "Requirement already satisfied: idna<4,>=2.5 in c:\\users\\yann\\anaconda3\\envs\\hf_gpu_env\\lib\\site-packages (from requests->transformers==4.40.1) (3.10)\n",
      "Requirement already satisfied: urllib3<3,>=1.21.1 in c:\\users\\yann\\anaconda3\\envs\\hf_gpu_env\\lib\\site-packages (from requests->transformers==4.40.1) (2.5.0)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in c:\\users\\yann\\anaconda3\\envs\\hf_gpu_env\\lib\\site-packages (from requests->transformers==4.40.1) (2025.6.15)\n",
      "Collecting accelerate==0.29.3\n",
      "  Downloading accelerate-0.29.3-py3-none-any.whl.metadata (18 kB)\n",
      "Requirement already satisfied: numpy>=1.17 in c:\\users\\yann\\anaconda3\\envs\\hf_gpu_env\\lib\\site-packages (from accelerate==0.29.3) (2.1.2)\n",
      "Requirement already satisfied: packaging>=20.0 in c:\\users\\yann\\anaconda3\\envs\\hf_gpu_env\\lib\\site-packages (from accelerate==0.29.3) (25.0)\n",
      "Requirement already satisfied: psutil in c:\\users\\yann\\anaconda3\\envs\\hf_gpu_env\\lib\\site-packages (from accelerate==0.29.3) (7.0.0)\n",
      "Requirement already satisfied: pyyaml in c:\\users\\yann\\anaconda3\\envs\\hf_gpu_env\\lib\\site-packages (from accelerate==0.29.3) (6.0.2)\n",
      "Requirement already satisfied: torch>=1.10.0 in c:\\users\\yann\\anaconda3\\envs\\hf_gpu_env\\lib\\site-packages (from accelerate==0.29.3) (2.5.1+cu121)\n",
      "Requirement already satisfied: huggingface-hub in c:\\users\\yann\\anaconda3\\envs\\hf_gpu_env\\lib\\site-packages (from accelerate==0.29.3) (0.23.1)\n",
      "Requirement already satisfied: safetensors>=0.3.1 in c:\\users\\yann\\anaconda3\\envs\\hf_gpu_env\\lib\\site-packages (from accelerate==0.29.3) (0.5.3)\n",
      "Requirement already satisfied: filelock in c:\\users\\yann\\anaconda3\\envs\\hf_gpu_env\\lib\\site-packages (from torch>=1.10.0->accelerate==0.29.3) (3.13.1)\n",
      "Requirement already satisfied: typing-extensions>=4.8.0 in c:\\users\\yann\\anaconda3\\envs\\hf_gpu_env\\lib\\site-packages (from torch>=1.10.0->accelerate==0.29.3) (4.12.2)\n",
      "Requirement already satisfied: networkx in c:\\users\\yann\\anaconda3\\envs\\hf_gpu_env\\lib\\site-packages (from torch>=1.10.0->accelerate==0.29.3) (3.3)\n",
      "Requirement already satisfied: jinja2 in c:\\users\\yann\\anaconda3\\envs\\hf_gpu_env\\lib\\site-packages (from torch>=1.10.0->accelerate==0.29.3) (3.1.4)\n",
      "Requirement already satisfied: fsspec in c:\\users\\yann\\anaconda3\\envs\\hf_gpu_env\\lib\\site-packages (from torch>=1.10.0->accelerate==0.29.3) (2024.6.1)\n",
      "Requirement already satisfied: sympy==1.13.1 in c:\\users\\yann\\anaconda3\\envs\\hf_gpu_env\\lib\\site-packages (from torch>=1.10.0->accelerate==0.29.3) (1.13.1)\n",
      "Requirement already satisfied: mpmath<1.4,>=1.1.0 in c:\\users\\yann\\anaconda3\\envs\\hf_gpu_env\\lib\\site-packages (from sympy==1.13.1->torch>=1.10.0->accelerate==0.29.3) (1.3.0)\n",
      "Requirement already satisfied: requests in c:\\users\\yann\\anaconda3\\envs\\hf_gpu_env\\lib\\site-packages (from huggingface-hub->accelerate==0.29.3) (2.32.4)\n",
      "Requirement already satisfied: tqdm>=4.42.1 in c:\\users\\yann\\anaconda3\\envs\\hf_gpu_env\\lib\\site-packages (from huggingface-hub->accelerate==0.29.3) (4.67.1)\n",
      "Requirement already satisfied: colorama in c:\\users\\yann\\anaconda3\\envs\\hf_gpu_env\\lib\\site-packages (from tqdm>=4.42.1->huggingface-hub->accelerate==0.29.3) (0.4.6)\n",
      "Requirement already satisfied: MarkupSafe>=2.0 in c:\\users\\yann\\anaconda3\\envs\\hf_gpu_env\\lib\\site-packages (from jinja2->torch>=1.10.0->accelerate==0.29.3) (2.1.5)\n",
      "Requirement already satisfied: charset_normalizer<4,>=2 in c:\\users\\yann\\anaconda3\\envs\\hf_gpu_env\\lib\\site-packages (from requests->huggingface-hub->accelerate==0.29.3) (3.4.2)\n",
      "Requirement already satisfied: idna<4,>=2.5 in c:\\users\\yann\\anaconda3\\envs\\hf_gpu_env\\lib\\site-packages (from requests->huggingface-hub->accelerate==0.29.3) (3.10)\n",
      "Requirement already satisfied: urllib3<3,>=1.21.1 in c:\\users\\yann\\anaconda3\\envs\\hf_gpu_env\\lib\\site-packages (from requests->huggingface-hub->accelerate==0.29.3) (2.5.0)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in c:\\users\\yann\\anaconda3\\envs\\hf_gpu_env\\lib\\site-packages (from requests->huggingface-hub->accelerate==0.29.3) (2025.6.15)\n",
      "Downloading accelerate-0.29.3-py3-none-any.whl (297 kB)\n",
      "Installing collected packages: accelerate\n",
      "  Attempting uninstall: accelerate\n",
      "    Found existing installation: accelerate 1.8.1\n",
      "    Uninstalling accelerate-1.8.1:\n",
      "      Successfully uninstalled accelerate-1.8.1\n",
      "Successfully installed accelerate-0.29.3\n"
     ]
    }
   ],
   "source": [
    "!pip install transformers==4.40.1 huggingface_hub==0.23.1\n",
    "!pip install accelerate==0.29.3\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "68557bd2",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "🚀 Device: cuda\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "from torch.utils.data import DataLoader, WeightedRandomSampler\n",
    "\n",
    "from transformers import (\n",
    "    AutoTokenizer, AutoModelForSequenceClassification,\n",
    "    TrainingArguments, Trainer, EarlyStoppingCallback,\n",
    "    get_cosine_schedule_with_warmup\n",
    ")\n",
    "from datasets import Dataset, DatasetDict\n",
    "from sklearn.metrics import f1_score, hamming_loss, classification_report\n",
    "from sklearn.utils.class_weight import compute_class_weight\n",
    "from collections import Counter\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')\n",
    "\n",
    "# Configuration GPU\n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "print(f\"🚀 Device: {device}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "e1ab0043",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "🚀 Device: cuda\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "from torch.utils.data import DataLoader, WeightedRandomSampler\n",
    "\n",
    "from transformers import (\n",
    "    AutoTokenizer, AutoModelForSequenceClassification,\n",
    "    TrainingArguments, Trainer, EarlyStoppingCallback,\n",
    "    get_cosine_schedule_with_warmup\n",
    ")\n",
    "from datasets import Dataset, DatasetDict\n",
    "from sklearn.metrics import f1_score, hamming_loss, classification_report\n",
    "from sklearn.utils.class_weight import compute_class_weight\n",
    "from collections import Counter\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')\n",
    "\n",
    "# Configuration GPU\n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "print(f\"🚀 Device: {device}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "dc217f4c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "🚀 Device: cuda\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "from torch.utils.data import DataLoader, WeightedRandomSampler\n",
    "\n",
    "from transformers import (\n",
    "    AutoTokenizer, AutoModelForSequenceClassification,\n",
    "    TrainingArguments, Trainer, EarlyStoppingCallback,\n",
    "    get_cosine_schedule_with_warmup\n",
    ")\n",
    "from datasets import Dataset, DatasetDict\n",
    "from sklearn.metrics import f1_score, hamming_loss, classification_report\n",
    "from sklearn.utils.class_weight import compute_class_weight\n",
    "from collections import Counter\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')\n",
    "\n",
    "# Configuration GPU\n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "print(f\"🚀 Device: {device}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e79e1c2e",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\Yann\\anaconda3\\envs\\hf_gpu_env\\lib\\site-packages\\transformers\\utils\\generic.py:441: FutureWarning: `torch.utils._pytree._register_pytree_node` is deprecated. Please use `torch.utils._pytree.register_pytree_node` instead.\n",
      "  _torch_pytree._register_pytree_node(\n"
     ]
    },
    {
     "ename": "RuntimeError",
     "evalue": "Failed to import transformers.training_args because of the following error (look up to see its traceback):\ncannot import name 'split_torch_state_dict_into_shards' from 'huggingface_hub' (c:\\Users\\Yann\\anaconda3\\envs\\hf_gpu_env\\lib\\site-packages\\huggingface_hub\\__init__.py)",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m\n",
      "\u001b[1;31mImportError\u001b[0m                               Traceback (most recent call last)\n",
      "File \u001b[1;32mc:\\Users\\Yann\\anaconda3\\envs\\hf_gpu_env\\lib\\site-packages\\transformers\\utils\\import_utils.py:1345\u001b[0m, in \u001b[0;36m_LazyModule._get_module\u001b[1;34m(self, module_name)\u001b[0m\n",
      "\u001b[0;32m   1344\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n",
      "\u001b[1;32m-> 1345\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mimportlib\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mimport_module\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43m.\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m \u001b[49m\u001b[38;5;241;43m+\u001b[39;49m\u001b[43m \u001b[49m\u001b[43mmodule_name\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[38;5;18;43m__name__\u001b[39;49m\u001b[43m)\u001b[49m\n",
      "\u001b[0;32m   1346\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mException\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m e:\n",
      "\n",
      "File \u001b[1;32mc:\\Users\\Yann\\anaconda3\\envs\\hf_gpu_env\\lib\\importlib\\__init__.py:126\u001b[0m, in \u001b[0;36mimport_module\u001b[1;34m(name, package)\u001b[0m\n",
      "\u001b[0;32m    125\u001b[0m         level \u001b[38;5;241m+\u001b[39m\u001b[38;5;241m=\u001b[39m \u001b[38;5;241m1\u001b[39m\n",
      "\u001b[1;32m--> 126\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43m_bootstrap\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_gcd_import\u001b[49m\u001b[43m(\u001b[49m\u001b[43mname\u001b[49m\u001b[43m[\u001b[49m\u001b[43mlevel\u001b[49m\u001b[43m:\u001b[49m\u001b[43m]\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mpackage\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mlevel\u001b[49m\u001b[43m)\u001b[49m\n",
      "\n",
      "File \u001b[1;32m<frozen importlib._bootstrap>:1050\u001b[0m, in \u001b[0;36m_gcd_import\u001b[1;34m(name, package, level)\u001b[0m\n",
      "\n",
      "File \u001b[1;32m<frozen importlib._bootstrap>:1027\u001b[0m, in \u001b[0;36m_find_and_load\u001b[1;34m(name, import_)\u001b[0m\n",
      "\n",
      "File \u001b[1;32m<frozen importlib._bootstrap>:1006\u001b[0m, in \u001b[0;36m_find_and_load_unlocked\u001b[1;34m(name, import_)\u001b[0m\n",
      "\n",
      "File \u001b[1;32m<frozen importlib._bootstrap>:688\u001b[0m, in \u001b[0;36m_load_unlocked\u001b[1;34m(spec)\u001b[0m\n",
      "\n",
      "File \u001b[1;32m<frozen importlib._bootstrap_external>:883\u001b[0m, in \u001b[0;36mexec_module\u001b[1;34m(self, module)\u001b[0m\n",
      "\n",
      "File \u001b[1;32m<frozen importlib._bootstrap>:241\u001b[0m, in \u001b[0;36m_call_with_frames_removed\u001b[1;34m(f, *args, **kwds)\u001b[0m\n",
      "\n",
      "File \u001b[1;32mc:\\Users\\Yann\\anaconda3\\envs\\hf_gpu_env\\lib\\site-packages\\transformers\\training_args.py:69\u001b[0m\n",
      "\u001b[0;32m     68\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m is_accelerate_available():\n",
      "\u001b[1;32m---> 69\u001b[0m     \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21;01maccelerate\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mstate\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mimport\u001b[39;00m AcceleratorState, PartialState\n",
      "\u001b[0;32m     70\u001b[0m     \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21;01maccelerate\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mutils\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mimport\u001b[39;00m DistributedType\n",
      "\n",
      "File \u001b[1;32mc:\\Users\\Yann\\anaconda3\\envs\\hf_gpu_env\\lib\\site-packages\\accelerate\\__init__.py:16\u001b[0m\n",
      "\u001b[0;32m     14\u001b[0m __version__ \u001b[38;5;241m=\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m1.8.1\u001b[39m\u001b[38;5;124m\"\u001b[39m\n",
      "\u001b[1;32m---> 16\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01maccelerator\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mimport\u001b[39;00m Accelerator\n",
      "\u001b[0;32m     17\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mbig_modeling\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mimport\u001b[39;00m (\n",
      "\u001b[0;32m     18\u001b[0m     cpu_offload,\n",
      "\u001b[0;32m     19\u001b[0m     cpu_offload_with_hook,\n",
      "\u001b[1;32m   (...)\u001b[0m\n",
      "\u001b[0;32m     24\u001b[0m     load_checkpoint_and_dispatch,\n",
      "\u001b[0;32m     25\u001b[0m )\n",
      "\n",
      "File \u001b[1;32mc:\\Users\\Yann\\anaconda3\\envs\\hf_gpu_env\\lib\\site-packages\\accelerate\\accelerator.py:34\u001b[0m\n",
      "\u001b[0;32m     33\u001b[0m \u001b[38;5;28;01mimport\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21;01mtorch\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mutils\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mhooks\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mas\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21;01mhooks\u001b[39;00m\n",
      "\u001b[1;32m---> 34\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21;01mhuggingface_hub\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mimport\u001b[39;00m split_torch_state_dict_into_shards\n",
      "\u001b[0;32m     36\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mcheckpointing\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mimport\u001b[39;00m load_accelerator_state, load_custom_state, save_accelerator_state, save_custom_state\n",
      "\n",
      "\u001b[1;31mImportError\u001b[0m: cannot import name 'split_torch_state_dict_into_shards' from 'huggingface_hub' (c:\\Users\\Yann\\anaconda3\\envs\\hf_gpu_env\\lib\\site-packages\\huggingface_hub\\__init__.py)\n",
      "\n",
      "The above exception was the direct cause of the following exception:\n",
      "\n",
      "\u001b[1;31mRuntimeError\u001b[0m                              Traceback (most recent call last)\n",
      "Cell \u001b[1;32mIn[1], line 8\u001b[0m\n",
      "\u001b[0;32m      5\u001b[0m \u001b[38;5;28;01mimport\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21;01mtorch\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mnn\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mfunctional\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mas\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21;01mF\u001b[39;00m\n",
      "\u001b[0;32m      6\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21;01mtorch\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mutils\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mdata\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mimport\u001b[39;00m DataLoader, WeightedRandomSampler\n",
      "\u001b[1;32m----> 8\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21;01mtransformers\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mimport\u001b[39;00m (\n",
      "\u001b[0;32m      9\u001b[0m     AutoTokenizer, AutoModelForSequenceClassification,\n",
      "\u001b[0;32m     10\u001b[0m     TrainingArguments, Trainer, EarlyStoppingCallback,\n",
      "\u001b[0;32m     11\u001b[0m     get_cosine_schedule_with_warmup\n",
      "\u001b[0;32m     12\u001b[0m )\n",
      "\u001b[0;32m     13\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21;01mdatasets\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mimport\u001b[39;00m Dataset, DatasetDict\n",
      "\u001b[0;32m     14\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21;01msklearn\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mmetrics\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mimport\u001b[39;00m f1_score, hamming_loss, classification_report\n",
      "\n",
      "File \u001b[1;32m<frozen importlib._bootstrap>:1075\u001b[0m, in \u001b[0;36m_handle_fromlist\u001b[1;34m(module, fromlist, import_, recursive)\u001b[0m\n",
      "\n",
      "File \u001b[1;32mc:\\Users\\Yann\\anaconda3\\envs\\hf_gpu_env\\lib\\site-packages\\transformers\\utils\\import_utils.py:1335\u001b[0m, in \u001b[0;36m_LazyModule.__getattr__\u001b[1;34m(self, name)\u001b[0m\n",
      "\u001b[0;32m   1333\u001b[0m     value \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_get_module(name)\n",
      "\u001b[0;32m   1334\u001b[0m \u001b[38;5;28;01melif\u001b[39;00m name \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_class_to_module\u001b[38;5;241m.\u001b[39mkeys():\n",
      "\u001b[1;32m-> 1335\u001b[0m     module \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_get_module\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_class_to_module\u001b[49m\u001b[43m[\u001b[49m\u001b[43mname\u001b[49m\u001b[43m]\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[0;32m   1336\u001b[0m     value \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mgetattr\u001b[39m(module, name)\n",
      "\u001b[0;32m   1337\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n",
      "\n",
      "File \u001b[1;32mc:\\Users\\Yann\\anaconda3\\envs\\hf_gpu_env\\lib\\site-packages\\transformers\\utils\\import_utils.py:1347\u001b[0m, in \u001b[0;36m_LazyModule._get_module\u001b[1;34m(self, module_name)\u001b[0m\n",
      "\u001b[0;32m   1345\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m importlib\u001b[38;5;241m.\u001b[39mimport_module(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m.\u001b[39m\u001b[38;5;124m\"\u001b[39m \u001b[38;5;241m+\u001b[39m module_name, \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m\u001b[38;5;18m__name__\u001b[39m)\n",
      "\u001b[0;32m   1346\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mException\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m e:\n",
      "\u001b[1;32m-> 1347\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mRuntimeError\u001b[39;00m(\n",
      "\u001b[0;32m   1348\u001b[0m         \u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mFailed to import \u001b[39m\u001b[38;5;132;01m{\u001b[39;00m\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m\u001b[38;5;18m__name__\u001b[39m\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m.\u001b[39m\u001b[38;5;132;01m{\u001b[39;00mmodule_name\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m because of the following error (look up to see its\u001b[39m\u001b[38;5;124m\"\u001b[39m\n",
      "\u001b[0;32m   1349\u001b[0m         \u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m traceback):\u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[38;5;132;01m{\u001b[39;00me\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m\"\u001b[39m\n",
      "\u001b[0;32m   1350\u001b[0m     ) \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21;01me\u001b[39;00m\n",
      "\n",
      "\u001b[1;31mRuntimeError\u001b[0m: Failed to import transformers.training_args because of the following error (look up to see its traceback):\n",
      "cannot import name 'split_torch_state_dict_into_shards' from 'huggingface_hub' (c:\\Users\\Yann\\anaconda3\\envs\\hf_gpu_env\\lib\\site-packages\\huggingface_hub\\__init__.py)"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "from torch.utils.data import DataLoader, WeightedRandomSampler\n",
    "\n",
    "from transformers import (\n",
    "    AutoTokenizer, AutoModelForSequenceClassification,\n",
    "    TrainingArguments, Trainer, EarlyStoppingCallback,\n",
    "    get_cosine_schedule_with_warmup\n",
    ")\n",
    "from datasets import Dataset, DatasetDict\n",
    "from sklearn.metrics import f1_score, hamming_loss, classification_report\n",
    "from sklearn.utils.class_weight import compute_class_weight\n",
    "from collections import Counter\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')\n",
    "\n",
    "# Configuration GPU\n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "print(f\"🚀 Device: {device}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fdfb5d22",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\Yann\\anaconda3\\envs\\hf_gpu_env\\lib\\site-packages\\transformers\\utils\\generic.py:441: FutureWarning: `torch.utils._pytree._register_pytree_node` is deprecated. Please use `torch.utils._pytree.register_pytree_node` instead.\n",
      "  _torch_pytree._register_pytree_node(\n"
     ]
    },
    {
     "ename": "RuntimeError",
     "evalue": "Failed to import transformers.training_args because of the following error (look up to see its traceback):\ncannot import name 'split_torch_state_dict_into_shards' from 'huggingface_hub' (c:\\Users\\Yann\\anaconda3\\envs\\hf_gpu_env\\lib\\site-packages\\huggingface_hub\\__init__.py)",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m\n",
      "\u001b[1;31mImportError\u001b[0m                               Traceback (most recent call last)\n",
      "File \u001b[1;32mc:\\Users\\Yann\\anaconda3\\envs\\hf_gpu_env\\lib\\site-packages\\transformers\\utils\\import_utils.py:1345\u001b[0m, in \u001b[0;36m_LazyModule._get_module\u001b[1;34m(self, module_name)\u001b[0m\n",
      "\u001b[0;32m   1344\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n",
      "\u001b[1;32m-> 1345\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mimportlib\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mimport_module\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43m.\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m \u001b[49m\u001b[38;5;241;43m+\u001b[39;49m\u001b[43m \u001b[49m\u001b[43mmodule_name\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[38;5;18;43m__name__\u001b[39;49m\u001b[43m)\u001b[49m\n",
      "\u001b[0;32m   1346\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mException\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m e:\n",
      "\n",
      "File \u001b[1;32mc:\\Users\\Yann\\anaconda3\\envs\\hf_gpu_env\\lib\\importlib\\__init__.py:126\u001b[0m, in \u001b[0;36mimport_module\u001b[1;34m(name, package)\u001b[0m\n",
      "\u001b[0;32m    125\u001b[0m         level \u001b[38;5;241m+\u001b[39m\u001b[38;5;241m=\u001b[39m \u001b[38;5;241m1\u001b[39m\n",
      "\u001b[1;32m--> 126\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43m_bootstrap\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_gcd_import\u001b[49m\u001b[43m(\u001b[49m\u001b[43mname\u001b[49m\u001b[43m[\u001b[49m\u001b[43mlevel\u001b[49m\u001b[43m:\u001b[49m\u001b[43m]\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mpackage\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mlevel\u001b[49m\u001b[43m)\u001b[49m\n",
      "\n",
      "File \u001b[1;32m<frozen importlib._bootstrap>:1050\u001b[0m, in \u001b[0;36m_gcd_import\u001b[1;34m(name, package, level)\u001b[0m\n",
      "\n",
      "File \u001b[1;32m<frozen importlib._bootstrap>:1027\u001b[0m, in \u001b[0;36m_find_and_load\u001b[1;34m(name, import_)\u001b[0m\n",
      "\n",
      "File \u001b[1;32m<frozen importlib._bootstrap>:1006\u001b[0m, in \u001b[0;36m_find_and_load_unlocked\u001b[1;34m(name, import_)\u001b[0m\n",
      "\n",
      "File \u001b[1;32m<frozen importlib._bootstrap>:688\u001b[0m, in \u001b[0;36m_load_unlocked\u001b[1;34m(spec)\u001b[0m\n",
      "\n",
      "File \u001b[1;32m<frozen importlib._bootstrap_external>:883\u001b[0m, in \u001b[0;36mexec_module\u001b[1;34m(self, module)\u001b[0m\n",
      "\n",
      "File \u001b[1;32m<frozen importlib._bootstrap>:241\u001b[0m, in \u001b[0;36m_call_with_frames_removed\u001b[1;34m(f, *args, **kwds)\u001b[0m\n",
      "\n",
      "File \u001b[1;32mc:\\Users\\Yann\\anaconda3\\envs\\hf_gpu_env\\lib\\site-packages\\transformers\\training_args.py:69\u001b[0m\n",
      "\u001b[0;32m     68\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m is_accelerate_available():\n",
      "\u001b[1;32m---> 69\u001b[0m     \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21;01maccelerate\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mstate\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mimport\u001b[39;00m AcceleratorState, PartialState\n",
      "\u001b[0;32m     70\u001b[0m     \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21;01maccelerate\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mutils\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mimport\u001b[39;00m DistributedType\n",
      "\n",
      "File \u001b[1;32mc:\\Users\\Yann\\anaconda3\\envs\\hf_gpu_env\\lib\\site-packages\\accelerate\\__init__.py:16\u001b[0m\n",
      "\u001b[0;32m     14\u001b[0m __version__ \u001b[38;5;241m=\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m1.8.1\u001b[39m\u001b[38;5;124m\"\u001b[39m\n",
      "\u001b[1;32m---> 16\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01maccelerator\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mimport\u001b[39;00m Accelerator\n",
      "\u001b[0;32m     17\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mbig_modeling\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mimport\u001b[39;00m (\n",
      "\u001b[0;32m     18\u001b[0m     cpu_offload,\n",
      "\u001b[0;32m     19\u001b[0m     cpu_offload_with_hook,\n",
      "\u001b[1;32m   (...)\u001b[0m\n",
      "\u001b[0;32m     24\u001b[0m     load_checkpoint_and_dispatch,\n",
      "\u001b[0;32m     25\u001b[0m )\n",
      "\n",
      "File \u001b[1;32mc:\\Users\\Yann\\anaconda3\\envs\\hf_gpu_env\\lib\\site-packages\\accelerate\\accelerator.py:34\u001b[0m\n",
      "\u001b[0;32m     33\u001b[0m \u001b[38;5;28;01mimport\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21;01mtorch\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mutils\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mhooks\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mas\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21;01mhooks\u001b[39;00m\n",
      "\u001b[1;32m---> 34\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21;01mhuggingface_hub\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mimport\u001b[39;00m split_torch_state_dict_into_shards\n",
      "\u001b[0;32m     36\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mcheckpointing\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mimport\u001b[39;00m load_accelerator_state, load_custom_state, save_accelerator_state, save_custom_state\n",
      "\n",
      "\u001b[1;31mImportError\u001b[0m: cannot import name 'split_torch_state_dict_into_shards' from 'huggingface_hub' (c:\\Users\\Yann\\anaconda3\\envs\\hf_gpu_env\\lib\\site-packages\\huggingface_hub\\__init__.py)\n",
      "\n",
      "The above exception was the direct cause of the following exception:\n",
      "\n",
      "\u001b[1;31mRuntimeError\u001b[0m                              Traceback (most recent call last)\n",
      "Cell \u001b[1;32mIn[1], line 8\u001b[0m\n",
      "\u001b[0;32m      5\u001b[0m \u001b[38;5;28;01mimport\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21;01mtorch\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mnn\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mfunctional\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mas\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21;01mF\u001b[39;00m\n",
      "\u001b[0;32m      6\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21;01mtorch\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mutils\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mdata\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mimport\u001b[39;00m DataLoader, WeightedRandomSampler\n",
      "\u001b[1;32m----> 8\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21;01mtransformers\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mimport\u001b[39;00m (\n",
      "\u001b[0;32m      9\u001b[0m     AutoTokenizer, AutoModelForSequenceClassification,\n",
      "\u001b[0;32m     10\u001b[0m     TrainingArguments, Trainer, EarlyStoppingCallback,\n",
      "\u001b[0;32m     11\u001b[0m     get_cosine_schedule_with_warmup\n",
      "\u001b[0;32m     12\u001b[0m )\n",
      "\u001b[0;32m     13\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21;01mdatasets\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mimport\u001b[39;00m Dataset, DatasetDict\n",
      "\u001b[0;32m     14\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21;01msklearn\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mmetrics\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mimport\u001b[39;00m f1_score, hamming_loss, classification_report\n",
      "\n",
      "File \u001b[1;32m<frozen importlib._bootstrap>:1075\u001b[0m, in \u001b[0;36m_handle_fromlist\u001b[1;34m(module, fromlist, import_, recursive)\u001b[0m\n",
      "\n",
      "File \u001b[1;32mc:\\Users\\Yann\\anaconda3\\envs\\hf_gpu_env\\lib\\site-packages\\transformers\\utils\\import_utils.py:1335\u001b[0m, in \u001b[0;36m_LazyModule.__getattr__\u001b[1;34m(self, name)\u001b[0m\n",
      "\u001b[0;32m   1333\u001b[0m     value \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_get_module(name)\n",
      "\u001b[0;32m   1334\u001b[0m \u001b[38;5;28;01melif\u001b[39;00m name \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_class_to_module\u001b[38;5;241m.\u001b[39mkeys():\n",
      "\u001b[1;32m-> 1335\u001b[0m     module \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_get_module\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_class_to_module\u001b[49m\u001b[43m[\u001b[49m\u001b[43mname\u001b[49m\u001b[43m]\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[0;32m   1336\u001b[0m     value \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mgetattr\u001b[39m(module, name)\n",
      "\u001b[0;32m   1337\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n",
      "\n",
      "File \u001b[1;32mc:\\Users\\Yann\\anaconda3\\envs\\hf_gpu_env\\lib\\site-packages\\transformers\\utils\\import_utils.py:1347\u001b[0m, in \u001b[0;36m_LazyModule._get_module\u001b[1;34m(self, module_name)\u001b[0m\n",
      "\u001b[0;32m   1345\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m importlib\u001b[38;5;241m.\u001b[39mimport_module(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m.\u001b[39m\u001b[38;5;124m\"\u001b[39m \u001b[38;5;241m+\u001b[39m module_name, \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m\u001b[38;5;18m__name__\u001b[39m)\n",
      "\u001b[0;32m   1346\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mException\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m e:\n",
      "\u001b[1;32m-> 1347\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mRuntimeError\u001b[39;00m(\n",
      "\u001b[0;32m   1348\u001b[0m         \u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mFailed to import \u001b[39m\u001b[38;5;132;01m{\u001b[39;00m\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m\u001b[38;5;18m__name__\u001b[39m\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m.\u001b[39m\u001b[38;5;132;01m{\u001b[39;00mmodule_name\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m because of the following error (look up to see its\u001b[39m\u001b[38;5;124m\"\u001b[39m\n",
      "\u001b[0;32m   1349\u001b[0m         \u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m traceback):\u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[38;5;132;01m{\u001b[39;00me\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m\"\u001b[39m\n",
      "\u001b[0;32m   1350\u001b[0m     ) \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21;01me\u001b[39;00m\n",
      "\n",
      "\u001b[1;31mRuntimeError\u001b[0m: Failed to import transformers.training_args because of the following error (look up to see its traceback):\n",
      "cannot import name 'split_torch_state_dict_into_shards' from 'huggingface_hub' (c:\\Users\\Yann\\anaconda3\\envs\\hf_gpu_env\\lib\\site-packages\\huggingface_hub\\__init__.py)"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "from torch.utils.data import DataLoader, WeightedRandomSampler\n",
    "\n",
    "from transformers import (\n",
    "    AutoTokenizer, AutoModelForSequenceClassification,\n",
    "    TrainingArguments, Trainer, EarlyStoppingCallback,\n",
    "    get_cosine_schedule_with_warmup\n",
    ")\n",
    "from datasets import Dataset, DatasetDict\n",
    "from sklearn.metrics import f1_score, hamming_loss, classification_report\n",
    "from sklearn.utils.class_weight import compute_class_weight\n",
    "from collections import Counter\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')\n",
    "\n",
    "# Configuration GPU\n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "print(f\"🚀 Device: {device}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0f40d866",
   "metadata": {},
   "source": [
    "## Focal Loss Implementation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "c9d9130e",
   "metadata": {},
   "outputs": [],
   "source": [
    "class FocalLoss(nn.Module):\n",
    "    \"\"\"Focal Loss pour gérer le déséquilibre de classes\"\"\"\n",
    "    def __init__(self, alpha=1.0, gamma=2.0, reduction='mean'):\n",
    "        super().__init__()\n",
    "        self.alpha = alpha\n",
    "        self.gamma = gamma\n",
    "        self.reduction = reduction\n",
    "    \n",
    "    def forward(self, inputs, targets):\n",
    "        bce_loss = F.binary_cross_entropy_with_logits(inputs, targets, reduction='none')\n",
    "        pt = torch.exp(-bce_loss)\n",
    "        focal_weight = self.alpha * (1 - pt) ** self.gamma\n",
    "        focal_loss = focal_weight * bce_loss\n",
    "        \n",
    "        if self.reduction == 'mean':\n",
    "            return focal_loss.mean()\n",
    "        elif self.reduction == 'sum':\n",
    "            return focal_loss.sum()\n",
    "        else:\n",
    "            return focal_loss\n",
    "\n",
    "class LabelSmoothingLoss(nn.Module):\n",
    "    \"\"\"Label Smoothing pour la régularisation\"\"\"\n",
    "    def __init__(self, smoothing=0.1):\n",
    "        super().__init__()\n",
    "        self.smoothing = smoothing\n",
    "    \n",
    "    def forward(self, logits, targets):\n",
    "        targets_smooth = targets * (1 - self.smoothing) + self.smoothing / 2\n",
    "        return F.binary_cross_entropy_with_logits(logits, targets_smooth)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fb42e0cb",
   "metadata": {},
   "source": [
    "## Modèle RoBERTa Optimisé avec Dropout Adaptatif"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "id": "91ba1959",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "✅ Modèle UltimateRoBERTaForMultiLabel CORRIGÉ!\n"
     ]
    }
   ],
   "source": [
    "class UltimateRoBERTaForMultiLabel(nn.Module):\n",
    "    def __init__(self, num_labels, dropout_rate=0.3, use_pooling=True):\n",
    "        super().__init__()\n",
    "        \n",
    "        # RoBERTa-Base (stable et performant)\n",
    "        self.roberta = AutoModelForSequenceClassification.from_pretrained(\n",
    "            \"roberta-base\",\n",
    "            num_labels=num_labels,\n",
    "            problem_type=\"multi_label_classification\",\n",
    "            output_attentions=True,\n",
    "            output_hidden_states=True\n",
    "        )\n",
    "        \n",
    "        # Configuration\n",
    "        hidden_size = self.roberta.config.hidden_size  # 768 pour roberta-base\n",
    "        self.num_labels = num_labels\n",
    "        self.use_pooling = use_pooling\n",
    "        \n",
    "        # Couches de classification avancées\n",
    "        self.dropout1 = nn.Dropout(dropout_rate)\n",
    "        self.dropout2 = nn.Dropout(dropout_rate * 0.5)\n",
    "        \n",
    "        # Architecture à plusieurs couches\n",
    "        self.classifier = nn.Sequential(\n",
    "            nn.Linear(hidden_size, hidden_size // 2),\n",
    "            nn.LayerNorm(hidden_size // 2),\n",
    "            nn.ReLU(),\n",
    "            nn.Dropout(dropout_rate),\n",
    "            \n",
    "            nn.Linear(hidden_size // 2, hidden_size // 4),\n",
    "            nn.LayerNorm(hidden_size // 4),\n",
    "            nn.ReLU(),\n",
    "            nn.Dropout(dropout_rate * 0.5),\n",
    "            \n",
    "            nn.Linear(hidden_size // 4, num_labels)\n",
    "        )\n",
    "        \n",
    "        # Pooling avancé pour capturer plus d'info\n",
    "        if use_pooling:\n",
    "            self.attention_pooling = nn.MultiheadAttention(\n",
    "                embed_dim=hidden_size, \n",
    "                num_heads=8, \n",
    "                batch_first=True\n",
    "            )\n",
    "        \n",
    "        # Loss functions\n",
    "        self.focal_loss = FocalLoss(alpha=1.0, gamma=2.0)\n",
    "        self.label_smoothing = LabelSmoothingLoss(smoothing=0.1)\n",
    "    \n",
    "    def forward(self, input_ids, attention_mask, labels=None):\n",
    "        # ✅ CORRECTION 1: Accès direct au modèle\n",
    "        outputs = self.roberta(\n",
    "            input_ids=input_ids,\n",
    "            attention_mask=attention_mask,\n",
    "            output_hidden_states=True,\n",
    "            output_attentions=True,\n",
    "            return_dict=True  # IMPORTANT !\n",
    "        )\n",
    "        \n",
    "        # Récupération des représentations\n",
    "        hidden_states = outputs.hidden_states[-1]  # Dernière couche\n",
    "        \n",
    "        if self.use_pooling:\n",
    "            # Attention pooling pour une meilleure représentation\n",
    "            pooled_output, _ = self.attention_pooling(\n",
    "                hidden_states, hidden_states, hidden_states,\n",
    "                key_padding_mask=~attention_mask.bool()\n",
    "            )\n",
    "            # Moyenne pondérée\n",
    "            pooled_output = (pooled_output * attention_mask.unsqueeze(-1)).sum(1) / attention_mask.sum(-1).unsqueeze(-1)\n",
    "        else:\n",
    "            # CLS token classique\n",
    "            pooled_output = hidden_states[:, 0]\n",
    "        \n",
    "        # Classification\n",
    "        pooled_output = self.dropout1(pooled_output)\n",
    "        logits = self.classifier(pooled_output)\n",
    "        \n",
    "        # Loss calculation\n",
    "        loss = None\n",
    "        if labels is not None:\n",
    "            # Combinaison de losses pour optimiser\n",
    "            focal_loss = self.focal_loss(logits, labels.float())\n",
    "            smooth_loss = self.label_smoothing(logits, labels.float())\n",
    "            \n",
    "            # Loss pondérée\n",
    "            loss = 0.7 * focal_loss + 0.3 * smooth_loss\n",
    "        \n",
    "        # ✅ CORRECTION 2: Retour correct\n",
    "        from transformers.modeling_outputs import SequenceClassifierOutput\n",
    "        return SequenceClassifierOutput(\n",
    "            loss=loss,\n",
    "            logits=logits,\n",
    "            hidden_states=outputs.hidden_states,\n",
    "            attentions=outputs.attentions\n",
    "        )\n",
    "\n",
    "print(\"✅ Modèle UltimateRoBERTaForMultiLabel CORRIGÉ!\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2b69ca0b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "🚀 Device: cuda\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "from torch.utils.data import DataLoader, WeightedRandomSampler\n",
    "\n",
    "from transformers import (\n",
    "    AutoTokenizer, AutoModelForSequenceClassification,\n",
    "    TrainingArguments, Trainer, EarlyStoppingCallback,\n",
    "    get_cosine_schedule_with_warmup\n",
    ")\n",
    "from datasets import Dataset, DatasetDict\n",
    "from sklearn.metrics import f1_score, hamming_loss, classification_report\n",
    "from sklearn.utils.class_weight import compute_class_weight\n",
    "from collections import Counter\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')\n",
    "\n",
    "# Configuration GPU\n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "print(f\"🚀 Device: {device}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e2db483a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "🚀 Device: cuda\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "from torch.utils.data import DataLoader, WeightedRandomSampler\n",
    "\n",
    "from transformers import (\n",
    "    AutoTokenizer, AutoModelForSequenceClassification,\n",
    "    TrainingArguments, Trainer, EarlyStoppingCallback,\n",
    "    get_cosine_schedule_with_warmup\n",
    ")\n",
    "from datasets import Dataset, DatasetDict\n",
    "from sklearn.metrics import f1_score, hamming_loss, classification_report\n",
    "from sklearn.utils.class_weight import compute_class_weight\n",
    "from collections import Counter\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')\n",
    "\n",
    "# Configuration GPU\n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "print(f\"🚀 Device: {device}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "295d9bde",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "🚀 Device: cuda\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "from torch.utils.data import DataLoader, WeightedRandomSampler\n",
    "\n",
    "from transformers import (\n",
    "    AutoTokenizer, AutoModelForSequenceClassification,\n",
    "    TrainingArguments, Trainer, EarlyStoppingCallback,\n",
    "    get_cosine_schedule_with_warmup\n",
    ")\n",
    "from datasets import Dataset, DatasetDict\n",
    "from sklearn.metrics import f1_score, hamming_loss, classification_report\n",
    "from sklearn.utils.class_weight import compute_class_weight\n",
    "from collections import Counter\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')\n",
    "\n",
    "# Configuration GPU\n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "print(f\"🚀 Device: {device}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5912fa88",
   "metadata": {},
   "source": [
    "## Tokenisation Optimisée"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "b74a4245",
   "metadata": {},
   "outputs": [],
   "source": [
    "def prepare_ultimate_data(df_train, df_val, df_test):\n",
    "    \"\"\"Version corrigée qui supprime TOUTES les colonnes problématiques\"\"\"\n",
    "    \n",
    "    print(\"🔧 PRÉPARATION ULTRA-OPTIMISÉE DES DONNÉES (CORRIGÉE)\")\n",
    "    print(\"=\" * 50)\n",
    "    \n",
    "    # 1. Nettoyer les DataFrames AVANT tokenisation\n",
    "    exclude_cols = ['id', 'text', 'example_very_unclear', 'num_labels', 'text_length', '__index_level_0__']\n",
    "    emotion_columns = [col for col in df_train.columns if col not in exclude_cols]\n",
    "    \n",
    "    print(f\"📊 Colonnes d'émotions: {len(emotion_columns)}\")\n",
    "    \n",
    "    # 2. NETTOYER les DataFrames en supprimant les index problématiques\n",
    "    df_train_clean = df_train.reset_index(drop=True)\n",
    "    df_val_clean = df_val.reset_index(drop=True)\n",
    "    df_test_clean = df_test.reset_index(drop=True)\n",
    "    \n",
    "    # 3. Tokenizer\n",
    "    tokenizer = AutoTokenizer.from_pretrained(\"roberta-base\")\n",
    "    \n",
    "    def tokenize_and_encode_fixed(examples):\n",
    "        # Tokenisation\n",
    "        tokenized = tokenizer(\n",
    "            examples[\"text\"],\n",
    "            truncation=True,\n",
    "            padding=\"max_length\",\n",
    "            max_length=256,\n",
    "            add_special_tokens=True,\n",
    "            return_attention_mask=True,\n",
    "            return_token_type_ids=False\n",
    "        )\n",
    "        \n",
    "        # Labels - SEULEMENT les émotions\n",
    "        labels = []\n",
    "        for i in range(len(examples[\"text\"])):\n",
    "            label_vector = [float(examples[col][i]) for col in emotion_columns]\n",
    "            labels.append(label_vector)\n",
    "        \n",
    "        tokenized[\"labels\"] = labels\n",
    "        return tokenized\n",
    "    \n",
    "    # 4. Créer datasets avec SEULEMENT text + émotions\n",
    "    datasets = {}\n",
    "    for split_name, df in [(\"train\", df_train_clean), (\"validation\", df_val_clean), (\"test\", df_test_clean)]:\n",
    "        # IMPORTANT: Sélectionner SEULEMENT les colonnes nécessaires\n",
    "        df_for_dataset = df[['text'] + emotion_columns].copy()\n",
    "        \n",
    "        # Supprimer les lignes avec texte vide\n",
    "        df_for_dataset = df_for_dataset[df_for_dataset['text'].notna() & (df_for_dataset['text'].str.len() > 0)]\n",
    "        \n",
    "        dataset = Dataset.from_pandas(df_for_dataset)\n",
    "        datasets[split_name] = dataset\n",
    "    \n",
    "    dataset_dict = DatasetDict(datasets)\n",
    "    \n",
    "    # 5. Tokenisation avec suppression COMPLÈTE des colonnes originales\n",
    "    print(\"🔧 Tokenisation en cours...\")\n",
    "    tokenized_datasets = dataset_dict.map(\n",
    "        tokenize_and_encode_fixed,\n",
    "        batched=True,\n",
    "        batch_size=1000,\n",
    "        # SUPPRIMER TOUTES les colonnes sauf input_ids, attention_mask, labels\n",
    "        remove_columns=dataset_dict[\"train\"].column_names,  # Supprime TOUT\n",
    "        desc=\"Tokenisation\"\n",
    "    )\n",
    "    \n",
    "    # 6. VÉRIFICATION finale des colonnes\n",
    "    print(\"🔍 Vérification des colonnes finales:\")\n",
    "    for split in tokenized_datasets:\n",
    "        cols = tokenized_datasets[split].column_names\n",
    "        print(f\"   {split}: {cols}\")\n",
    "        \n",
    "        # Vérifier qu'il n'y a que les bonnes colonnes\n",
    "        expected_cols = ['input_ids', 'attention_mask', 'labels']\n",
    "        unexpected_cols = [col for col in cols if col not in expected_cols]\n",
    "        if unexpected_cols:\n",
    "            print(f\"   ⚠️ Colonnes inattendues dans {split}: {unexpected_cols}\")\n",
    "    \n",
    "    tokenized_datasets.set_format(\"torch\")\n",
    "    \n",
    "    return tokenizer, tokenized_datasets, emotion_columns"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "80d634f5",
   "metadata": {},
   "source": [
    "## Cacul poid et metrics"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "id": "692cd7a1",
   "metadata": {},
   "outputs": [],
   "source": [
    "def compute_optimal_class_weights(df_train, emotion_columns):\n",
    "    \"\"\"Calcul optimisé des poids de classes\"\"\"\n",
    "    \n",
    "    print(\"⚖️ CALCUL DES POIDS DE CLASSES\")\n",
    "    \n",
    "    y_train = df_train[emotion_columns].values\n",
    "    pos_weights = []\n",
    "    class_info = {}\n",
    "    \n",
    "    for i, emotion in enumerate(emotion_columns):\n",
    "        emotion_labels = y_train[:, i]\n",
    "        pos_count = np.sum(emotion_labels)\n",
    "        neg_count = len(emotion_labels) - pos_count\n",
    "        \n",
    "        # Calcul du poids avec lissage\n",
    "        pos_weight = (neg_count + 1) / (pos_count + 1)  # Lissage pour éviter poids infinis\n",
    "        pos_weights.append(pos_weight)\n",
    "        \n",
    "        class_info[emotion] = {\n",
    "            'pos_weight': pos_weight,\n",
    "            'frequency': pos_count / len(emotion_labels),\n",
    "            'samples': int(pos_count)\n",
    "        }\n",
    "    \n",
    "    # Affichage informatif\n",
    "    sorted_emotions = sorted(class_info.items(), key=lambda x: x[1]['frequency'], reverse=True)\n",
    "    \n",
    "    print(\"📊 Top 5 émotions les plus fréquentes:\")\n",
    "    for emotion, info in sorted_emotions[:5]:\n",
    "        print(f\"   {emotion}: {info['frequency']:.3f} ({info['samples']} échantillons)\")\n",
    "    \n",
    "    print(\"📊 Top 5 émotions les plus rares:\")\n",
    "    for emotion, info in sorted_emotions[-5:]:\n",
    "        print(f\"   {emotion}: {info['frequency']:.3f} ({info['samples']} échantillons)\")\n",
    "    \n",
    "    return torch.tensor(pos_weights, dtype=torch.float32), class_info\n",
    "\n",
    "def compute_ultimate_metrics(eval_pred):\n",
    "    \"\"\"Métriques ultra-complètes\"\"\"\n",
    "    predictions, labels = eval_pred\n",
    "    \n",
    "    # Conversion en probabilités\n",
    "    probs = torch.sigmoid(torch.tensor(predictions)).numpy()\n",
    "    \n",
    "    # Seuils optimisés par validation (vous pouvez ajuster)\n",
    "    optimal_thresholds = np.full(probs.shape[1], 0.5)  # Par défaut 0.5\n",
    "    \n",
    "    # Prédictions binaires\n",
    "    y_pred = (probs > optimal_thresholds).astype(int)\n",
    "    y_true = labels.astype(int)\n",
    "    \n",
    "    # Métriques principales\n",
    "    f1_micro = f1_score(y_true, y_pred, average=\"micro\", zero_division=0)\n",
    "    f1_macro = f1_score(y_true, y_pred, average=\"macro\", zero_division=0)\n",
    "    f1_weighted = f1_score(y_true, y_pred, average=\"weighted\", zero_division=0)\n",
    "    hamming = hamming_loss(y_true, y_pred)\n",
    "    \n",
    "    # Métriques par classe\n",
    "    f1_per_class = f1_score(y_true, y_pred, average=None, zero_division=0)\n",
    "    \n",
    "    return {\n",
    "        \"f1_micro\": f1_micro,\n",
    "        \"f1_macro\": f1_macro,\n",
    "        \"f1_weighted\": f1_weighted,\n",
    "        \"hamming_loss\": hamming,\n",
    "        \"f1_mean\": np.mean(f1_per_class),\n",
    "        \"f1_std\": np.std(f1_per_class),\n",
    "        \"f1_top5\": np.mean(np.sort(f1_per_class)[-5:]),  # Moyenne des 5 meilleures\n",
    "    }"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8abc19c0",
   "metadata": {},
   "source": [
    "## Trainer opti"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "id": "dd9148f5",
   "metadata": {},
   "outputs": [],
   "source": [
    "class UltimateTrainer(Trainer):\n",
    "    def __init__(self, pos_weights=None, *args, **kwargs):\n",
    "        super().__init__(*args, **kwargs)\n",
    "        self.pos_weights = pos_weights.to(self.args.device) if pos_weights is not None else None\n",
    "        \n",
    "    def compute_loss(self, model, inputs, return_outputs=False):\n",
    "        labels = inputs.get(\"labels\")\n",
    "        outputs = model(**inputs)\n",
    "        \n",
    "        if labels is not None:\n",
    "            # Le modèle calcule déjà sa loss optimisée\n",
    "            loss = outputs.loss\n",
    "            \n",
    "            # Ajout optionnel d'une loss avec class weights\n",
    "            if self.pos_weights is not None:\n",
    "                weighted_loss = F.binary_cross_entropy_with_logits(\n",
    "                    outputs.logits, \n",
    "                    labels.float(), \n",
    "                    pos_weight=self.pos_weights\n",
    "                )\n",
    "                # Combinaison des losses\n",
    "                loss = 0.8 * loss + 0.2 * weighted_loss\n",
    "            \n",
    "            outputs.loss = loss\n",
    "        \n",
    "        return (outputs.loss, outputs) if return_outputs else outputs.loss"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "98359589",
   "metadata": {},
   "source": [
    "## Config Entrianement"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "id": "1c39def9",
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_ultimate_training_args():\n",
    "    \"\"\"Configuration d'entraînement pour performances maximales\"\"\"\n",
    "    \n",
    "    return TrainingArguments(\n",
    "        # Répertoires\n",
    "        output_dir=\"./results_ultimate_roberta\",\n",
    "        logging_dir=\"./logs_ultimate\",\n",
    "        \n",
    "        # Stratégie d'évaluation\n",
    "        evaluation_strategy=\"steps\",\n",
    "        eval_steps=1000,  # Évaluation fréquente\n",
    "        save_strategy=\"steps\",\n",
    "        save_steps=1000,\n",
    "        logging_steps=100,\n",
    "        \n",
    "        # Hyperparamètres optimisés\n",
    "        num_train_epochs=6,  # Plus d'époques pour convergence\n",
    "        per_device_train_batch_size=4,\n",
    "        per_device_eval_batch_size=8,\n",
    "        gradient_accumulation_steps=8,  # Batch effectif = 32\n",
    "        \n",
    "        # Optimisation\n",
    "        learning_rate=8e-6,  # Légèrement plus bas pour stabilité\n",
    "        weight_decay=0.01,\n",
    "        warmup_ratio=0.1,  # Plus de warmup\n",
    "        lr_scheduler_type=\"cosine\",  # Scheduler avancé\n",
    "        \n",
    "        # Performance\n",
    "        fp16=True,\n",
    "        dataloader_num_workers=2,\n",
    "        dataloader_pin_memory=False,\n",
    "        \n",
    "        # Sélection du meilleur modèle\n",
    "        load_best_model_at_end=True,\n",
    "        metric_for_best_model=\"f1_macro\",\n",
    "        greater_is_better=True,\n",
    "        \n",
    "        # Stability\n",
    "        seed=42,\n",
    "        data_seed=42,\n",
    "        \n",
    "        # Monitoring\n",
    "        report_to=\"none\",\n",
    "        run_name=\"ultimate_roberta_emotion\",\n",
    "        \n",
    "        # Sauvegarde\n",
    "        save_total_limit=3,\n",
    "        \n",
    "        # Optimisations avancées\n",
    "        remove_unused_columns=False,\n",
    "        push_to_hub=False,\n",
    "        \n",
    "        # Early stopping via callback\n",
    "        # load_best_model_at_end=True assure qu'on garde le meilleur\n",
    "    )"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ab8963a8",
   "metadata": {},
   "source": [
    "##  Pipeline complet"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cc1e4659",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "🔥 ENTRAÎNEMENT ROBERTA ULTIMATE (AVEC MONITORING)\n",
      "============================================================\n",
      "🔧 PRÉPARATION ULTRA-OPTIMISÉE DES DONNÉES (CORRIGÉE)\n",
      "==================================================\n",
      "📊 Colonnes d'émotions: 28\n",
      "🔧 Tokenisation en cours...\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "d893e2b252d744b48dcaae43fc199c40",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Tokenisation:   0%|          | 0/166242 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "7dac6fbadeed4f2c8306018eb9bf9718",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Tokenisation:   0%|          | 0/20780 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "884b86f231264412bf72fae0c8cae419",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Tokenisation:   0%|          | 0/20781 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "🔍 Vérification des colonnes finales:\n",
      "   train: ['input_ids', 'attention_mask', 'labels']\n",
      "   validation: ['input_ids', 'attention_mask', 'labels']\n",
      "   test: ['input_ids', 'attention_mask', 'labels']\n",
      "⚖️ CALCUL DES POIDS DE CLASSES\n",
      "📊 Top 5 émotions les plus fréquentes:\n",
      "   neutral: 0.266 (44298 échantillons)\n",
      "   approval: 0.085 (14068 échantillons)\n",
      "   admiration: 0.082 (13701 échantillons)\n",
      "   annoyance: 0.066 (10918 échantillons)\n",
      "   gratitude: 0.056 (9243 échantillons)\n",
      "📊 Top 5 émotions les plus rares:\n",
      "   embarrassment: 0.012 (1954 échantillons)\n",
      "   nervousness: 0.009 (1424 échantillons)\n",
      "   pride: 0.006 (1033 échantillons)\n",
      "   relief: 0.006 (1017 échantillons)\n",
      "   grief: 0.003 (538 échantillons)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of RobertaForSequenceClassification were not initialized from the model checkpoint at roberta-base and are newly initialized: ['classifier.dense.bias', 'classifier.dense.weight', 'classifier.out_proj.bias', 'classifier.out_proj.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      "Exception in thread Thread-19 (monitor):\n",
      "Traceback (most recent call last):\n",
      "  File \"c:\\Users\\Yann\\anaconda3\\envs\\hf_gpu_env\\lib\\threading.py\", line 1016, in _bootstrap_inner\n",
      "    self.run()\n",
      "  File \"c:\\Users\\Yann\\anaconda3\\envs\\hf_gpu_env\\lib\\site-packages\\ipykernel\\ipkernel.py\", line 766, in run_closure\n",
      "    _threading_Thread_run(self)\n",
      "  File \"c:\\Users\\Yann\\anaconda3\\envs\\hf_gpu_env\\lib\\threading.py\", line 953, in run\n",
      "    self._target(*self._args, **self._kwargs)\n",
      "  File \"C:\\Users\\Yann\\AppData\\Local\\Temp\\ipykernel_22988\\1269042144.py\", line 10, in monitor\n",
      "TypeError: 'bool' object is not callable\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "🚀 LANCEMENT DE L'ENTRAÎNEMENT + MONITORING...\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "0b989848aa1d4ba2bba3b840aede72cf",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/31170 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'loss': 0.6001, 'grad_norm': 1.9647996425628662, 'learning_rate': 1.2832852101379533e-07, 'epoch': 0.01}\n",
      "{'loss': 0.5843, 'grad_norm': 1.8275004625320435, 'learning_rate': 2.5665704202759066e-07, 'epoch': 0.02}\n",
      "{'loss': 0.5867, 'grad_norm': 1.8281399011611938, 'learning_rate': 3.8498556304138593e-07, 'epoch': 0.03}\n",
      "{'loss': 0.5639, 'grad_norm': 1.7274155616760254, 'learning_rate': 5.133140840551813e-07, 'epoch': 0.04}\n",
      "{'loss': 0.5407, 'grad_norm': 1.531896948814392, 'learning_rate': 6.416426050689766e-07, 'epoch': 0.05}\n",
      "{'loss': 0.5128, 'grad_norm': 1.5013582706451416, 'learning_rate': 7.699711260827719e-07, 'epoch': 0.06}\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "6d6ab2027da54e2fb28eba6e157c2477",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/2598 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# AVANT de lancer votre pipeline, définissez cette fonction :\n",
    "import threading\n",
    "import time\n",
    "from IPython.display import clear_output\n",
    "\n",
    "def start_monitoring_thread(trainer, refresh_seconds=60):\n",
    "    \"\"\"Lance le monitoring dans un thread séparé\"\"\"\n",
    "    \n",
    "    def monitor():\n",
    "        while not trainer.state.is_world_process_zero() or trainer.state.epoch < trainer.args.num_train_epochs:\n",
    "            try:\n",
    "                clear_output(wait=True)\n",
    "                \n",
    "                print(\"🚀 MONITORING ENTRAÎNEMENT ROBERTA\")\n",
    "                print(\"=\" * 50)\n",
    "                \n",
    "                # État actuel\n",
    "                current_epoch = trainer.state.epoch\n",
    "                total_epochs = trainer.args.num_train_epochs\n",
    "                current_step = trainer.state.global_step\n",
    "                \n",
    "                print(f\"📊 Époque: {current_epoch:.1f}/{total_epochs}\")\n",
    "                print(f\"📊 Step: {current_step}\")\n",
    "                \n",
    "                # Progression visuelle\n",
    "                progress = (current_epoch / total_epochs) * 100\n",
    "                bar_length = 30\n",
    "                filled = int(bar_length * progress / 100)\n",
    "                bar = \"█\" * filled + \"░\" * (bar_length - filled)\n",
    "                print(f\"📈 [{bar}] {progress:.1f}%\")\n",
    "                \n",
    "                # Dernières métriques\n",
    "                if hasattr(trainer.state, 'log_history') and trainer.state.log_history:\n",
    "                    logs = trainer.state.log_history\n",
    "                    \n",
    "                    # Train loss\n",
    "                    train_logs = [log for log in logs if 'train_loss' in log]\n",
    "                    if train_logs:\n",
    "                        print(f\"🔥 Train Loss: {train_logs[-1]['train_loss']:.4f}\")\n",
    "                    \n",
    "                    # Eval metrics\n",
    "                    eval_logs = [log for log in logs if 'eval_f1_macro' in log]\n",
    "                    if eval_logs:\n",
    "                        last_eval = eval_logs[-1]\n",
    "                        print(f\"🎯 Eval F1 Macro: {last_eval['eval_f1_macro']:.4f}\")\n",
    "                        print(f\"🎯 Eval F1 Micro: {last_eval['eval_f1_micro']:.4f}\")\n",
    "                        \n",
    "                        # Objectif\n",
    "                        if last_eval['eval_f1_macro'] >= 0.45:\n",
    "                            print(\"🏆 OBJECTIF F1 > 0.45 ATTEINT!\")\n",
    "                \n",
    "                print(f\"⏰ {time.strftime('%H:%M:%S')} | Next update in {refresh_seconds}s\")\n",
    "                \n",
    "                time.sleep(refresh_seconds)\n",
    "                \n",
    "            except Exception as e:\n",
    "                print(f\"Monitoring error: {e}\")\n",
    "                time.sleep(refresh_seconds)\n",
    "    \n",
    "    # Lancer dans un thread\n",
    "    monitor_thread = threading.Thread(target=monitor, daemon=True)\n",
    "    monitor_thread.start()\n",
    "    return monitor_thread\n",
    "\n",
    "# PUIS modifiez votre pipeline comme ça :\n",
    "def train_ultimate_roberta_with_monitoring(df_train, df_val, df_test):\n",
    "    \"\"\"Pipeline avec monitoring intégré\"\"\"\n",
    "    \n",
    "    print(\"🔥 ENTRAÎNEMENT ROBERTA ULTIMATE (AVEC MONITORING)\")\n",
    "    print(\"=\" * 60)\n",
    "    \n",
    "    # 1-6. Préparation (identique à votre code)\n",
    "    tokenizer, tokenized_datasets, emotion_columns = prepare_ultimate_data(\n",
    "        df_train, df_val, df_test\n",
    "    )\n",
    "    \n",
    "    pos_weights, class_info = compute_optimal_class_weights(df_train, emotion_columns)\n",
    "    \n",
    "    model = UltimateRoBERTaForMultiLabel(\n",
    "        num_labels=len(emotion_columns),\n",
    "        dropout_rate=0.2,\n",
    "        use_pooling=True\n",
    "    ).to(device)\n",
    "    \n",
    "    training_args = create_ultimate_training_args()\n",
    "    early_stopping = EarlyStoppingCallback(\n",
    "        early_stopping_patience=5,\n",
    "        early_stopping_threshold=0.0001\n",
    "    )\n",
    "    \n",
    "    trainer = UltimateTrainer(\n",
    "        model=model,\n",
    "        args=training_args,\n",
    "        train_dataset=tokenized_datasets[\"train\"],\n",
    "        eval_dataset=tokenized_datasets[\"validation\"],\n",
    "        tokenizer=tokenizer,\n",
    "        compute_metrics=compute_ultimate_metrics,\n",
    "        callbacks=[early_stopping],\n",
    "        pos_weights=pos_weights\n",
    "    )\n",
    "    \n",
    "    # 🆕 DÉMARRER LE MONITORING AVANT L'ENTRAÎNEMENT\n",
    "    print(\"🚀 LANCEMENT DE L'ENTRAÎNEMENT + MONITORING...\")\n",
    "    monitor_thread = start_monitoring_thread(trainer, refresh_seconds=30)\n",
    "    \n",
    "    # 7. ENTRAÎNEMENT\n",
    "    train_result = trainer.train()\n",
    "    \n",
    "    # Le reste identique...\n",
    "    print(\"\\n📊 ÉVALUATION FINALE...\")\n",
    "    test_results = trainer.evaluate(tokenized_datasets[\"test\"])\n",
    "    \n",
    "    print(f\"\\n🏆 RÉSULTATS TEST FINAUX:\")\n",
    "    for key, value in test_results.items():\n",
    "        if 'eval_' in key:\n",
    "            print(f\"   {key.replace('eval_', '').upper()}: {value:.4f}\")\n",
    "    \n",
    "    trainer.save_model(\"./best_roberta_emotion_model\")\n",
    "    tokenizer.save_pretrained(\"./best_roberta_emotion_model\")\n",
    "    \n",
    "    return trainer, tokenizer, test_results, emotion_columns, class_info\n",
    "\n",
    "# LANCEMENT AVEC MONITORING\n",
    "trainer, tokenizer, final_results, emotions, class_info = train_ultimate_roberta_with_monitoring(\n",
    "    df_train, df_val, df_test\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "38158094",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "🚀 Device: cuda\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "from torch.utils.data import DataLoader, WeightedRandomSampler\n",
    "\n",
    "from transformers import (\n",
    "    AutoTokenizer, AutoModelForSequenceClassification,\n",
    "    TrainingArguments, Trainer, EarlyStoppingCallback,\n",
    "    get_cosine_schedule_with_warmup\n",
    ")\n",
    "from datasets import Dataset, DatasetDict\n",
    "from sklearn.metrics import f1_score, hamming_loss, classification_report\n",
    "from sklearn.utils.class_weight import compute_class_weight\n",
    "from collections import Counter\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')\n",
    "\n",
    "# Configuration GPU\n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "print(f\"🚀 Device: {device}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7de0bf2e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "🚀 Device: cuda\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "from torch.utils.data import DataLoader, WeightedRandomSampler\n",
    "\n",
    "from transformers import (\n",
    "    AutoTokenizer, AutoModelForSequenceClassification,\n",
    "    TrainingArguments, Trainer, EarlyStoppingCallback,\n",
    "    get_cosine_schedule_with_warmup\n",
    ")\n",
    "from datasets import Dataset, DatasetDict\n",
    "from sklearn.metrics import f1_score, hamming_loss, classification_report\n",
    "from sklearn.utils.class_weight import compute_class_weight\n",
    "from collections import Counter\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')\n",
    "\n",
    "# Configuration GPU\n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "print(f\"🚀 Device: {device}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "afc69a2a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "🚀 Device: cuda\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "from torch.utils.data import DataLoader, WeightedRandomSampler\n",
    "\n",
    "from transformers import (\n",
    "    AutoTokenizer, AutoModelForSequenceClassification,\n",
    "    TrainingArguments, Trainer, EarlyStoppingCallback,\n",
    "    get_cosine_schedule_with_warmup\n",
    ")\n",
    "from datasets import Dataset, DatasetDict\n",
    "from sklearn.metrics import f1_score, hamming_loss, classification_report\n",
    "from sklearn.utils.class_weight import compute_class_weight\n",
    "from collections import Counter\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')\n",
    "\n",
    "# Configuration GPU\n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "print(f\"🚀 Device: {device}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0ab906c7",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "🚀 Device: cuda\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "from torch.utils.data import DataLoader, WeightedRandomSampler\n",
    "\n",
    "from transformers import (\n",
    "    AutoTokenizer, AutoModelForSequenceClassification,\n",
    "    TrainingArguments, Trainer, EarlyStoppingCallback,\n",
    "    get_cosine_schedule_with_warmup\n",
    ")\n",
    "from datasets import Dataset, DatasetDict\n",
    "from sklearn.metrics import f1_score, hamming_loss, classification_report\n",
    "from sklearn.utils.class_weight import compute_class_weight\n",
    "from collections import Counter\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')\n",
    "\n",
    "# Configuration GPU\n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "print(f\"🚀 Device: {device}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ea06701f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "🚀 Device: cuda\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "from torch.utils.data import DataLoader, WeightedRandomSampler\n",
    "\n",
    "from transformers import (\n",
    "    AutoTokenizer, AutoModelForSequenceClassification,\n",
    "    TrainingArguments, Trainer, EarlyStoppingCallback,\n",
    "    get_cosine_schedule_with_warmup\n",
    ")\n",
    "from datasets import Dataset, DatasetDict\n",
    "from sklearn.metrics import f1_score, hamming_loss, classification_report\n",
    "from sklearn.utils.class_weight import compute_class_weight\n",
    "from collections import Counter\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')\n",
    "\n",
    "# Configuration GPU\n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "print(f\"🚀 Device: {device}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "efe32b34",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "🚀 Device: cuda\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "from torch.utils.data import DataLoader, WeightedRandomSampler\n",
    "\n",
    "from transformers import (\n",
    "    AutoTokenizer, AutoModelForSequenceClassification,\n",
    "    TrainingArguments, Trainer, EarlyStoppingCallback,\n",
    "    get_cosine_schedule_with_warmup\n",
    ")\n",
    "from datasets import Dataset, DatasetDict\n",
    "from sklearn.metrics import f1_score, hamming_loss, classification_report\n",
    "from sklearn.utils.class_weight import compute_class_weight\n",
    "from collections import Counter\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')\n",
    "\n",
    "# Configuration GPU\n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "print(f\"🚀 Device: {device}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "03303147",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "🔥 DÉMARRAGE DU MEILLEUR ROBERTA POSSIBLE...\n",
      "🔥 ENTRAÎNEMENT ROBERTA ULTIMATE\n",
      "============================================================\n",
      "🔧 PRÉPARATION ULTRA-OPTIMISÉE DES DONNÉES\n",
      "==================================================\n",
      "📊 Colonnes d'émotions: 28\n",
      "   ['admiration', 'amusement', 'anger', 'annoyance', 'approval', 'caring', 'confusion', 'curiosity', 'desire', 'disappointment', 'disapproval', 'disgust', 'embarrassment', 'excitement', 'fear', 'gratitude', 'grief', 'joy', 'love', 'nervousness', 'optimism', 'pride', 'realization', 'relief', 'remorse', 'sadness', 'surprise', 'neutral']\n",
      "📊 Tailles des datasets:\n",
      "   Train: 166242 exemples\n",
      "   Val: 20780 exemples\n",
      "   Test: 20781 exemples\n",
      "🔧 Tokenisation en cours...\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "4eccc6fe74d84c7ea6fe0ecb18020f3b",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Tokenisation:   0%|          | 0/166242 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "d378360b77274ed7bc920d8735e44a1d",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Tokenisation:   0%|          | 0/20780 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "d072659db6e548e49e7c5b23477b7d00",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Tokenisation:   0%|          | 0/20781 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "✅ Tokenisation terminée\n",
      "   Train tokenisé: 166242\n",
      "   Val tokenisé: 20780\n",
      "   Test tokenisé: 20781\n",
      "⚖️ CALCUL DES POIDS DE CLASSES\n",
      "📊 Top 5 émotions les plus fréquentes:\n",
      "   neutral: 0.266 (44298 échantillons)\n",
      "   approval: 0.085 (14068 échantillons)\n",
      "   admiration: 0.082 (13701 échantillons)\n",
      "   annoyance: 0.066 (10918 échantillons)\n",
      "   gratitude: 0.056 (9243 échantillons)\n",
      "📊 Top 5 émotions les plus rares:\n",
      "   embarrassment: 0.012 (1954 échantillons)\n",
      "   nervousness: 0.009 (1424 échantillons)\n",
      "   pride: 0.006 (1033 échantillons)\n",
      "   relief: 0.006 (1017 échantillons)\n",
      "   grief: 0.003 (538 échantillons)\n",
      "🏗️ Initialisation du modèle Ultimate RoBERTa...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of RobertaForSequenceClassification were not initialized from the model checkpoint at roberta-base and are newly initialized: ['classifier.dense.bias', 'classifier.dense.weight', 'classifier.out_proj.bias', 'classifier.out_proj.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "📊 Modèle initialisé avec 28 labels\n"
     ]
    },
    {
     "ename": "TypeError",
     "evalue": "TrainingArguments.__init__() got an unexpected keyword argument 'eval_strategy'",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[30], line 80\u001b[0m\n\u001b[0;32m     78\u001b[0m \u001b[38;5;66;03m# 🚀 LANCEMENT DU TRAINING ULTIMATE\u001b[39;00m\n\u001b[0;32m     79\u001b[0m \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m🔥 DÉMARRAGE DU MEILLEUR ROBERTA POSSIBLE...\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[1;32m---> 80\u001b[0m trainer, tokenizer, final_results, emotions, class_info \u001b[38;5;241m=\u001b[39m \u001b[43mtrain_ultimate_roberta\u001b[49m\u001b[43m(\u001b[49m\n\u001b[0;32m     81\u001b[0m \u001b[43m    \u001b[49m\u001b[43mdf_train\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mdf_val\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mdf_test\u001b[49m\n\u001b[0;32m     82\u001b[0m \u001b[43m)\u001b[49m\n\u001b[0;32m     84\u001b[0m \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[38;5;124m🏆 ENTRAÎNEMENT TERMINÉ!\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[0;32m     85\u001b[0m \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m🎯 Performance finale: F1 Macro = \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mfinal_results\u001b[38;5;241m.\u001b[39mget(\u001b[38;5;124m'\u001b[39m\u001b[38;5;124meval_f1_macro\u001b[39m\u001b[38;5;124m'\u001b[39m,\u001b[38;5;250m \u001b[39m\u001b[38;5;241m0\u001b[39m)\u001b[38;5;132;01m:\u001b[39;00m\u001b[38;5;124m.4f\u001b[39m\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m\"\u001b[39m)\n",
      "Cell \u001b[1;32mIn[30], line 26\u001b[0m, in \u001b[0;36mtrain_ultimate_roberta\u001b[1;34m(df_train, df_val, df_test)\u001b[0m\n\u001b[0;32m     23\u001b[0m \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m📊 Modèle initialisé avec \u001b[39m\u001b[38;5;132;01m{\u001b[39;00m\u001b[38;5;28mlen\u001b[39m(emotion_columns)\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m labels\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[0;32m     25\u001b[0m \u001b[38;5;66;03m# 4. Configuration d'entraînement\u001b[39;00m\n\u001b[1;32m---> 26\u001b[0m training_args \u001b[38;5;241m=\u001b[39m \u001b[43mcreate_ultimate_training_args\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m     28\u001b[0m \u001b[38;5;66;03m# 5. Callbacks\u001b[39;00m\n\u001b[0;32m     29\u001b[0m early_stopping \u001b[38;5;241m=\u001b[39m EarlyStoppingCallback(\n\u001b[0;32m     30\u001b[0m     early_stopping_patience\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m5\u001b[39m,  \u001b[38;5;66;03m# Patient pour trouver le meilleur\u001b[39;00m\n\u001b[0;32m     31\u001b[0m     early_stopping_threshold\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m0.0001\u001b[39m\n\u001b[0;32m     32\u001b[0m )\n",
      "Cell \u001b[1;32mIn[28], line 4\u001b[0m, in \u001b[0;36mcreate_ultimate_training_args\u001b[1;34m()\u001b[0m\n\u001b[0;32m      1\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21mcreate_ultimate_training_args\u001b[39m():\n\u001b[0;32m      2\u001b[0m \u001b[38;5;250m    \u001b[39m\u001b[38;5;124;03m\"\"\"Configuration d'entraînement pour performances maximales\"\"\"\u001b[39;00m\n\u001b[1;32m----> 4\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mTrainingArguments\u001b[49m\u001b[43m(\u001b[49m\n\u001b[0;32m      5\u001b[0m \u001b[43m        \u001b[49m\u001b[38;5;66;43;03m# Répertoires\u001b[39;49;00m\n\u001b[0;32m      6\u001b[0m \u001b[43m        \u001b[49m\u001b[43moutput_dir\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43m./results_ultimate_roberta\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\n\u001b[0;32m      7\u001b[0m \u001b[43m        \u001b[49m\u001b[43mlogging_dir\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43m./logs_ultimate\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\n\u001b[0;32m      8\u001b[0m \u001b[43m        \u001b[49m\n\u001b[0;32m      9\u001b[0m \u001b[43m        \u001b[49m\u001b[38;5;66;43;03m# Stratégie d'évaluation\u001b[39;49;00m\n\u001b[0;32m     10\u001b[0m \u001b[43m        \u001b[49m\u001b[43meval_strategy\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43msteps\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\n\u001b[0;32m     11\u001b[0m \u001b[43m        \u001b[49m\u001b[43meval_steps\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;241;43m300\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m  \u001b[49m\u001b[38;5;66;43;03m# Évaluation fréquente\u001b[39;49;00m\n\u001b[0;32m     12\u001b[0m \u001b[43m        \u001b[49m\u001b[43msave_strategy\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43msteps\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\n\u001b[0;32m     13\u001b[0m \u001b[43m        \u001b[49m\u001b[43msave_steps\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;241;43m300\u001b[39;49m\u001b[43m,\u001b[49m\n\u001b[0;32m     14\u001b[0m \u001b[43m        \u001b[49m\u001b[43mlogging_steps\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;241;43m50\u001b[39;49m\u001b[43m,\u001b[49m\n\u001b[0;32m     15\u001b[0m \u001b[43m        \u001b[49m\n\u001b[0;32m     16\u001b[0m \u001b[43m        \u001b[49m\u001b[38;5;66;43;03m# Hyperparamètres optimisés\u001b[39;49;00m\n\u001b[0;32m     17\u001b[0m \u001b[43m        \u001b[49m\u001b[43mnum_train_epochs\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;241;43m10\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m  \u001b[49m\u001b[38;5;66;43;03m# Plus d'époques pour convergence\u001b[39;49;00m\n\u001b[0;32m     18\u001b[0m \u001b[43m        \u001b[49m\u001b[43mper_device_train_batch_size\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;241;43m8\u001b[39;49m\u001b[43m,\u001b[49m\n\u001b[0;32m     19\u001b[0m \u001b[43m        \u001b[49m\u001b[43mper_device_eval_batch_size\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;241;43m16\u001b[39;49m\u001b[43m,\u001b[49m\n\u001b[0;32m     20\u001b[0m \u001b[43m        \u001b[49m\u001b[43mgradient_accumulation_steps\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;241;43m4\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m  \u001b[49m\u001b[38;5;66;43;03m# Batch effectif = 32\u001b[39;49;00m\n\u001b[0;32m     21\u001b[0m \u001b[43m        \u001b[49m\n\u001b[0;32m     22\u001b[0m \u001b[43m        \u001b[49m\u001b[38;5;66;43;03m# Optimisation\u001b[39;49;00m\n\u001b[0;32m     23\u001b[0m \u001b[43m        \u001b[49m\u001b[43mlearning_rate\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;241;43m8e-6\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m  \u001b[49m\u001b[38;5;66;43;03m# Légèrement plus bas pour stabilité\u001b[39;49;00m\n\u001b[0;32m     24\u001b[0m \u001b[43m        \u001b[49m\u001b[43mweight_decay\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;241;43m0.01\u001b[39;49m\u001b[43m,\u001b[49m\n\u001b[0;32m     25\u001b[0m \u001b[43m        \u001b[49m\u001b[43mwarmup_ratio\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;241;43m0.15\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m  \u001b[49m\u001b[38;5;66;43;03m# Plus de warmup\u001b[39;49;00m\n\u001b[0;32m     26\u001b[0m \u001b[43m        \u001b[49m\u001b[43mlr_scheduler_type\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mcosine_with_restarts\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m  \u001b[49m\u001b[38;5;66;43;03m# Scheduler avancé\u001b[39;49;00m\n\u001b[0;32m     27\u001b[0m \u001b[43m        \u001b[49m\n\u001b[0;32m     28\u001b[0m \u001b[43m        \u001b[49m\u001b[38;5;66;43;03m# Performance\u001b[39;49;00m\n\u001b[0;32m     29\u001b[0m \u001b[43m        \u001b[49m\u001b[43mfp16\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mtorch\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mcuda\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mis_available\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m     30\u001b[0m \u001b[43m        \u001b[49m\u001b[43mdataloader_num_workers\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;241;43m4\u001b[39;49m\u001b[43m,\u001b[49m\n\u001b[0;32m     31\u001b[0m \u001b[43m        \u001b[49m\u001b[43mdataloader_pin_memory\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43;01mTrue\u001b[39;49;00m\u001b[43m,\u001b[49m\n\u001b[0;32m     32\u001b[0m \u001b[43m        \u001b[49m\n\u001b[0;32m     33\u001b[0m \u001b[43m        \u001b[49m\u001b[38;5;66;43;03m# Sélection du meilleur modèle\u001b[39;49;00m\n\u001b[0;32m     34\u001b[0m \u001b[43m        \u001b[49m\u001b[43mload_best_model_at_end\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43;01mTrue\u001b[39;49;00m\u001b[43m,\u001b[49m\n\u001b[0;32m     35\u001b[0m \u001b[43m        \u001b[49m\u001b[43mmetric_for_best_model\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mf1_macro\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\n\u001b[0;32m     36\u001b[0m \u001b[43m        \u001b[49m\u001b[43mgreater_is_better\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43;01mTrue\u001b[39;49;00m\u001b[43m,\u001b[49m\n\u001b[0;32m     37\u001b[0m \u001b[43m        \u001b[49m\n\u001b[0;32m     38\u001b[0m \u001b[43m        \u001b[49m\u001b[38;5;66;43;03m# Stability\u001b[39;49;00m\n\u001b[0;32m     39\u001b[0m \u001b[43m        \u001b[49m\u001b[43mseed\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;241;43m42\u001b[39;49m\u001b[43m,\u001b[49m\n\u001b[0;32m     40\u001b[0m \u001b[43m        \u001b[49m\u001b[43mdata_seed\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;241;43m42\u001b[39;49m\u001b[43m,\u001b[49m\n\u001b[0;32m     41\u001b[0m \u001b[43m        \u001b[49m\n\u001b[0;32m     42\u001b[0m \u001b[43m        \u001b[49m\u001b[38;5;66;43;03m# Monitoring\u001b[39;49;00m\n\u001b[0;32m     43\u001b[0m \u001b[43m        \u001b[49m\u001b[43mreport_to\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mnone\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\n\u001b[0;32m     44\u001b[0m \u001b[43m        \u001b[49m\u001b[43mrun_name\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43multimate_roberta_emotion\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\n\u001b[0;32m     45\u001b[0m \u001b[43m        \u001b[49m\n\u001b[0;32m     46\u001b[0m \u001b[43m        \u001b[49m\u001b[38;5;66;43;03m# Sauvegarde\u001b[39;49;00m\n\u001b[0;32m     47\u001b[0m \u001b[43m        \u001b[49m\u001b[43msave_total_limit\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;241;43m3\u001b[39;49m\u001b[43m,\u001b[49m\n\u001b[0;32m     48\u001b[0m \u001b[43m        \u001b[49m\n\u001b[0;32m     49\u001b[0m \u001b[43m        \u001b[49m\u001b[38;5;66;43;03m# Optimisations avancées\u001b[39;49;00m\n\u001b[0;32m     50\u001b[0m \u001b[43m        \u001b[49m\u001b[43mremove_unused_columns\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43;01mFalse\u001b[39;49;00m\u001b[43m,\u001b[49m\n\u001b[0;32m     51\u001b[0m \u001b[43m        \u001b[49m\u001b[43mpush_to_hub\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43;01mFalse\u001b[39;49;00m\u001b[43m,\u001b[49m\n\u001b[0;32m     52\u001b[0m \u001b[43m        \u001b[49m\n\u001b[0;32m     53\u001b[0m \u001b[43m        \u001b[49m\u001b[38;5;66;43;03m# Early stopping via callback\u001b[39;49;00m\n\u001b[0;32m     54\u001b[0m \u001b[43m        \u001b[49m\u001b[38;5;66;43;03m# load_best_model_at_end=True assure qu'on garde le meilleur\u001b[39;49;00m\n\u001b[0;32m     55\u001b[0m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[1;31mTypeError\u001b[0m: TrainingArguments.__init__() got an unexpected keyword argument 'eval_strategy'"
     ]
    }
   ],
   "source": [
    "def train_ultimate_roberta(df_train, df_val, df_test):\n",
    "    \"\"\"Pipeline complet pour le meilleur RoBERTa possible\"\"\"\n",
    "    \n",
    "    print(\"🔥 ENTRAÎNEMENT ROBERTA ULTIMATE\")\n",
    "    print(\"=\" * 60)\n",
    "    \n",
    "    # 1. Préparation des données\n",
    "    tokenizer, tokenized_datasets, emotion_columns = prepare_ultimate_data(\n",
    "        df_train, df_val, df_test\n",
    "    )\n",
    "    \n",
    "    # 2. Calcul des poids\n",
    "    pos_weights, class_info = compute_optimal_class_weights(df_train, emotion_columns)\n",
    "    \n",
    "    # 3. Modèle ultimate\n",
    "    print(\"🏗️ Initialisation du modèle Ultimate RoBERTa...\")\n",
    "    model = UltimateRoBERTaForMultiLabel(\n",
    "        num_labels=len(emotion_columns),\n",
    "        dropout_rate=0.2,  # Dropout modéré\n",
    "        use_pooling=True   # Attention pooling activé\n",
    "    ).to(device)\n",
    "    \n",
    "    print(f\"📊 Modèle initialisé avec {len(emotion_columns)} labels\")\n",
    "    \n",
    "    # 4. Configuration d'entraînement\n",
    "    training_args = create_ultimate_training_args()\n",
    "    \n",
    "    # 5. Callbacks\n",
    "    early_stopping = EarlyStoppingCallback(\n",
    "        early_stopping_patience=5,  # Patient pour trouver le meilleur\n",
    "        early_stopping_threshold=0.0001\n",
    "    )\n",
    "    \n",
    "    # 6. Trainer ultimate\n",
    "    trainer = UltimateTrainer(\n",
    "        model=model,\n",
    "        args=training_args,\n",
    "        train_dataset=tokenized_datasets[\"train\"],\n",
    "        eval_dataset=tokenized_datasets[\"validation\"],\n",
    "        tokenizer=tokenizer,\n",
    "        compute_metrics=compute_ultimate_metrics,\n",
    "        callbacks=[early_stopping],\n",
    "        pos_weights=pos_weights\n",
    "    )\n",
    "    \n",
    "    # 7. ENTRAÎNEMENT\n",
    "    print(\"🚀 LANCEMENT DE L'ENTRAÎNEMENT ULTIMATE...\")\n",
    "    print(\"   Cela peut prendre 1-3 heures selon votre GPU\")\n",
    "    print(\"=\" * 60)\n",
    "    \n",
    "    train_result = trainer.train()\n",
    "    \n",
    "    # 8. Évaluation finale\n",
    "    print(\"\\n📊 ÉVALUATION FINALE...\")\n",
    "    \n",
    "    # Validation\n",
    "    val_results = trainer.evaluate(tokenized_datasets[\"validation\"])\n",
    "    print(f\"\\n🎯 RÉSULTATS VALIDATION:\")\n",
    "    for key, value in val_results.items():\n",
    "        if 'eval_' in key:\n",
    "            print(f\"   {key.replace('eval_', '').upper()}: {value:.4f}\")\n",
    "    \n",
    "    # Test\n",
    "    test_results = trainer.evaluate(tokenized_datasets[\"test\"])\n",
    "    print(f\"\\n🏆 RÉSULTATS TEST FINAUX:\")\n",
    "    for key, value in test_results.items():\n",
    "        if 'eval_' in key:\n",
    "            print(f\"   {key.replace('eval_', '').upper()}: {value:.4f}\")\n",
    "    \n",
    "    # 9. Sauvegarde du meilleur modèle\n",
    "    trainer.save_model(\"./best_roberta_emotion_model\")\n",
    "    tokenizer.save_pretrained(\"./best_roberta_emotion_model\")\n",
    "    \n",
    "    print(\"\\n✅ MODÈLE SAUVEGARDÉ DANS: ./best_roberta_emotion_model\")\n",
    "    \n",
    "    return trainer, tokenizer, test_results, emotion_columns, class_info\n",
    "\n",
    "# 🚀 LANCEMENT DU TRAINING ULTIMATE\n",
    "print(\"🔥 DÉMARRAGE DU MEILLEUR ROBERTA POSSIBLE...\")\n",
    "trainer, tokenizer, final_results, emotions, class_info = train_ultimate_roberta(\n",
    "    df_train, df_val, df_test\n",
    ")\n",
    "\n",
    "print(\"\\n🏆 ENTRAÎNEMENT TERMINÉ!\")\n",
    "print(f\"🎯 Performance finale: F1 Macro = {final_results.get('eval_f1_macro', 0):.4f}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b355c4ea",
   "metadata": {},
   "source": [
    " ## Analyse post entrainements"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f85871ce",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Maintenant on peut faire l'analyse avec toutes les variables définies\n",
    "def analyze_ultimate_results_fixed(trainer, tokenized_datasets, emotions):\n",
    "    \"\"\"Analyse complète des résultats - VERSION CORRIGÉE\"\"\"\n",
    "    \n",
    "    print(\"🔍 ANALYSE DÉTAILLÉE DES RÉSULTATS\")\n",
    "    print(\"=\" * 50)\n",
    "    \n",
    "    # Vérification que tokenized_datasets existe\n",
    "    if tokenized_datasets is None:\n",
    "        print(\"❌ Erreur: tokenized_datasets est None\")\n",
    "        return None\n",
    "    \n",
    "    if \"test\" not in tokenized_datasets:\n",
    "        print(\"❌ Erreur: pas de dataset 'test'\")\n",
    "        return None\n",
    "    \n",
    "    # Prédictions\n",
    "    print(\"📊 Génération des prédictions...\")\n",
    "    predictions = trainer.predict(tokenized_datasets[\"test\"])\n",
    "    probs = torch.sigmoid(torch.tensor(predictions.predictions)).numpy()\n",
    "    y_true = predictions.label_ids\n",
    "    \n",
    "    print(f\"   Shape probs: {probs.shape}\")\n",
    "    print(f\"   Shape y_true: {y_true.shape}\")\n",
    "    \n",
    "    # Optimisation des seuils par émotion\n",
    "    best_thresholds = []\n",
    "    emotion_performances = []\n",
    "    \n",
    "    print(\"🔧 Optimisation des seuils...\")\n",
    "    for i, emotion in enumerate(emotions):\n",
    "        best_f1 = 0\n",
    "        best_threshold = 0.5\n",
    "        \n",
    "        # Recherche du seuil optimal\n",
    "        for threshold in np.arange(0.1, 0.9, 0.05):  # Pas plus large pour rapidité\n",
    "            y_pred_temp = (probs[:, i] > threshold).astype(int)\n",
    "            f1_temp = f1_score(y_true[:, i], y_pred_temp, zero_division=0)\n",
    "            \n",
    "            if f1_temp > best_f1:\n",
    "                best_f1 = f1_temp\n",
    "                best_threshold = threshold\n",
    "        \n",
    "        best_thresholds.append(best_threshold)\n",
    "        emotion_performances.append({\n",
    "            'emotion': emotion,\n",
    "            'f1_score': best_f1,\n",
    "            'threshold': best_threshold,\n",
    "            'frequency': np.mean(y_true[:, i])\n",
    "        })\n",
    "    \n",
    "    # Prédictions finales avec seuils optimaux\n",
    "    y_pred_optimal = np.zeros_like(probs)\n",
    "    for i, threshold in enumerate(best_thresholds):\n",
    "        y_pred_optimal[:, i] = (probs[:, i] > threshold).astype(int)\n",
    "    \n",
    "    # Métriques finales optimisées\n",
    "    final_f1_micro = f1_score(y_true, y_pred_optimal, average=\"micro\")\n",
    "    final_f1_macro = f1_score(y_true, y_pred_optimal, average=\"macro\")\n",
    "    final_hamming = hamming_loss(y_true, y_pred_optimal)\n",
    "    \n",
    "    # Tri des performances\n",
    "    emotion_performances.sort(key=lambda x: x['f1_score'], reverse=True)\n",
    "    \n",
    "    print(\"🏆 TOP 10 ÉMOTIONS MIEUX PRÉDITES:\")\n",
    "    for i, perf in enumerate(emotion_performances[:10], 1):\n",
    "        print(f\"   {i:2d}. {perf['emotion']:15} | F1: {perf['f1_score']:.3f} | Seuil: {perf['threshold']:.2f}\")\n",
    "    \n",
    "    print(\"\\n⚠️ TOP 5 ÉMOTIONS LES PLUS DIFFICILES:\")\n",
    "    for i, perf in enumerate(emotion_performances[-5:], 1):\n",
    "        print(f\"   {i:2d}. {perf['emotion']:15} | F1: {perf['f1_score']:.3f} | Freq: {perf['frequency']:.3f}\")\n",
    "    \n",
    "    print(f\"\\n🎯 MÉTRIQUES FINALES AVEC SEUILS OPTIMISÉS:\")\n",
    "    print(f\"   F1 MICRO:     {final_f1_micro:.4f}\")\n",
    "    print(f\"   F1 MACRO:     {final_f1_macro:.4f}\")\n",
    "    print(f\"   HAMMING LOSS: {final_hamming:.4f}\")\n",
    "    \n",
    "    # Comparaison avec les objectifs\n",
    "    target_f1_macro = 0.45\n",
    "    improvement = final_f1_macro - target_f1_macro\n",
    "    \n",
    "    print(f\"\\n🎯 OBJECTIF vs RÉALITÉ:\")\n",
    "    print(f\"   Objectif:     {target_f1_macro:.4f}\")\n",
    "    print(f\"   Obtenu:       {final_f1_macro:.4f}\")\n",
    "    print(f\"   Amélioration: {improvement:+.4f}\")\n",
    "    \n",
    "    if final_f1_macro >= target_f1_macro:\n",
    "        print(\"   🏆 OBJECTIF ATTEINT! 🏆\")\n",
    "    else:\n",
    "        print(\"   📈 Proche de l'objectif, continuez l'optimisation!\")\n",
    "    \n",
    "    return {\n",
    "        'f1_micro': final_f1_micro,\n",
    "        'f1_macro': final_f1_macro,\n",
    "        'hamming_loss': final_hamming,\n",
    "        'emotion_performances': emotion_performances,\n",
    "        'best_thresholds': best_thresholds\n",
    "    }\n",
    "\n",
    "# 🔍 ANALYSE FINALE CORRIGÉE\n",
    "print(\"\\n🔍 DÉMARRAGE DE L'ANALYSE...\")\n",
    "final_analysis = analyze_ultimate_results_fixed(trainer, tokenized_datasets, emotions)\n",
    "\n",
    "if final_analysis is not None:\n",
    "    print(\"\\n🔥 MISSION ACCOMPLIE! ANALYSE TERMINÉE! 🔥\")\n",
    "    print(f\"🏆 F1 Macro Final: {final_analysis['f1_macro']:.4f}\")\n",
    "else:\n",
    "    print(\"❌ Erreur dans l'analyse\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d672afc0",
   "metadata": {},
   "outputs": [],
   "source": [
    "# VERSION COMPLÈTE TOUT-EN-UN\n",
    "def run_complete_analysis():\n",
    "    \"\"\"Fonction complète qui fait tout d'un coup\"\"\"\n",
    "    \n",
    "    print(\"🚀 ANALYSE COMPLÈTE ROBERTA\")\n",
    "    print(\"=\" * 40)\n",
    "    \n",
    "    # 1. Vérifications\n",
    "    required_vars = ['trainer', 'df_test', 'df_train']\n",
    "    missing = [var for var in required_vars if var not in globals()]\n",
    "    \n",
    "    if missing:\n",
    "        print(f\"❌ Variables manquantes: {missing}\")\n",
    "        return None\n",
    "    \n",
    "    # 2. Créer emotions si manquant\n",
    "    if 'emotions' not in globals():\n",
    "        exclude_cols = ['id', 'text', 'example_very_unclear', 'num_labels', 'text_length', '__index_level_0__']\n",
    "        emotions = [col for col in df_train.columns if col not in exclude_cols]\n",
    "        print(f\"📊 Émotions créées: {len(emotions)}\")\n",
    "    \n",
    "    # 3. Créer tokenized_datasets si manquant\n",
    "    if 'tokenized_datasets' not in globals():\n",
    "        print(\"🔧 Création de tokenized_datasets...\")\n",
    "        \n",
    "        from transformers import AutoTokenizer\n",
    "        from datasets import Dataset\n",
    "        \n",
    "        tokenizer = AutoTokenizer.from_pretrained(\"roberta-base\")\n",
    "        \n",
    "        def tokenize_for_analysis(examples):\n",
    "            tokenized = tokenizer(\n",
    "                examples[\"text\"],\n",
    "                truncation=True,\n",
    "                padding=\"max_length\",\n",
    "                max_length=256\n",
    "            )\n",
    "            labels = [[float(examples[col][i]) for col in emotions] for i in range(len(examples[\"text\"]))]\n",
    "            tokenized[\"labels\"] = labels\n",
    "            return tokenized\n",
    "        \n",
    "        test_dataset = Dataset.from_pandas(df_test[['text'] + emotions])\n",
    "        tokenized_test = test_dataset.map(tokenize_for_analysis, batched=True, remove_columns=['text'] + emotions)\n",
    "        tokenized_test.set_format(\"torch\")\n",
    "        \n",
    "        tokenized_datasets = {\"test\": tokenized_test}\n",
    "        print(\"✅ tokenized_datasets créé!\")\n",
    "    \n",
    "    # 4. Analyse\n",
    "    print(\"🔍 Lancement de l'analyse...\")\n",
    "    \n",
    "    try:\n",
    "        analysis = analyze_ultimate_results_fixed(trainer, tokenized_datasets, emotions)\n",
    "        return analysis\n",
    "    except Exception as e:\n",
    "        print(f\"❌ Erreur: {e}\")\n",
    "        return None\n",
    "\n",
    "# LANCER L'ANALYSE COMPLÈTE\n",
    "result = run_complete_analysis()\n",
    "\n",
    "if result:\n",
    "    print(f\"\\n🎯 RÉSULTAT FINAL: F1 Macro = {result['f1_macro']:.4f}\")\n",
    "    \n",
    "    # Afficher le top 5 des émotions\n",
    "    print(\"\\n🏆 TOP 5 ÉMOTIONS:\")\n",
    "    for i, perf in enumerate(result['emotion_performances'][:5], 1):\n",
    "        print(f\"   {i}. {perf['emotion']}: F1 = {perf['f1_score']:.3f}\")\n",
    "else:\n",
    "    print(\"❌ Analyse échouée\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "hf_gpu_env",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.18"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
